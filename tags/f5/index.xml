<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>F5 on Jing Lin‘s profile</title><link>http://linjing.io/tags/f5/</link><description>Recent content in F5 on Jing Lin‘s profile</description><generator>Source Themes academia (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Copyright &amp;copy; {year} linjing.io host on github, imesh.cloud host on netlify. CI/CD by github actions and netlify.Thanks bootcdn support for front libary CDN</copyright><lastBuildDate>Tue, 01 Feb 2022 00:00:00 +0000</lastBuildDate><atom:link href="http://linjing.io/tags/f5/index.xml" rel="self" type="application/rss+xml"/><item><title>Container Egress Service(CES)</title><link>http://linjing.io/post/f5-container-egress-service-ces/</link><pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate><guid>http://linjing.io/post/f5-container-egress-service-ces/</guid><description>&lt;h2 id="solution-architecture">Solution architecture&lt;/h2>
&lt;h3 id="components">Components&lt;/h3>
&lt;p>The CES solution includes the following components:&lt;/p>
&lt;ul>
&lt;li>CES controller: a container running in k8s. This component is the control plane, responsible for converting the outbound policies that deployed in k8s into the external data plane component(here is F5 AFM).&lt;/li>
&lt;li>F5 BIG-IP AFM: Data plane components running outside of k8s. Accept the configuration issued by the CES controller and execute specific access control rules, such as access control lists, bandwidth limiting, traffic programming, etc.&lt;/li>
&lt;li>CNI: CNI is a choice of the user environment itself and is not included in the CES plan. However, different CNIs will have different effects on the functions of the CES solution. Use &lt;a href="https://github.com/kubeovn/kube-ovn/">kube-ovn&lt;/a> CNI to get the full functionality of CES.&lt;/li>
&lt;/ul>
&lt;h3 id="architecture-diagram">Architecture diagram&lt;/h3>
&lt;p>&lt;img src="img/high-level-arch.jpg" alt="high-level-arch">&lt;/p>
&lt;h3 id="policy-scope-and-role">Policy scope and role&lt;/h3>
&lt;p>CES provides three policy scopes &lt;code>cluster global&lt;/code> &lt;code>namespace&lt;/code> and &lt;code>service&lt;/code>. Its meaning and user role relationship are as follows:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>scope&lt;/th>
&lt;th>meaning&lt;/th>
&lt;th>Adaptation role&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Cluster global&lt;/td>
&lt;td>It is the global level policy of the cluster, which is used to control the general and overall access control of the cluster. For example, the cluster&amp;rsquo;s access to basic public services such as NTP and DNS of the enterprise. The scope policy is applied to the outbound access control of all services in the cluster.&lt;/td>
&lt;td>Cluster administrator, Security team&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>namespace&lt;/td>
&lt;td>This policy level is effective for a single namespace or project. It is used to control the access of all services in specific NS or project to access the services out of the cluster. Policies in different namespaces or projects do not affect each other. *This function requires the support of CNI.&lt;/td>
&lt;td>Project team, application operation team&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>service level&lt;/td>
&lt;td>The policy control the k8s servcies to the external services. Only valid for specific services. So if the CNI can not support namespace level policy, set svc level policy is an alternative way.&lt;/td>
&lt;td>Project team, application operation, microservice owner&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="tenant-isolation">Tenant isolation&lt;/h3>
&lt;p>The CES solution supports strong isolation of &lt;code>network + namespace&lt;/code>. Supports the administrative isolation of configuration objects on the data plane, and also supports strict traffic isolation at the network level. Support different namespaces to use overlapping CIDR.&lt;/p>
&lt;pre>&lt;code>Need CNI support network isolation. For example kube-ovn's per ns subnet
&lt;/code>&lt;/pre>&lt;h2 id="solution-value">Solution value&lt;/h2>
&lt;h3 id="challenges-solved">Challenges solved&lt;/h3>
&lt;ul>
&lt;li>High-frequency changes in outbound traffic caused by container IP dynamics&lt;/li>
&lt;li>Different role groups have different requirements for the scope setting of the policy, and the policy needs to match the role in multiple dimensions&lt;/li>
&lt;li>Dynamic bandwidth limit requirements for outbound traffic&lt;/li>
&lt;li>Protocol in-depth security inspection requirements&lt;/li>
&lt;li>Advanced requirements for flow programmable based on access control events&lt;/li>
&lt;li>Visualization requirements for outbound traffic&lt;/li>
&lt;/ul>
&lt;h3 id="provided-capabilities">Provided capabilities&lt;/h3>
&lt;ul>
&lt;li>Dynamic IP ACL control with Cluster/Pod/NS granularity&lt;/li>
&lt;li>Cluster/Pod/NS granular FQDN ACL control&lt;/li>
&lt;li>Time-based access control&lt;/li>
&lt;li>Matched flow event trigger and programmable&lt;/li>
&lt;li>Matched traffic redirection&lt;/li>
&lt;li>Protocol security and compliance testing&lt;/li>
&lt;li>IP intelligence&lt;/li>
&lt;li>Traffic matching log&lt;/li>
&lt;li>Traffic matching visualization report&lt;/li>
&lt;li>Protocol detection visual report&lt;/li>
&lt;li>TCP/IP Errors report&lt;/li>
&lt;li>NAT control and logging&lt;/li>
&lt;li>Data flow visualization tracking&lt;/li>
&lt;li>Visual simulation of access rules&lt;/li>
&lt;li>Transparent detection mode&lt;/li>
&lt;li>High-speed log outgoing&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>Partial functions will evolve along with version iterations
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Next step:&lt;/strong>&lt;/p>
&lt;p>&lt;a href="https://github.com/f5devcentral/container-egress-service/wiki/EN_2_CES_Installation">Understanding CES installation&lt;/a>&lt;/p></description></item><item><title>To implement cloud native, you need such an infrastructure</title><link>http://linjing.io/post/f5-cloudnative-media-interview-zhiding/</link><pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate><guid>http://linjing.io/post/f5-cloudnative-media-interview-zhiding/</guid><description>&lt;h1 id="to-implement-cloud-native-you-need-such-an-infrastructure">To implement cloud native, you need such an infrastructure&lt;/h1>
&lt;p>When a ten thousand zhang tall building starts from the ground, only when the foundation piles are deeply driven and the cornerstones are firmly laid, can the building be built higher and more stable. Digital transformation is not the case - all kinds of system applications at the top layer are ultimately inseparable from the support of the underlying infrastructure. It&amp;rsquo;s just that this base must change according to needs and times, instead of building a &amp;ldquo;pillar&amp;rdquo; and building a &amp;ldquo;building&amp;rdquo;.&lt;/p>
&lt;p>Take cloud native applications that are very popular right now, if they are also built on the centralized and complex traditional infrastructure, it is equivalent to &amp;ldquo;new wine in old bottles&amp;rdquo;, and accidentally &amp;ldquo;sprinkled wine in a bottle&amp;rdquo;. Get busy.&lt;/p>
&lt;p>In this regard, Lin Jing, senior solution architect of F5 Networks, said in an interview with a reporter from Zhiding.com that the unique characteristics of cloud-native applications such as flexibility, agility, and simplification have put forward many new requirements for enterprise IT architecture. In three aspects: First, the orchestration of IT service capabilities. Since IT services are abstracted into various atomic services, this puts forward higher requirements for enterprises in event-based automation and operation and maintenance data capability mining; second, the IT architecture is flattened. More and more assembleable architectures are integrated into the underlying network system, which will weaken the previous network-centric thinking, and the capabilities of the platform will become more and more important; third, IT talents are mixed. Talent lines are no longer bounded by obvious networks, systems, etc., and technology-mixed talents will be increasingly strengthened in the scenario of IT architecture platformization.&lt;/p>
&lt;p>&lt;img src="./liiTecDmaLd2_600.jpeg" alt="To implement cloud native, you need such an infrastructure">&lt;/p>
&lt;p>​ &lt;strong>Lin Jing, Solutions Architect,&lt;/strong> &lt;strong>F5 Networks&lt;/strong>&lt;/p>
&lt;p>&amp;ldquo;This means that enterprises need to use new technologies and use cloud-native standards, microservices, containers, etc. to build a modern application architecture to meet the current urgent needs.&amp;rdquo; Lin Jing emphasized. In this process, F5 has been deeply involved in the application network for many years. To help enterprises build an infrastructure that can meet the needs of digital transformation and support the implementation of their cloud-native applications, it should be said that they are very familiar with it.&lt;/p>
&lt;p>&lt;strong>Three footholds, one big platform&lt;/strong>&lt;/p>
&lt;p>From the perspective of F5, it is decomposed from the perspective of F5. Specifically, it pays more attention to three aspects in the context of cloud native: firstly, how to transform the traditional infrastructure into a programmable mode to make the architecture more flexible and scalable; secondly It is how to build a modern service architecture based on new technologies such as microservices and containers; the third is to integrate the two.&lt;/p>
&lt;p>For the first point, we see that the focus of F5 in traditional infrastructure in the past was mainly from the boundary of the data center entrance, to the authentication of data center services, the load balancing of background applications, and then to the release and policy control of application services. , all products and services revolve around applications. Now, as long as F5 endows the platform carrying these services with programmable capabilities and releases such capabilities to the upper layer, it can well meet the needs of enterprises in terms of flexible application invocation.&lt;/p>
&lt;p>&amp;ldquo;First of all, at the infrastructure layer, we have tenanted the underlying service resources and hardware resources of F5, and provided automated orchestration tools such as Ansible and Terrafrom to help enterprises achieve rapid resource allocation through interfaces; at the abstraction layer, using DO Business deployment with AS3, using F5OS-API to help users adapt to the division of underlying resources, etc.&amp;rdquo; Lin Jing explained.&lt;/p>
&lt;p>For the second point, enterprises often start by building an assembleable architecture, that is, building their own private cloud, or directly using public cloud services. In order to integrate into this new modern cloud-native architecture, F5 has introduced many new capabilities for itself - for example, through the acquisition of NGINX, it has improved its capabilities including service mesh and PaaS entry, and truly penetrated into cloud-native; Through the acquisition of Volterra, a unified cloud-native platform interaction capability from public cloud, private cloud to edge is built; through the acquisition of Threat Stack, the full-stack security capabilities under the cloud-native system are further complemented.&lt;/p>
&lt;p>&amp;ldquo;For example, in terms of operation, we can provide a multi-language operation server through the NGINX standard APP Server and Unit, and provide a standard Kubernetes Ingress controller under the Kubernetes system; secondly, in Kubernetes, we will also provide NGINX. Proxy at the containerization layer such as Service Proxy, and API management provided by NGINX, help enterprises manage the full life cycle of APIs.” According to Lin Jing, in addition to the PaaS layer, F5 also provides many SaaS services, involving security, analysis and insight , Smart DNS and other applications.&lt;/p>
&lt;p>For the integration of traditional architecture and modern application architecture, F5 believes that the key lies in the collaboration between the two different architectures. In this regard, F5 also creatively proposed the concepts of &amp;ldquo;internal cloud native application service&amp;rdquo; and &amp;ldquo;external cloud native application service&amp;rdquo;. The former refers to service capabilities around technical scenarios such as containers and Kubernetes; the latter refers to providing more external capabilities under the above conventional services, such as connecting and managing internal application services with external APIs.&lt;/p>
&lt;p>&amp;ldquo;At the boundary of the data center, from security to compliance operations, we used to look at the data center from the perspective of virtual machines and the grid as the core. But under the new PaaS system, all IPs are very dynamic. , to achieve real-time monitoring, security policies and norms will be challenged, therefore, integration between traditional infrastructure and PaaS must be carried out.” Lin Jing emphasized.&lt;/p>
&lt;p>&lt;strong>Complete technical and role challenges&lt;/strong>&lt;/p>
&lt;p>Today, F5 has put this core idea into practice in the process of serving corporate customers. Take a bank as an example: Previously, the bank drove the construction of its own PaaS system through the cloud management center. However, in the process of business release, they found that all release processes would eventually return to the traditional management and control model of the network department. &amp;ldquo;At this time, the cooperation of the two departments is required, and the fast and agile characteristics of the cloud itself will be greatly weakened.&amp;rdquo; Lin Jing said.&lt;/p>
&lt;p>In this regard, F5 proposed an innovative Hub model, which is the &amp;ldquo;one center&amp;rdquo; model. Specifically, a simulated space area is listed on top of Kubernetes, which is managed uniformly by the network team, and all services released by the business department can eventually pass through this central area and be quickly written to the foundation with the help of the F5 controller. facility. In this way, the technical use threshold of the business department is lowered, and the original release mode of the network team is retained, enabling better collaboration between the two departments. The solution used in it, F5 is called &amp;ldquo;the solution of the entrance Ingress&amp;rdquo;, namely Container Ingress Services.&lt;/p>
&lt;p>Correspondingly, F5 also proposed the Egress solution, which mainly aims at the technical and role challenges of enterprises in the process of implementing cloud-native applications. The technical challenge is mainly reflected in the outbound traffic of the container. Since the IP address of the container is constantly changing during the outbound traffic, the traditional firewall cannot perform fine adjustment, which means that the location of all control policies must be able to dynamically sense the container; role challenges It is mainly reflected in the differences in demands between different departments. For example, the business department and the network department will have different security demands, and who should determine the policy standards in the end, which is a very real problem.&lt;/p>
&lt;p>To this end, F5 provides two targeted solutions - solving technical problems through automation controllers, and reducing the difficulty of safe landing through differentiated classification of security policies. &amp;ldquo;In other words, we can divide security policy rules into three categories: first, enterprise-level basic key policies, such as DNS, NTP, auditing system, etc.; second, specific policies for each project; third, under microservices, local unit services. Refinement control strategy, for example, some microservices have unique requirements, and after starting one of the microservices, it is connected to a third party, so you can configure refined items for independent microservice units. Lin Jing explained to reporters , &amp;ldquo;Because the attention of each layer of policy is different and the security roles are separated, through the layered design, it is possible to make better cooperation between traditional security personnel and modern organizational structure implementers to avoid inefficiencies. Communicate to help enterprises achieve cloud native more efficiently. &amp;quot;&lt;/p>
&lt;p>&lt;strong>From technology to talents, give full play to the existing strengths of F5&lt;/strong>&lt;/p>
&lt;p>All in all, F5 covers almost all of these capabilities, from traditional infrastructure services to upper-layer application delivery, from all-center application solutions to corresponding digital experiences. For itself, it not only penetrates into the cloud native system, but also builds a bridge between traditional architecture and cloud native architecture for enterprises. In Lin Jing&amp;rsquo;s words, F5 has regarded cloud native as a very important part of its strategic planning.&lt;/p>
&lt;p>In this process, F5&amp;rsquo;s goal is to start from four aspects: infrastructure network, application network, security and application operation, &amp;ldquo;to help enterprises build applications for better digital experience&amp;rdquo;. For example, delivering multi-cloud application capabilities such as consistent deployment, multi-cloud workload management, edge application management, modern application security, and application insight for enterprises; providing platform-level O&amp;amp;M capabilities, better service agents, service governance, and DevOps foundations At the same time, it also needs to ensure full-stack security including network, host, application and other layers.&lt;/p>
&lt;p>However, this does not mean a complete overthrow of F5&amp;rsquo;s past products, but to give new capabilities to old technologies. &amp;ldquo;For example, with the help of the F5 CRS controller technology, the traditional F5 solution technology can be introduced into the PaaS platform or modern system to help the business release better and faster.&amp;rdquo; Lin Jing said. &amp;ldquo;For another example, AI&amp;rsquo;s insights into data can also help enterprises improve the adaptive capabilities of applications, enhance the digital experience of applications, help users better manage applications on hybrid clouds and edges, and optimize and protect application security.&amp;rdquo;&lt;/p>
&lt;p>&amp;ldquo;Of course, we don&amp;rsquo;t just focus on cloud-native technologies, but also in terms of technology, culture, or talent, etc., and, based on F5&amp;rsquo;s deep understanding of traditional infrastructure, to help users truly understand the data center perspective. , do a good job of cloud native in every field.&amp;rdquo; Lin Jing concluded, &amp;ldquo;In other words, F5 is using its deep understanding of enterprises and industries to provide more and more modern and new solutions, which It is a very big advantage of F5 in the cloud-native field.&amp;rdquo; In its essence, you will find that whether it is communication control or service management, these are the original strengths of F5, but they are just switched to a new scenario. &amp;ldquo;So, for F5, we have never left, but have been cultivating.&amp;rdquo;&lt;/p></description></item><item><title>To implement cloud native, you need such an infrastructure</title><link>http://linjing.io/publication/f5-cloudnative-media-interview/</link><pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate><guid>http://linjing.io/publication/f5-cloudnative-media-interview/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>Check here for full article &lt;a href="http://soft.zhiding.cn/software_zone/2021/0929/3136583.shtml">The link&lt;/a>.&lt;/p></description></item><item><title>From load balancing to cloud native application services</title><link>http://linjing.io/post/from-lb-to-cloud-native-application-services/</link><pubDate>Tue, 20 Jul 2021 00:00:00 +0000</pubDate><guid>http://linjing.io/post/from-lb-to-cloud-native-application-services/</guid><description>&lt;h3 id="born-to-be-simpleload-balancing">Born to be simple(Load Balancing)&lt;/h3>
&lt;p>In the 1990s, the rapid development of the Internet gave birth to a large number of online websites, and the number of Web visits increased rapidly. At that time, a simple appeal was how to improve the access speed and ability of Web sites.&lt;/p>
&lt;p>At that time, in the Six Arms bar on the slopes of downtown Seattle, several young people were here every night to enthusiastically discuss their entrepreneurial dreams. They were obsessed with human-computer interfaces and studied how to break through the limits of immersive virtual reality. . Michael Almquist was one of them. He found that the servers at the time could not meet their needs, so they studied the use of load balancing to help solve the problems they encountered.&lt;/p>
&lt;p>In 1996, F5 Labs was established in a dilapidated office on the fifth floor of the Seattle Tower. Michael Almquist was the founder. Such a technology was discovered by investors, bringing F5 Labs from the field of virtual reality technology to a world that helps to achieve trouble-free and efficient Internet communication.&lt;/p>
&lt;p>Alteon and Radware were also established in the same year as F5, but these two companies had stories with each other more than ten years later. Juniper was also established this year, and has had a consistent market with F5 in the following years.&lt;/p>
&lt;p>Before the Internet bubble burst, this field basically revolved around how to load balance and optimize Web sites. Therefore, in the early days, there will be the term &amp;ldquo;Web switch&amp;rdquo;. The basic idea is to achieve greater access capabilities by distributing connections to more different servers. When one server goes down, users can still access other available servers. The core technology is Load Balancing, and some Web optimization capabilities are added. The basic technical deployment patterns are as follows:&lt;/p>
&lt;p>&lt;img src="1.png" alt="Load balancing">&lt;/p>
&lt;p>In 1997, F5 released the BIG-IP product. The earliest name of BIG-IP is actually called BIG/IP, which is derived from the name TCP/IP. BIG expresses the meaning of a super IP representing many backing service IPs. In the same year that BIG-IP was released, a company called ArrowPoint was established, mainly for web optimization.&lt;/p>
&lt;p>In 1998, F5 released the 3DNS product. On Load Balancing, DNS has always been an original technology. 3DNS products expand the concept of space (source, target) and time (availability) on top of the basic technology of DNS polling and resolution, forming three dimensions (3D), which is also 3DNS The origin of the naming was later changed to Global Traffic Management (GTM). In recent years, it was also named DNS to express a complete and comprehensive enterprise DNS architecture. We can actually see the focus of the market direction at different stages from the name change. The use of smart DNS technology has helped to further enhance the Web access experience, allowing users to access the nearest available site in time. The technical concepts used in 3DNS are still widely used today, whether it is global traffic management or enterprise basic DNS. In the same year, the industry also established two companies, uRoam and Netscaler. One was later acquired by F5, and the other was a company in the same field of F5.&lt;/p>
&lt;h3 id="success-in-adc">Success in ADC&lt;/h3>
&lt;p>The Internet bubble reached its peak in 2000, and this year was also the year when the most relevant manufacturers in this field were established. Fineground, a web optimization, application acceleration and security vendor; application front-end optimization vendor Redline; WAN optimization vendor Peribit. Application security vendor Magnifire. At the same time Array was also established this year. If we look through the information, we will find that at this stage the market will have a lot of terms about products. In addition to the &amp;ldquo;Web switches&amp;rdquo; mentioned above, there are also &amp;ldquo;content switches&amp;rdquo;, four-layer switches, and seven-layer switches. Manufacturers of different technical backgrounds are engaged in a secret struggle.&lt;/p>
&lt;p>In 2001, the U.S. stock market plummeted and the Internet company bubble burst. The business model of simply relying on simple Load Balancing for Internet Web sites is no longer sustainable. Combing the acquisitions in this field from 2000 to 2005, we can see that the market has become complicated, with a large number of manufacturers established and a large number of manufacturers acquiring:&lt;/p>
&lt;ul>
&lt;li>In 2000, Cisco acquired ArrowPoint, and Fineground, which was created in the same year, was also acquired by Cisco in 2005. Through this acquisition, Cisco finally completed the construction of its application content network (AON) technology products.&lt;/li>
&lt;li>In 2003, F5 acquired uRoam and built an APM module for SSL VPN and access identity and policy management.&lt;/li>
&lt;li>In 2004, F5 acquired Magnifire to build WAF product capabilities. That is, the current Advance WAF module.&lt;/li>
&lt;li>In 2005, F5 acquired Swan Labs to enrich the capabilities of WAN acceleration, the later WOM module.&lt;/li>
&lt;li>In 2005, Citrix acquired Netscaler, which became its later application delivery product.&lt;/li>
&lt;li>In 2005, Juniper built its application-oriented product line through the acquisition of Peribit and Redline.&lt;/li>
&lt;/ul>
&lt;p>And behind this frenzy, a standardized market area is being shaped. It can be seen from the acquisition technology direction of the above-mentioned vendors that the technology trend at the time was relatively clear, and the market was focusing on how to access applications faster and more securely, and to ensure that the applications were available for construction.&lt;/p>
&lt;p>In 2003, Gartner defined the Application Delivery Controller (ADC) concept for the first time. In the early days, the definition of ADC was still mainly a combination of load balancing technology and offloading technology, and it was Web-oriented. The latest definition is:&lt;/p>
&lt;blockquote>
&lt;p>The Application Delivery Controller (ADC) is deployed in the data center and optimizes application performance, security, and resource efficiency by offloading servers, providing in-depth payload inspection, and making full use of complex protocols. They were originally deployed for external-facing Web applications and are now used to provide services for many types of business applications and protocols.&lt;/p>
&lt;/blockquote>
&lt;p>It can be seen that later ADC products are more oriented towards the processing of complex applications in enterprises. This is why there are arguments that ADC should become a platform, which has attributes similar to middleware to help companies better deliver applications.&lt;/p>
&lt;p>The stock market crash caused companies in this field to consider shifting technology application scenarios from Internet Web sites to enterprise applications. 2002 was the most critical year for F5. This year, F5 established TMOS (Traffic Management Operating System) as the foundation of BIG-IP. This real-time event-driven traffic operating system established F5&amp;rsquo;s leading position in the application delivery network (ADN) field. The three consecutive acquisitions in 2003, 2004, and 2005 helped quickly form a complete ADC product line.&lt;/p>
&lt;p>The TMOS V9 version was released in 2004, bringing the market into a new development track. In mid-2005, Gartner announced that F5 had achieved the highest ADC market share.&lt;/p>
&lt;p>2006 is a sign of the maturity of the ADC market. The ADC technology represented by F5 has formed a de facto standard in the field. The products have formed a wealth of connection management, protocol control, SSL offloading, Web compression and optimization, traffic shaping, DoS protection, Web security, IPv6, link load, GSLB, etc. Application delivery capabilities. The technical architecture deployment is basically similar to the following figure:&lt;/p>
&lt;p>&lt;img src="2.png" alt="">&lt;/p>
&lt;p>Consolidating a mature market is not an easy task. It requires continuous investment in technology research and development to ensure competitiveness in the industry. The period from 2006 to 2008 was a period of very high growth in F5 R&amp;amp;D investment in history. Although it was during the global economic crisis, the quarter-on-year growth of R&amp;amp;D investment remained between 30%-40%.&lt;/p>
&lt;p>At this time, several large companies in the same field are disproportionate in their R&amp;amp;D investment and market revenue. Whether it is due to lack of investment or technical route issues, they eventually withdraw from the market due to lack of technical competitiveness.&lt;/p>
&lt;ul>
&lt;li>Juniper abandoned its DX product line in 2008 and announced its withdrawal&lt;/li>
&lt;li>Nortel ended in 2009, Radware acquired Alteon assets&lt;/li>
&lt;li>In 2010, Cisco stopped selling AON and ACE XML gateway products&lt;/li>
&lt;li>In 2012, Cisco officially stopped ACE research and development&lt;/li>
&lt;/ul>
&lt;p>The failure cases of Nortel, Cisco, and Juniper fully illustrate that the ADC field is a high-tech market. It requires continuous technological accumulation and continuous technological breakthroughs. For a long time, F5&amp;rsquo;s annual R&amp;amp;D investment accounts for approximately 17%-18% of its revenue, which is higher than the 15.7% average of the software and Internet industries. The annual R&amp;amp;D investment is close to 5 times the revenue of the F5 Chinese market in the same year. Continuous high R&amp;amp;D investment has ensured F5&amp;rsquo;s leading position in technology in the industry.&lt;/p>
&lt;p>It is precisely because of the maturity of ADC products that around 2009, the market once made the argument that Load Balancing was dead to emphasize that companies should attach importance to the capabilities of ADC products. F5 ADC products have rich application-oriented capabilities, such as rich and in-depth protocol control, event-based programmable architecture, connection-oriented refined management, high dynamic configuration without reload, comprehensive automation and API interfaces, and rich The observable ability. Enterprises can fully open up these capabilities and provide them to application teams and middleware teams.&lt;/p>
&lt;p>At this stage of the rapid development of ADC products, another field is also constantly developing, which is the soft load field represented by NGINX and HAproxy.&lt;/p>
&lt;p>NGINX began to develop in September 2004, and HAproxy began to develop in December 2005. The origins of these two products are similar to those of F5, and they are both developed for the actual needs of their own business. NGINX is to solve the high concurrency problem of the website, and HAproxy is to solve the problem of application session retention of the author&amp;rsquo;s own security company. Eventually evolved into today&amp;rsquo;s typical reverse proxy software.&lt;/p>
&lt;p>In terms of time, since ADC hardware products were established in 2003, soft load products have developed together with hardware ADC products. The use of soft load by cloud and top Internet companies has accelerated the application of soft load product scenarios, exposing it to the public and being understood by more people. Whether it is LVS, Tengine, Openresty, ELB, etc.&lt;/p>
&lt;p>2016 is the inflection point of the enterprise market&amp;rsquo;s perception of soft load. With the further development of enterprises&amp;rsquo; digital transformation, DevOps, dual-mode IT, elastic architecture, and enterprise private cloud, soft loads have begun to be widely mentioned and applied.&lt;/p>
&lt;p>Based on the understanding of the soft load market, F5 has released the Virtual Edition (VE) of TMOS since 2009, actively building the cloud initialization capabilities of related products, strengthening the ecological construction of DevOps tools such as Ansible/Terraform modules, etc., open command and statement -Style interface to achieve more Gitops capabilities. These capabilities allow companies to deploy F5 VE soft ADC products faster and better to meet business needs. There is an interesting number. F5 has deployed 50,000 sets of hardware devices in China in 19 years, with an average of more than 2,600 units per year. During the 2020 Spring Festival epidemic alone, it quickly helped users deploy 3000 sets of software ADCs. The advantages of easy deployment of soft loads have been greatly brought into play.&lt;/p>
&lt;p>Subsequently, in 2019, F5 acquired NGINX to further strengthen the soft load market.&lt;/p>
&lt;h3 id="back-to-simple--service-proxy">Back to Simple- Service Proxy&lt;/h3>
&lt;p>With the development of application architecture, applications are transforming from traditional monolithic applications to distributed or microservices. Whether it is a distributed or microservice architecture, its core is to split multiple services of an application to form a relatively independent service unit. The direct result of the split is that an additional mechanism is needed to ensure that these independent work units can coordinate and unified work, which is inseparable from distributed computing, storage, messaging, and so on. When these independent service units need to communicate with each other, it is necessary to think about how to make these services that communicate through the network more reliable, safer, and more optimized. This is what the field of application delivery is concerned about, but it has changed from user-oriented and network-oriented to service-oriented. We call it Service Proxy.&lt;/p>
&lt;p>Access gateways in distributed systems or API gateways for microservices are typical ADC requirements, such as identity recognition, SSL offloading, content routing, application security, current and speed limiting, DDOS, etc. These scenarios have been driven by developers for a long time. Due to the characteristics of the software, it is easier for developers to access software products like NGINX. This is a typical change in user roles compared to traditional ADC products.&lt;/p>
&lt;p>In environments such as microservices and cloud natives, the communication interface between services is simpler and more unified, which makes the technical requirements for reverse proxy software simpler, and no longer need such a complex and rich special protocol support , No longer need complex network technical characteristics requirements. What is needed is for soft load products to have more dynamic configuration, which can be linked with the registration center and configuration center to realize the discovery of services and the introduction of strategies. The products need to be lightweight and easy to deploy and suitable for virtual machines, containers, etc. The use of these scenarios requires fast enough performance, sufficient observable data, and sufficient flexible deployment capabilities.&lt;/p>
&lt;p>&lt;img src="3.png" alt="">&lt;/p>
&lt;p>(Under cloud native, it is difficult to directly see a concrete load balancer)&lt;/p>
&lt;p>Around 2017, with the development of cloud native, Service Proxy began to appear in large numbers. There are endless products around Ingress Controller, Sidecar, API Gateway, such as Linkerd, Envoy, Gloo, Mosn and so on. From traditional ADC to today&amp;rsquo;s service-centric modern lightweight decoupled Service Proxy, the technology is returning to a simple Web-oriented load balancing era, client-side load balancing or server-side load balancing.&lt;/p>
&lt;p>At the end of 2017, F5 launched Aspen Mesh, a commercial service mesh solution product based on Istio. Help users use service grid technology more reliably.&lt;/p>
&lt;p>In 2019, F5 acquired NGINX. Based on NGINX to create modern application API gateway, K8S Ingress Controller, cloud native application protection, NGINX service grid and other product solutions.&lt;/p>
&lt;p>In 2021, F5 acquired the start-up Volterra. Help enterprises realize multi-cloud and edge application management based on K8S technology.&lt;/p>
&lt;p>The launch of these products allows F5 to quickly cover the three directions of cloud-native Service Proxy development.&lt;/p>
&lt;p>&lt;img src="4.png" alt="">&lt;/p>
&lt;p>(Three directions of Service Proxy development under cloud native)&lt;/p>
&lt;h3 id="facing-the-current--enterprise-cloud-native-application-service">Facing the current- Enterprise Cloud Native Application Service&lt;/h3>
&lt;p>When we return to the actual situation of the enterprise and use a picture to express the changes in this related field, we can see that the deployment position of products in the related field is constantly improving, from basic network hardware to a cloud environment. The service component has become a logical resource object in the cloud native environment. From visible and tangible to visible and intangible, from visible and intangible to invisible and intangible. Enterprises should pay full attention to the selection of soft load products that can cover all scenarios to ensure that they can evolve their enterprise application architecture under unified technology and professional services to avoid technical risks.&lt;/p>
&lt;p>&lt;img src="5.png" alt="">&lt;/p>
&lt;p>(Load balancing, an ever-increasing position)&lt;/p>
&lt;p>Cloud native architecture is the future direction of enterprises, but the cloud native architecture of enterprises will not be achieved overnight. It must evolve slowly on top of the company&amp;rsquo;s existing IT infrastructure. In such an evolutionary process, the cloud native environment that the company is building needs to use the company&amp;rsquo;s existing infrastructure. The existing infrastructure of the enterprise must also be changed to the cloud-native environment, and the two need to be integrated with each other.&lt;/p>
&lt;p>This is true for infrastructure and so are people. With the improvement of enterprise platform-based capabilities, we can clearly see that I&amp;amp;O personnel are becoming the main force of future data center technology innovation. The leading role personnel in this field have changed from network personnel to developers, and ultimately to platform personnel.&lt;/p>
&lt;h3 id="conclusion">Conclusion&lt;/h3>
&lt;p>It can be seen that from 1996 to 2006, and then to 2016. Every 10 years of changes in the application delivery field have echoed the changes in market demand and are in line with the changes in application architecture. From simple Web load balancing to complex enterprise application delivery, from monolithic applications to distributed, microservice architecture. The target audience also ranges from network personnel to application personnel to today&amp;rsquo;s platform and infrastructure personnel. Whether it is the complexity of ADC functions or the simplicity and efficiency of Service Proxy, products in the application delivery field have become the most important infrastructure components for enterprises.&lt;/p></description></item><item><title>How an application delivery veteran see Envoy in the era of cloud native</title><link>http://linjing.io/post/f5-envoy-cloud-native/</link><pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate><guid>http://linjing.io/post/f5-envoy-cloud-native/</guid><description>&lt;h2 id="foreword">Foreword&lt;/h2>
&lt;p>Envoy, messenger, envoy, representative! Just like the meaning of the word itself, with a sense of authority, a sense of sacred full agent. Combined with its own use and role, it is really &amp;ldquo;people as their name&amp;rdquo;, can&amp;rsquo;t help but like Lyft, I don&amp;rsquo;t know which master got the name to get this name. In the current era of fiery microservices, Envoy is an absolute star, and it is no exaggeration to describe it as everyone knows. Someone once asked me how to look at Envoy and whether Envoy will replace F5 instead of NGINX in the cloud-native era. As a veteran who has experienced two waves of change in the field of application delivery technology, in this article I will talk about Envoy in the future From a perspective to understand and answer this question. Why talk a little bit, this is really not modesty, but objectively, there is really no such in-depth large-scale long-term use and research of all technical details of Envoy, so I will combine my professional experience and experience to make an Envoy Talk.&lt;/p>
&lt;h2 id="star-studded-envoy">Star-studded Envoy&lt;/h2>
&lt;p>First, let&amp;rsquo;s take a look at how Envoy officially introduced Envoy:&lt;/p>
&lt;blockquote>
&lt;p>ENVOY IS AN OPEN SOURCE EDGE AND SERVICE PROXY, DESIGNED FOR CLOUD-NATIVE APPLICATIONS&lt;/p>
&lt;/blockquote>
&lt;p>From this description on the homepage of the website, we can clearly see the official definition of Envoy, which is simply a proxy for east-west, north-south traffic in the cloud native era. Lfyt is the pioneer of the microservice application architecture. We can see Lfyt in a large number of microservice sermon articles. After a large-scale shift from monolithic applications to microservice architecture, a serious problem was placed in development. In front of the architects, on the one hand, Lyft&amp;rsquo;s services are developed in multiple languages, and the use of class libraries to solve various problems under the distributed architecture requires a lot of language adaptation and code intrusion. On the other hand, Lyft&amp;rsquo;s business Both are deployed on AWS, relying heavily on AWS&amp;rsquo; ELB and EC2, but the traffic control, insight, and problem elimination between the services provided by ELB and AWS at that time could not meet Lyft&amp;rsquo;s needs. It is based on this background, Lfyt is Envoy development started in May 2015. It was first deployed as an edge agent and began to replace ELB, and then began to be deployed as a sidecar method for large-scale deployment. On September 14, 2016, Lyft officially announced this project on its blog: Envoy C++ L7 proxy and communication bus . For a while, Envoy received a lot of attention, and companies such as Google began to contribute to this project, and donated the project to CNCF one year later in September 2017. With a good mom like Lyft, and the succession to CNCF as a rich dad, plus the half-brother Istio star brother&amp;rsquo;s blessing, it can be said that Envoy has a good scene for a while, earning enough eyeball and developer support, I graduated from CNCF in just over a year.&lt;/p>
&lt;p>Container technology has helped enterprises practice Devops and microservice transformation. The k8s container orchestration platform allows enterprises to move more business from traditional architectures to modern container-based infrastructures with more confidence. k8s solves container orchestration and applications. Issues such as publishing, but when the communication between services has changed from the previous call between memory to TCP-based network communication, the impact of the network on application services has become more huge and uncertain, based on traditional application architecture operation and maintenance The means cannot adapt and solve the huge and complex communication insights and troubleshooting between services. In order to solve such problems, the service mesh application was born and quickly became a hot topic of concern. The Istio project is the most important player in this ecosystem. Istio&amp;rsquo;s architecture is a typical management plane and data separation architecture. The choice of data plane is open, but Istio chooses Envoy as the data plane by default. The two popular stars joined forces to make Linkerd eclipsed almost at the same time. At this point in time, NGINX also briefly carried out the Nginmesh project, trying to make NGINX as the data plane of Istio, but eventually gave up at the end of 2018, why did you give up, this article will be mentioned later.&lt;/p>
&lt;p>In addition to Istio&amp;rsquo;s selection of Envoy as the data plane, there are many projects based on Envoy, such as multiple Ingress Controller projects of k8s: Gloo, Contur, Ambassador. Istio&amp;rsquo;s own Ingress gateway and Egress gateway also choose Envoy. Take a look at the Envoy users listed on their official homepage and say that starlight is not too much. Note that F5 in the list is very interesting.&lt;/p>
&lt;p>&lt;img src="envoy-endusers.jpg" alt="">
(Envoy end user list)&lt;/p>
&lt;h2 id="envoy-born-for-the-times">Envoy: born for the times&lt;/h2>
&lt;p>Below I will look at the technical aspects of why Envoy is so valued by the community. It will be summarized from the following aspects:&lt;/p>
&lt;ul>
&lt;li>Technical characteristics&lt;/li>
&lt;li>Deployment architecture&lt;/li>
&lt;li>Software Architecture&lt;/li>
&lt;/ul>
&lt;h3 id="technical-characteristics">Technical characteristics&lt;/h3>
&lt;ul>
&lt;li>Interface and API&lt;/li>
&lt;li>Dynamic&lt;/li>
&lt;li>Scalability&lt;/li>
&lt;li>Observability&lt;/li>
&lt;li>Modernity&lt;/li>
&lt;/ul>
&lt;h4 id="interface-and-api">Interface and API&lt;/h4>
&lt;p>When I first opened the configuration of Envoy, my first feeling was, God, how should such a product user configure and use. Under the intuitive experience, in an uncomplicated experimental environment, the number of lines of an Envoy&amp;rsquo;s actual configuration file actually reached 20,000 lines.&lt;/p>
&lt;pre>&lt;code># kubectl exec -it productpage-v1-7f4cc988c6-qxqjs -n istio-bookinfo -c istio-proxy -- sh
$ curl http://127.0.0.1:15000/config_dump | wc -l
% Total % Received % Xferd Average Speed Time Time Time Current
Dload Upload Total Spent Left Speed
100 634k 0 634k 0 0 10.1M 0 --:--:-- --:--:-- --:--:-- 10.1M
20550
&lt;/code>&lt;/pre>&lt;p>Although this is a dynamic configuration in the Istio environment, although there are ways to optimize it to reduce the actual configuration amount, or that we will not do such a large amount of configuration when using the static configuration method for configuration, but when we see the following actual The configuration structure output will feel that for such a software, it is obviously impractical to configure and maintain in a normal way. Its configuration is completely json structured and has a large number of descriptive configurations. Compared to NGINX and other such reverse For agent software, its configuration structure is too complicated.&lt;/p>
&lt;p>&lt;img src="envoy-json.jpg" alt="">
(Complex configuration structure)&lt;/p>
&lt;p>Obviously, Envoy&amp;rsquo;s design is not designed for manual, so Envoy designed a large number of xDS protocol interfaces, users need to design an xDS server to implement all configuration processing, Envoy supports gRPC or REST to communicate with the server to update Own configuration. xDS is the general name of the Envoy DS (discover service) protocol, which can be divided into Listener DS (LDS), Route DS (RDS), Cluster DS (CDS), Endpoint DS (EDS), and Secret DS in order to ensure consistent configuration DS-ADS of polymerization and the like, may be more xDS view here . These interfaces are used to automatically generate various specific configuration objects. It can be seen that this is a highly dynamic runtime configuration. To use it well, you must develop a server with sufficient capabilities. Obviously this is not the design thinking of traditional reverse proxy software.&lt;/p>
&lt;p>&lt;img src="envoy-xds.png" alt="">
(Picture from &lt;a href="https://gist.github.com/nikhilsuvarna/bd0aa0ef01880270c13d145c61a4af22">https://gist.github.com/nikhilsuvarna/bd0aa0ef01880270c13d145c61a4af22&lt;/a> )&lt;/p>
&lt;h4 id="dynamic">Dynamic&lt;/h4>
&lt;p>As mentioned earlier, Envoy&amp;rsquo;s configuration relies heavily on interface automation to generate various configurations. These configurations can be modified by Runtime without reloading files. In modern application architectures, the life cycle of a service endpoint becomes shorter and its operation Uncertainty or resilience has become greater, so the ability to make runtime changes to the configuration without having to reload the configuration file is particularly valuable in modern application architectures, which is an important consideration for Istio&amp;rsquo;s choice of Envoy as the data plane. Envoy also has a hot restart capability, which makes it more elegant when an upgrade or a restart is necessary, and existing connections can be protected more.&lt;/p>
&lt;p>In the Istio scenario, Envoy&amp;rsquo;s container runs two processes, one called pilot-agent and one is envoy-proxy itself. The pilot-agent is responsible for managing and starting Envoy, and generates an envoy under /etc/istio/proxy/ -rev0.json Initial configuration file, this file defines how Envoy should communicate with the pilot server to obtain the configuration, and use this configuration file to finally start the Envoy process. However, the final configuration of Envoy is not only the content in envoy-rev0.json, it contains all the dynamic configurations discovered through the xDS protocol mentioned above.&lt;/p>
&lt;pre>&lt;code># kubectl exec -it productpage-v1-7f4cc988c6-qxqjs -n istio-bookinfo -c istio-proxy -- sh
$ ps -ef
UID PID PPID C STIME TTY TIME CMD
istio-p+ 1 0 0 Jun25 ? 00:00:33 /usr/local/bin/pilot-agent proxy sidecar --domain istio-bookinfo.svc.cluster.local --serviceCluster productpage.istio-bookinfo --proxyLogLevel=warning --proxyComp
istio-p+ 14 1 0 Jun25 ? 00:05:31 /usr/local/bin/envoy -c etc/istio/proxy/envoy-rev0.json --restart-epoch 0 --drain-time-s 45 --parent-shutdown-time-s 60 --service-cluster productpage.istio-bookin
istio-p+ 142 0 0 15:38 pts/0 00:00:00 sh
istio-p+ 148 142 0 15:38 pts/0 00:00:00 ps -ef
&lt;/code>&lt;/pre>&lt;p>In the envoy overall configuration dump of the following figure, you can see that the contents of bootstrap and other static and dynamic configurations are included:&lt;/p>
&lt;p>&lt;img src="envoy-dump-config-json-struc.jpg.jpg" alt="">
(Envoy configuration structure)&lt;/p>
&lt;p>Combined with the following figure, you can see the basic Envoy configuration structure and its logic, whether it is an entrance listener (similar to F5&amp;rsquo;s VS and part of the profile configuration, NGINX&amp;rsquo;s listener and some Server paragraph configuration) or routing control logic (similar to F5 LTM policy, NGINX&amp;rsquo;s Various Locations matching, etc., or Clusters (similar to F5 pool, NGINX upstream), Endpoints (similar to F5 pool member, NGINX upstream server), and even SSL certificates can be automatically discovered from the service side through the interface&lt;/p>
&lt;p>&lt;img src="envoy-basic-objects-logic.png" alt="">
(picture (From &lt;a href="https://gist.github.com/nikhilsuvarna/bd0aa0ef01880270c13d145c61a4af22">https://gist.github.com/nikhilsuvarna/bd0aa0ef01880270c13d145c61a4af22&lt;/a> )&lt;/p>
&lt;h4 id="scalability">Scalability&lt;/h4>
&lt;p>A lot of filters can be seen in the configuration of Envoy. These are the performance of its scalability. Envoy learned the architecture of F5 and NGINX, and used a lot of plug-ins to make it easier for developers to develop. From the start of listener, it supports the use of filter, and supports developers to develop L3, L4, L7 plug-ins to achieve protocol expansion and more control.&lt;/p>
&lt;p>In practice, companies may not have as many C++ development reserves as languages ​​such as JavaScript, so Envoy also supports Lua and Webassembly extensions. This aspect eliminates the need to frequently recompile binaries and restart, and on the other hand reduces enterprise plug-in development. Difficulty, so that companies can use more Webassembly compatible languages ​​for plug-in writing, and then compile to Webassenmbly machine code to achieve efficient operation. At present, Envoy and Istio are still in the early stages of using Webassembly for expansion, and it will take some time to mature.&lt;/p>
&lt;p>&lt;img src="concept-envoy-filter.png" alt="">
(Picture from &lt;a href="https://www.servicemesher.com/istio-handbook/concepts/envoy.html">https://www.servicemesher.com/istio-handbook/concepts/envoy.html&lt;/a> )&lt;/p>
&lt;p>As can be seen from the above figure, such a request processing structure is very close to the design idea of ​​the F5 TMOS system, and is similar to NGINX to a certain extent. Connections and requests correspond to different processing components at different protocol levels and stages, and these components are themselves extensible and programmable, which in turn enables flexible programming control of the data flow.&lt;/p>
&lt;h4 id="observability">Observability&lt;/h4>
&lt;p>It is said that Envoy is born with the characteristics of cloud native. One of the characteristics is the emphasis on observability. You can see the three observable components: logs, metrics, and tracing are all supported by Envoy by default.&lt;/p>
&lt;p>Envoy allows users to define flexible log formats in flexible locations in a flexible manner. These changes can be delivered through dynamic configuration to achieve immediate effect, and allows the definition of sampling of logs. In Metrics, it provides many indicators that can be integrated with Prometheus. It is worth mentioning that Envoy allows the filter itself to expand these indicators. For example, in the filter such as current limiting or verification, the plug-in itself is allowed to define its own indicators to help users better. Use and quantify the operational status of the plugin. In terms of Tracing, Envoy supports integration with third parties such as zipkin, jaeger, datadog, lightStep, etc. Envoy can produce a uniform request ID and keep it spread throughout the network structure. It also supports external x-client-trace-id to achieve A description of the relationship topology between microservices.&lt;/p>
&lt;p>&lt;img src="envoy-kiali.jpg" alt="">&lt;/p>
&lt;p>Each span generated by Envoy contains the following data:&lt;/p>
&lt;ul>
&lt;li>Set by the &amp;ndash;service-clusteroriginal service cluster information.&lt;/li>
&lt;li>The start time and duration of the request.&lt;/li>
&lt;li>Set by the &amp;ndash;service-nodeoriginal host information.&lt;/li>
&lt;li>By x-envoy-downstream-service-clusterdownstream cluster header set.&lt;/li>
&lt;li>HTTP request URL, method, protocol and user agent.&lt;/li>
&lt;li>By custom_tagsanother custom label settings.&lt;/li>
&lt;li>The upstream cluster name and address.&lt;/li>
&lt;li>HTTP response status code.&lt;/li>
&lt;li>GRPC response status and messages (if available).&lt;/li>
&lt;li>Error flag when HTTP status is 5xx or GRPC status is not &amp;ldquo;OK&amp;rdquo;.&lt;/li>
&lt;li>Track system-specific metadata.&lt;/li>
&lt;/ul>
&lt;h4 id="modernity">Modernity&lt;/h4>
&lt;p>In fact, it is obviously correct nonsense to say that Envoy has modernity. Envoy was born for modern application architecture. Here we mainly want to explain from several aspects that we can most easily feel. The first is its special structural design. In Envoy, it supports the use of iptables to intercept the traffic and do transparent processing. It can use getsockopt () to extract the original destination information in the NAT entry, and allow listeners to listen on the listener. The transferred port listener jumps to an unbound listener that actually matches the original destination information. Although from the perspective of a reverse proxy, this is a bit like F5&amp;rsquo;s VS internal jump, NGINX&amp;rsquo;s subrequest, but its biggest feature and ability lies in transparent connection, which is especially important in the deployment Pod sidecar mode, refer to specific principles herein .&lt;/p>
&lt;p>For the gray-scale publishing, traffic mirroring, circuit breaker, global current limiting and other functions that are favorite for modern applications, its configuration is also very simple. Although F5/NGINX and other software can also accomplish similar tasks, they are native Envoy has greater advantages in terms of ease of configuration and ease of configuration.&lt;/p>
&lt;p>Another manifestation of modernity is the support of the protocol. Look at the following supported protocols. Students who are familiar with application delivery and reverse proxy software may not help but express their admiration. The support of these protocols on the other hand shows Envoy’s A feature that is more oriented towards developers and SRE.&lt;/p>
&lt;ul>
&lt;li>gRPC&lt;/li>
&lt;li>HTTP2&lt;/li>
&lt;li>MongoDB&lt;/li>
&lt;li>DynamoDB&lt;/li>
&lt;li>Redis&lt;/li>
&lt;li>Postgres&lt;/li>
&lt;li>Kafka&lt;/li>
&lt;li>Dubbo&lt;/li>
&lt;li>Thrift&lt;/li>
&lt;li>ZooKeeper&lt;/li>
&lt;li>RockeMQ&lt;/li>
&lt;/ul>
&lt;h3 id="deployment-architecture">Deployment architecture&lt;/h3>
&lt;p>After understanding the technical characteristics of Envoy, let&amp;rsquo;s look at Envoy from the perspective of deployment architecture.&lt;/p>
&lt;p>Complete Sidecar model deployment, which is the biggest deployment feature of Envoy. The communication between services is completely transformed into the communication between Envoy agents, so that many non-business functions are removed from the service code to external proxy components. Envoy is responsible for network communication control Observable with flow. It can also be deployed as a simplified sidecar, which only acts as a proxy for the inbound direction of service without additional traffic manipulation. This structure is used in the external observability based on NGINX to achieve business observability
&lt;img src="t1.jpg" alt="">&lt;/p>
&lt;p>Hub type, which is the same as the Router-mesh type concept in NGINX&amp;rsquo;s MRA. All services use a centralized Envoy to communicate. This deployment structure is generally suitable for small and medium-sized services. Service flow can be directed by adapting to service registration. To Envoy
&lt;img src="t2.jpg" alt="">&lt;/p>
&lt;p>Envoy can also be used as an Ingress edge gateway or Egress gateway. In this scenario, Envoy is generally used for Ingress controller or API gateway. You can see that many such implementations like to use Envoy as the underlying layer, such as Gloo, Ambassador, etc.
&lt;img src="t3.jpg" alt="">&lt;/p>
&lt;p>The following deployment structure should be familiar to everyone. As an Edge gateway, Envoy also deploys an additional layer of microservice gateway (or proxy platform layer)
&lt;img src="t5.jpg" alt="">&lt;/p>
&lt;p>Finally, this is to integrate all forms of Envoy deployment. This architecture may be in the middle of the process of migrating services from traditional architecture to microservice architecture
&lt;img src="t4.jpg" alt="">&lt;/p>
&lt;p>Ok, take a look at how Envoy is used in Istio
&lt;img src="t6.jpg" alt="">&lt;/p>
&lt;p>In summary, due to the cross-platform nature of Envoy, it has the same flexible deployment structure as NGINX, but in fact the deployment structure often has a strong relationship with the final configuration implementation mechanism, can the software&amp;rsquo;s ability adapt to the flexibility under this structure Implementation with simple configuration is the ultimate test. Objectively speaking, Envoy has an advantage in this respect.&lt;/p>
&lt;h3 id="software-architecture">Software Architecture&lt;/h3>
&lt;p>Envoy adopts a single-process multi-thread design structure, and the main thread is responsible for configuration updates and process signal processing. Requests are handled by multiple worker threads. In order to simplify and avoid processing complexity, a connection is always handled by one thread, which can minimize some lock operations caused by data sharing between threads. Envoy avoids state sharing between threads as much as possible, and designed the Thread Local Store mechanism for this purpose. In the log writing, the worker thread actually writes to the memory cache, and finally the file refresh thread is responsible for writing to the disk, which can improve efficiency to a certain extent. Overall, Envoy is still more focused on simplifying complexity and emphasizing flexibility, so unlike NGINX, it does not put the pursuit of performance in the first place, which can be obtained in the relevant official blog of Envoy verification.&lt;/p>
&lt;p>&lt;img src="envoy-thread.png" alt="">&lt;/p>
&lt;p>Similar to NGINX, Envoy is an asynchronous, non-blocking design, using an event-driven approach. Each thread is responsible for each listener, SO_REUSEPORT can also be used to share sockets, NGINX also has a similar mechanism.&lt;/p>
&lt;p>&lt;img src="t7.jpg" alt="">&lt;/p>
&lt;p>After the listener listens and starts processing, the connection will be processed by subsequent L3, 4, 7 and other filters according to the configuration.&lt;/p>
&lt;p>&lt;img src="envoy-arch.jpg" alt="">&lt;/p>
&lt;h2 id="f5nginx-the-sword-is-not-out">F5/NGINX: the sword is not out&lt;/h2>
&lt;p>After understanding the technical characteristics and architecture of Envoy, we return to the original point of this article. Envoy has been carrying the genes of modern application architecture from birth, does it mean that these front waves such as NGINX/F5 are out of date.&lt;/p>
&lt;p>I remember the author of NGINX, Igor, at the F5 China 520 conference to explain why NGINX is so successful. He said that he did not expect to be so successful because the reason is that he developed the right software at the right time. We know that during the period around 2003, there was still no talk about distributed architecture and microservices. At that time, the main problem to be solved was stand-alone performance. Based on this background, NGINX is strict in terms of architecture design and code quality. Demanding performance. In terms of functionality, NGINX was originally a Web Server software, L7 reverse proxy is an extension of its capabilities, and L4 proxy capabilities increase even later. In view of this background, from the perspective of modern application architecture, there are indeed some Capability is more difficult to cover. Similarly, Envoy was born and developed in the era of modern application architecture. As Envoy self-explained, it refers to a large number of existing hardware and software reverse proxy and load balancing products. From the above technical analysis, it can also be seen that Envoy has many NGINX and F5 Architectural concept, it can be said that Envoy draws many essences from mature reverse proxy products, and fully considers the needs of modern application architecture when designing, it is also a correct software at the right time.&lt;/p>
&lt;p>Under the microservices architecture, many problems have become how to control the communication and traffic insights between services. This is a typical application delivery field. As a frontier in this field, on the one hand, we must actively embrace and adapt to the new era of application architecture. On the one hand Need to innovate and continue to lead new directions. There have been two technological innovations in this field in history. The first was around 2006, when the topic of &amp;ldquo;load balancing was dead&amp;rdquo; was fired. The essence was that the market began to change at that time, and everyone was no longer satisfied with simple loads. Balanced, demand is derived from more complex scenarios such as application security, network optimization, application optimization, access control, and flow control. The concept of application delivery began to be proposed. It can be said that before 2006, the main concepts and technical directions of the market were based on The four-layer switch is the core concept of load balancing technology. Most players are traditional network manufacturers. The thinking and concepts are based on network switching. F5 is like a strange guy. The product design thinking is completely on another dimension. The TMOS V9 operating system, which has been released since 2004, has led the market since then, and no one has surpassed it for 10 years thereafter. The second technological innovation occurred around 2016. Affected by the cloud and microservices, software and lightweight became the mainstream of the market. At the same time, Devops thought means that the role of users has changed. The traditional design for network operation and maintenance personnel It began to become difficult to meet market demand. The field dominated by F5 has also undergone new changes in the market. Gartner no longer publishes magic quadrant analysis in the field of application delivery, and instead forms guidance in the way of Guide.&lt;/p>
&lt;p>&lt;img src="F5-stock.jpeg" alt="">&lt;/p>
&lt;p>Looking at the present, history is always surprisingly similar.&lt;/p>
&lt;p>The modern application architecture is developing rapidly, and a large number of applications are beginning to be micro-serviced. However, from the perspective of the overall chain of business access, Envoy cannot solve all problems, such as application security protection, complex enterprise protocols, and different needs caused by different organizational relationships. It can be seen that the application delivery products represented by F5/NGINX have also begun to actively realize product integration under the Devops tide. F5 has released a complete automated tool chain, from the product’s bootstrap to network configuration, to application service configuration, to the final Monitoring and telemetry have formed a complete interface, and use declarative interface to promote product management to a higher role crowd and management system. NGINX also builds its own API and Controller plane, and provides a declarative API interface to the outside world. Developers can better use the interface to integrate into their own control plane. These changes are for developers or SRE to better use F5/NGINX. For details, please refer to my &amp;ldquo;From Traditional ADC to Cloud Native ADC&amp;rdquo; &lt;a href="https://mp.weixin.qq.com/s?src=11&amp;amp;timestamp=1593224168&amp;amp;ver=2425&amp;amp;signature=znUdlLDdpbGGxWX7pZhH2uSVq1SAdQuloO09HIXssdQ15nRtWVOIgzlYTFmjOIUsDrqghPbSZM6vQI45TIqmINQKjposI7AfJ6jKQaEXm9KD4tEV5Bk9AF0RGuKvVuHI&amp;amp;new=1">series of articles&lt;/a>.&lt;/p>
&lt;p>&lt;img src="slides-3.jpg" alt="">&lt;/p>
&lt;p>After acquiring NGINX and Shape, F5 put forward a new view that will make full use of the widely accessible data plane capabilities, and use AI to further tap the data potential to help users better grasp and understand application behavior and performance, and provide references for business operations. , And feedback to component configuration and operation management to form a closed loop.&lt;/p>
&lt;p>An important scenario for modern application delivery is still indispensable, that is, application security. Although Istio and other products have made many attempts in secure communication, identity, and strategy, application security itself is relatively lacking. F5 is a leading manufacturer in the field of WAF security Through the transfer of security capabilities to NGINX, a new NGINX APP Protect is formed, which uses its cross-platform capabilities to help users better manage application security capabilities in microservice scenarios and help enterprises better implement DevSecOps.&lt;/p>
&lt;p>If we compare the technical features of Envoy with F5, we can see that F5 lacks scalability and modernity to a certain extent. F5 has good programming control capabilities, but it is relatively larger than the development of larger plug-ins. Insufficient, this and modernity can often be linked together. For example, if you want to make a complex 7-layer filter similar to Envoy for a very new protocol, it is impossible to achieve, although iRule or iRuleLX can do something to a certain extent. However, in any case, the final product form of F5 itself determines that F5&amp;rsquo;s BIGIP cannot be completely cross-platform, because it cannot run as a container. It is worth expecting that such morphological restrictions will be broken by F5&amp;rsquo;s next-generation TMOS system.&lt;/p>
&lt;p>Service Mesh is the current popular technology direction. F5 builds an enterprise-level Aspen Mesh service mesh product based on Istio, which helps enterprises deploy and use Istio better and easier. Aspen mesh team members enter the Istio Technical Oversight Committee with only 7 positions and are responsible for the important responsibilities of Istio&amp;rsquo;s RFCs/Designs/APIs. Although Istio has absolute ecology and popularity in the field of service mesh, this does not mean that Istio is the only choice. In many cases, customers may want to adopt a more concise Service Mesh to achieve most of the required functions instead of deploying one. The entire complex Istio solution, NGINX Service Mesh (NSM) based on NGINX components will bring new choices to users, a more simple and easy to use Service Mesh product, this is the reason why we mentioned NGINX to terminate Nginmesh at the beginning of the article .&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>Technology development is an inevitable process. In 2006, it evolved from traditional load balancing technology to application delivery. In addition to load balancing, it introduced many aspects such as security, access control, access control, and flow control. Around 2016, new technological changes have occurred in this field again. The emergence of a large number of new generation reverse proxy open source software has a new impact on traditional application delivery products. Active adaptation and change and innovation are the key to winning. Envoy has excellent capabilities as a new representative, but it is not a silver bullet to solve all problems. Envoy has a steeper learning curve and higher development and maintenance costs. For enterprises, they should choose the appropriate solution and Products to solve different problems in the architecture, to avoid catching the trend and let yourself fall into the trap.&lt;/p>
&lt;p>F5 needs more to let developers understand the huge potential of TMOS system (especially the subversion of the next generation products in architecture and form), understand its excellent all-agent architecture and program control at any level, so that developers, SRE develops with F5 TMOS as a capability platform and middleware, and better utilizes F5&amp;rsquo;s own application delivery capabilities to quickly realize its own needs.&lt;/p>
&lt;p>Finally, again quote a sentence from the homepage of the official Envoy website:&lt;/p>
&lt;blockquote>
&lt;p>As microservice practitioners soon realized, most of the operational problems that arise when moving to a distributed architecture are ultimately based on two aspects: network and observability.&lt;/p>
&lt;/blockquote>
&lt;p>And to ensure more reliable network delivery and better observability is the strength of Qianlang. Innovate, Qianlang.&lt;/p>
&lt;p>Written at the end: No matter how the technology changes, the human factor is still the core, regardless of the company or the manufacturer, in such a wave of technology, it should have sufficient technical reserves, just like the traditional financial industry through the establishment of technology companies to seek transformation, Manufacturers also need to be transformed. F5 China&amp;rsquo;s SE has almost 100% passed the CKA certification. Regardless of the relative proportion or absolute number, it should be unique in the industry. The transformation is not only in products, but also in thinking.&lt;/p>
&lt;p>Check more istio practice detail at my tech blog &lt;a href="https://imesh.club">https://imesh.club&lt;/a>&lt;/p></description></item><item><title>What changes does envoy bring to ADN</title><link>http://linjing.io/publication/envoy-2020-6/</link><pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate><guid>http://linjing.io/publication/envoy-2020-6/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>Check here for full article &lt;a href="https://www.servicemesher.com/blog/thoughts-to-envoy-from-adn-perspective/">The link&lt;/a>.&lt;/p></description></item><item><title>F5 BIG-IP links Istio to enhance ingress service capabilities</title><link>http://linjing.io/post/f5-istio-work-together/</link><pubDate>Mon, 22 Jun 2020 00:00:00 +0000</pubDate><guid>http://linjing.io/post/f5-istio-work-together/</guid><description>&lt;p>In the Istio system, in order to ensure the unity of policy coordination and experience, users will consider using Istio&amp;rsquo;s own Ingressgateway as the entrance to north-south traffic. Ingressgateway is generally deployed by deployment of multiple pods, scattered on multiple nodes of the cluster, depending on Due to the specific exposure type, especially in on-prem deployment, it is still necessary to deploy relevant load balancers outside the k8s cluster to load balance these ingressgateways, on the one hand, it can avoid access difficulties and operation and maintenance difficulties caused by multiple entrances. On the other hand, the high-performance and high-reliability F5 BIGIP can provide more function control and security value-added services for k8s cluster entrance traffic, which is similar to the Ingress controller.&lt;/p>
&lt;p>Unlike exposing ordinary service svc to external BIG-IP, ingressgateway itself is a collection point of various service ports. It may itself listen to many ports, so it is not easy to treat ingressgateway as a single ordinary svc. This article mainly explains how to combine Istio ingressgateway with BIG-IP to enhance the entrance business capability.&lt;/p>
&lt;p>The possible methods on the network structure are:&lt;/p>
&lt;p>External load balancer &amp;mdash; access to &amp;ndash;&amp;gt; ingressgateway&amp;rsquo;s nodeport port&lt;/p>
&lt;p>External load balancer &amp;mdash; access to &amp;ndash;&amp;gt; ingressgateway direct endpoints port (direct to pod)&lt;/p>
&lt;p>From the point of view of performance, it is naturally the second direct pod method mentioned above that has better performance, depending on the network model of the k8s cluster. If the external and pod can be directly routed or the two-layer direct connection is naturally the easiest, if it cannot be directly routed, it needs to be based on vxlan and other tunnels to achieve pod direct. F5 BIGIP supports Layer 2 direct, dynamic routing or vxlan tunnel mode. Refer to this article for detailed network deployment structure , or search for related articles in this blog. In the following, we assume that F5 BIGIP has implemented vxlan with k8s cluster, which can reach the pod directly. The final data path is as follows:&lt;/p>
&lt;p>&lt;strong>client&amp;ndash;&amp;gt;F5BIGIP&amp;ndash;&amp;gt;Istio ingressgateway pod&amp;ndash;&amp;gt;endpoints&lt;/strong>&lt;/p>
&lt;p>The underlying implementation of Istio Ingressgateway is envoy. When we publish a service to Ingressgateway through Gateway+VirtualService resource, Ingressgateway will listen to the port specified in Gateway. Therefore, once a new service is released, there may be a new listening port. However, when we deploy the ingressgateway pod, we will not configure all the external mappings in advance. That is to say, the port that the container in the pod listens to is not configured in the deployment of the pod. Don’t worry, it can be directly accessed at this time. This listening port on the pod, although the deployment port is not specified in advance.&lt;/p>
&lt;p>So how to load balance for Ingressgateway through BIGIP and dynamically discover these new monitoring services? The answer is naturally the solution described in this article. F5 BIGIP provides a controller that runs inside k8s and automatically pushes these changes to BIGIP. on. Since the same k8s svc contains one more port, you need to pay attention to the servicePort parameter when publishing this k8s svc to F5. The specific publishing process refers to the following steps:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Deploy Istio Gateway+VirtualService resources&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Edit the k8s svc corresponding to the existing Ingressgateway and add new port and target port configurations&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Configure a new F5 configmap resource and specify the corresponding servicePort to publish the new service&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="demo">DEMO:&lt;/h2>
&lt;ol>
&lt;li>First check the existing Ingressgateway pod ports are as follows, port 32400 is not exposed in the container port&lt;/li>
&lt;/ol>
&lt;pre>&lt;code> name: istio-proxy
ports:
- containerPort: 15020
protocol: TCP
- containerPort: 8080
protocol: TCP
- containerPort: 8443
protocol: TCP
- containerPort: 31400
protocol: TCP
- containerPort: 15443
protocol: TCP
- containerPort: 15011
protocol: TCP
- containerPort: 15012
protocol: TCP
- containerPort: 8060
protocol: TCP
- containerPort: 853
protocol: TCP
- containerPort: 15090
name: http-envoy-prom
protocol: TCP
&lt;/code>&lt;/pre>&lt;ol start="2">
&lt;li>Deploy Istio Gateway and VirtualService&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
name: tcp-echo-gateway
spec:
selector:
istio: ingressgateway
servers:
- port:
number: 32400
name: tcp
protocol: TCP
hosts:
- &amp;quot;*&amp;quot;
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
name: tcp-echo-destination
spec:
host: tcp-echo
subsets:
- name: v1
labels:
version: v1
- name: v2
labels:
version: v2
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
name: tcp-echo
spec:
hosts:
- &amp;quot;*&amp;quot;
gateways:
- tcp-echo-gateway
tcp:
- match:
- port: 32400 ###########32400端口监听
route:
- destination:
host: tcp-echo
port:
number: 9000
subset: v1
&lt;/code>&lt;/pre>&lt;ol start="3">
&lt;li>After the deployment is complete, check envoy to confirm that the monitoring has been issued&lt;/li>
&lt;/ol>
&lt;pre>&lt;code> {
&amp;quot;name&amp;quot;: &amp;quot;0.0.0.0_32400&amp;quot;,
&amp;quot;address&amp;quot;: {
&amp;quot;socketAddress&amp;quot;: {
&amp;quot;address&amp;quot;: &amp;quot;0.0.0.0&amp;quot;,
&amp;quot;portValue&amp;quot;: 32400
}
},
&amp;quot;filterChains&amp;quot;: &amp;amp;#91;
{
&amp;quot;filters&amp;quot;: &amp;amp;#91;
。。。。。。。。。。省略。。。。。。。。。。
{
&amp;quot;name&amp;quot;: &amp;quot;envoy.tcp_proxy&amp;quot;,
&amp;quot;typedConfig&amp;quot;: {
&amp;quot;@type&amp;quot;:
。。。。。
&amp;quot;cluster&amp;quot;: &amp;quot;outbound|9000|v1|tcp-echo.istio-io-tcp-traffic-shifting.svc.cluster.local&amp;quot;,
。。。。。
}
}
]
}
],
&amp;quot;trafficDirection&amp;quot;: &amp;quot;OUTBOUND&amp;quot;
},
&lt;/code>&lt;/pre>&lt;ol start="4">
&lt;li>Modify the existing Ingressgateway svc, increase the external exposure of 32400 port&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>kubectl edit svc istio-ingressgateway -n istio-system -o yaml
修改前：
ports:
- name: status-port
nodePort: 31702
port: 15020
protocol: TCP
targetPort: 15020
- name: http2
nodePort: 31547
port: 80
protocol: TCP
targetPort: 8080
- name: https
nodePort: 31956
port: 443
protocol: TCP
targetPort: 8443
- name: tcp
nodePort: 30775
port: 31400
protocol: TCP
targetPort: 31400
- name: tls
nodePort: 30536
port: 15443
protocol: TCP
targetPort: 15443
selector:
app: istio-ingressgateway
istio: ingressgateway
sessionAffinity: None
type: LoadBalancer
修改后：
ports:
- name: status-port
nodePort: 31702
port: 15020
protocol: TCP
targetPort: 15020
- name: http2
nodePort: 31547
port: 80
protocol: TCP
targetPort: 8080
- name: https
nodePort: 31956
port: 443
protocol: TCP
targetPort: 8443
- name: tcp
nodePort: 30775
port: 31400
protocol: TCP
targetPort: 31400
- name: tcp2
nodePort: 30776
port: 32400
protocol: TCP
targetPort: 32400 #########新增端口
- name: tls
nodePort: 30536
port: 15443
protocol: TCP
targetPort: 15443
root@k8s-master-v1-16 ~]# kubectl get svc -n istio-system
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE
grafana ClusterIP 10.96.165.101 &amp;amp;lt;none&amp;gt; 3000/TCP 2d
istio-egressgateway ClusterIP 10.110.88.185 &amp;amp;lt;none&amp;gt; 80/TCP,443/TCP,15443/TCP 2d
istio-ingressgateway LoadBalancer 10.96.122.225 &amp;amp;lt;pending&amp;gt; 15020:31702/TCP,80:31547/TCP,443:31956/TCP,31400:30775/TCP,32400:30776/TCP,15443:30536/TCP 2d
istiod ClusterIP 10.102.252.88 &amp;amp;lt;none&amp;gt; 15010/TCP,15012/TCP,443/TCP,15014/TCP,53/UDP,853/TCP 2d
jaeger-agent ClusterIP None &amp;amp;lt;none&amp;gt; 5775/UDP,6831/UDP,6832/UDP 2d
jaeger-collector ClusterIP 10.105.130.171 &amp;amp;lt;none&amp;gt; 14267/TCP,14268/TCP,14250/TCP 2d
jaeger-collector-headless ClusterIP None &amp;amp;lt;none&amp;gt; 14250/TCP 2d
jaeger-query ClusterIP 10.99.139.251 &amp;amp;lt;none&amp;gt; 16686/TCP 2d
kiali ClusterIP 10.101.189.237 &amp;amp;lt;none&amp;gt; 20001/TCP 2d
prometheus ClusterIP 10.109.157.108 &amp;amp;lt;none&amp;gt; 9090/TCP 2d
tracing ClusterIP 10.101.62.56 &amp;amp;lt;none&amp;gt; 80/TCP 2d
zipkin ClusterIP 10.98.181.246 &amp;amp;lt;none&amp;gt; 9411/TCP
&lt;/code>&lt;/pre>&lt;ol start="5">
&lt;li>Publish the 32400 servicePort to F5, at this time you need to add an F5 configmap, pay attention to the Chinese comments&lt;/li>
&lt;/ol>
&lt;pre>&lt;code>kind: ConfigMap
apiVersion: v1
metadata:
name: istio-ingressgateway.32400.vs
namespace: istio-system
labels:
f5type: virtual-server
data:
# See the f5-schema table for schema-controller compatibility
# https://clouddocs.f5.com/containers/latest/releases_and_versioning.html#f5-schema
schema: &amp;quot;f5schemadb://bigip-virtual-server_v0.1.7.json&amp;quot;
data: |
{
&amp;quot;virtualServer&amp;quot;: {
&amp;quot;backend&amp;quot;: {
&amp;quot;serviceName&amp;quot;: &amp;quot;istio-ingressgateway&amp;quot;,
&amp;quot;servicePort&amp;quot;: 32400
####It is important here. The port of the corresponding k8s svc is filled in here. The F5 CIS controller will automatically find the targetPort (CIS cluster mode) or nodeport (CIS nodeport mode) corresponding to the servicePort
},
&amp;quot;frontend&amp;quot;: {
&amp;quot;virtualAddress&amp;quot;: {
&amp;quot;port&amp;quot;: 31400,
&amp;quot;bindAddr&amp;quot;: &amp;quot;172.16.100.195&amp;quot;
},
&amp;quot;partition&amp;quot;: &amp;quot;k8s&amp;quot;,
&amp;quot;balance&amp;quot;: &amp;quot;least-connections-member&amp;quot;,
&amp;quot;mode&amp;quot;: &amp;quot;tcp&amp;quot;
}
}
}
&lt;/code>&lt;/pre>&lt;p>F5 will automatically generate the following configuration in the red box:&lt;/p>
&lt;p>&lt;img src="https://imesh.club/upload/2020/06/1592839169293-1024x418.jpg?v=1592839202" alt="F5 will automatically generate the following configuration in the red box:">&lt;/p>
&lt;p>Simulate access to the business from the outside, you can see that it can be accessed normally&lt;/p>
&lt;pre>&lt;code># jlin @ Mac in ~ &amp;amp;#91;myf5.net]
$ for i in {1..2000}; do (date; sleep 1) | nc istiobookinfo.lab.f5se.io 32400; done
one Mon Jun 22 22:24:17 CST 2020
one Mon Jun 22 22:24:18 CST 2020
one Mon Jun 22 22:24:19 CST 2020
&lt;/code>&lt;/pre>&lt;p>At this point, the newly released service monitor on Istio Ingressgateway is successfully automatically posted to BIGIP. Users only need to access BIGIP&amp;rsquo;s VS to access services within k8s (on Istio Ingressgateway).&lt;/p>
&lt;p>For the subsequent release of other new port services, repeat the above steps.&lt;/p>
&lt;blockquote>
&lt;p>Note: The above configuration uses the non-F5 AS3 configmap configuration method, if you are using CIS 2.0, you need to pay attention to this issue
&lt;a href="https://github.com/F5Networks/k8s-bigip-ctlr/issues/1341">https://github.com/F5Networks/k8s-bigip-ctlr/issues/1341&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Check more istio practice detail at my tech blog &lt;a href="https://imesh.club">https://imesh.club&lt;/a>&lt;/p></description></item><item><title>From legacy ADC to cloud native ADC series</title><link>http://linjing.io/publication/f5-cloudnative-adc-2019/</link><pubDate>Mon, 26 Aug 2019 00:00:00 +0000</pubDate><guid>http://linjing.io/publication/f5-cloudnative-adc-2019/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>The serials include:&lt;/p>
&lt;ul>
&lt;li>Opening ………… What is ADC&lt;/li>
&lt;li>Chapter 1 ………… Cloud Native Introduction&lt;/li>
&lt;li>Chapter 2 ………… Financial Industry and Cloud Native&lt;/li>
&lt;li>Chapter 3 ………… F5/Nginx and Cloud Native&lt;/li>
&lt;li>Chapter 4 ………… Cloud Native ADC&lt;/li>
&lt;li>Chapter 5 ………… PaaS platform services exposed&lt;/li>
&lt;li>Chapter 6 ………… Service Mesh&lt;/li>
&lt;li>Chapter 7 ………… API priority&lt;/li>
&lt;li>Chapter 8 ………… Cloud-Ready&amp;rsquo;s first step towards cloud native&lt;/li>
&lt;/ul>
&lt;p>Check here for full article &lt;a href="https://mp.weixin.qq.com/s?src=11&amp;amp;timestamp=1593747903&amp;amp;ver=2437&amp;amp;signature=leiJvKEmHTvn*yyw6bL07z82bZgQhGOCnagUwEu19mrUmVTYvzumj8dBZIs-oa2PXl6JKtgWuV9f6e0x3Pm6x4cI05D53WhNlEBeEp6yzVj7rxqacvebvYrEuYx2PMGy&amp;amp;new=1">The link&lt;/a>.&lt;/p></description></item><item><title>Viewing the construction of cloud native from the perspective of application delivery</title><link>http://linjing.io/publication/f5-cloudnative-adc-2019-infoq/</link><pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate><guid>http://linjing.io/publication/f5-cloudnative-adc-2019-infoq/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>Check here for full article &lt;a href="https://mp.weixin.qq.com/s?src=11&amp;amp;timestamp=1593747903&amp;amp;ver=2437&amp;amp;signature=NMKNJY7DgRaQ96uW56ThcIWUIbCE6cmgl*31qXOkJlL2uf2BNnje7nb2JEmDWL7Qe59oB7G48iAPu3tUEqEh7Lqoi1ukoA*uyq-7kjp0*W9rwv777OcGywyn6VV4vIip&amp;amp;new=1">The link&lt;/a>.&lt;/p></description></item></channel></rss>