[{"authors":["admin"],"categories":null,"content":"It has been 17+ years I focus on the industry of application delivery. Initially, I was site engineer to support big banking customers, got lots of practice during there. The experience of 4 years F5 support (TAC) let me know how to handle complicated issues, people, or technical case. I am familiar with K8s, Docker, service mesh, NGINX, Ansible, DNS, HTTP, SSL, TCP, UDP, WAF, Load balance, Identity Access Management, CDN, Web Accelerator, TCL programming. I like to dig the root of cause when I immerse in troubleshooting.\nAfter the TAC role, I moved to F5 APAC consulting team, I am the first one consultant in GCG.As a consultant, I delivered complicate post-sale and pre-sales projects for APAC customers. Appreciate the 4 years’ experience, I am better on time/project management and communications.\nI decided to take challenge again, so I became the first one Specialist System Engineer in GCG, This is a role that need strong hands-on, pre-sale experience, wide domains knowledge and be innovative. During the role I designed the biggest IPV4/6 smart and secure DNS architecture for the biggest bank in China, delivered the first production level F5 PaaS solution. 3 years ago, I promoted as F5 Solution Architect, and now I am senior solution architect, focus on F5 modern App relevant solutions and business.\nI have strong self-learning ability, keep passion to new technology. Also, I am blog enthusiast, keep writing blogs in the past 16 years (https://cnadn.net).\nI am familiar with private cloud like openstack/SDN,Vmware. Also good on docker, k8s. I got the Open Group TOGAF v9.2 certificate and I am CNCF Certified Kubernetes Administrator (CKA #664), own CCNP/MCSE/JNCIS certificates. After F5 acquiring NGINX, I built NGINX Accreditation exam process and questions. I am also the first one F5 certified security solution expert in China. Beside those, I am also interested to open source technology like service mesh(Istio, envoy),observability(ELK, Prometheus, Grafana) etc.\nI am the first author of the book- NGINX Classic Tutorial. I am good for talks on events or media. I am Cloud Native advocate and is a member of kube-ovn Community Steering Committee.\nI believe no pain no gain. There is no short path to success. Moving forward and just do it, Never give up.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1735210820,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"http://linjing.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"It has been 17+ years I focus on the industry of application delivery. Initially, I was site engineer to support big banking customers, got lots of practice during there. The experience of 4 years F5 support (TAC) let me know how to handle complicated issues, people, or technical case. I am familiar with K8s, Docker, service mesh, NGINX, Ansible, DNS, HTTP, SSL, TCP, UDP, WAF, Load balance, Identity Access Management,","tags":null,"title":"Jing Lin (林静)","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026#34;Courses\u0026#34; url = \u0026#34;courses/\u0026#34; weight = 50 Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026#34;Docs\u0026#34; url = \u0026#34;docs/\u0026#34; weight = 50 Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1735210820,"objectID":"01d39688af48040d7111d20c6b01d10b","permalink":"http://linjing.io/courses/example.1/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example.1/","section":"courses","summary":"Learn how to use Academia's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview 2","type":"docs"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026#34;Courses\u0026#34; url = \u0026#34;courses/\u0026#34; weight = 50 Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026#34;Docs\u0026#34; url = \u0026#34;docs/\u0026#34; weight = 50 Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1735210820,"objectID":"970b63766f241ba034ef2d1838dad4b3","permalink":"http://linjing.io/courses/example.2/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example.2/","section":"courses","summary":"Learn how to use Academia's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview 3","type":"docs"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026#34;Courses\u0026#34; url = \u0026#34;courses/\u0026#34; weight = 50 Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026#34;Docs\u0026#34; url = \u0026#34;docs/\u0026#34; weight = 50 Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1735210820,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"http://linjing.io/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academia's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academia:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"http://linjing.io/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academia:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academia:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"883c5cf2007b50b720ce5f4a17b72261","permalink":"http://linjing.io/courses/example.1/example3/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example.1/example3/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academia:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academia:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"32df3afea9008eacfc678398fd6443ad","permalink":"http://linjing.io/courses/example.2/example3/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example.2/example3/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academia:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with academia:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"ae73c2dafb9eed90c8870cdf783e948c","permalink":"http://linjing.io/courses/example.2/example4/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example.2/example4/","section":"courses","summary":"Here are some more tips for getting started with academia:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with academia:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"http://linjing.io/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with academia:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with academia:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"507e4cd2746d8b7ea0b6ed4a42cb4462","permalink":"http://linjing.io/courses/example.1/example4/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example.1/example4/","section":"courses","summary":"Here are some more tips for getting started with academia:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":["Jing Lin(林静)"],"categories":[],"content":"Name Product Name: BIG-IP Kubernetes Gateway Controller\nCode Name: bigip-kubernetes-gateway\nDescription Gateway API is an open source project managed by the SIG-NETWORK community. It is a collection of resources that model service networking in Kubernetes. These resources - GatewayClass,Gateway, HTTPRoute, TCPRoute, Service, etc - aim to evolve Kubernetes service networking through expressive, extensible, and role-oriented interfaces that are implemented by many vendors and have broad industry support.\nF5 BIG-IP kubernetes Gateway is an implementation of Kubernetes Gateway API. It uses F5 BIG-IP as the downstream implementation and integration.\nSee https://gateway-api.f5se.io for more information.\nSource code repository: https://github.com/f5devcentral/bigip-kubernetes-gateway.\nQuick view BIG-IP Kubernetes Gatewway enables the conversion of GatewayAPI resources to BIG-IP ADC capabilities automatically:\n\nCode Github f5devcentral\nInstallation The installation process is simple, see https://gateway-api.f5se.io/quick-start/ for details.\nUsage As the quick getstart, see https://gateway-api.f5se.io/Use-Cases/simple-gateway/.\nSupport For support, please open a GitHub issue. Note, the code in this repository is community supported and is not supported by F5.\nMaintenance and F5 Technical Support of this F5 code is provided only if the software (i) is unmodified; and (ii) has been marked as F5 Supported in SOL80012344, (https://support.f5.com/csp/article/K80012344).\nSupport will only be provided to customers who have an existing BIG-IP support contract associated with a valid BIG-IP serial number. For information about support policies, see http://www.f5.com/about/guidelines-policies/ and http://askf5.com.\nRoadmap The bigip-kubernetes-gateway versions are released on dockerhub as Docker images.\nFor a list of supported Gateway API resources and features, see the Gateway API Compatibility doc. Check here for Gateway API\u0026rsquo;s latest status.\nContributing We are open to contributions, if\n you are interested in participating in our project and you have experience in kubernetes and golang development, BIG-IP related applications or development experience is preferred.  Authors and acknowledgment Contributors for now：\n zongzw f5zong Niklaus-xie myf5 Jing Lin  ","date":1675036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"595a4179a05b0bae155265d3c2abf70a","permalink":"http://linjing.io/post/big-ip-gateway-api/","publishdate":"2023-01-30T00:00:00Z","relpermalink":"/post/big-ip-gateway-api/","section":"post","summary":"F5 BIG-IP kubernetes Gateway is an implementation of Kubernetes Gateway API. It uses F5 BIG-IP as the downstream implementation and integration.","tags":["F5","k8s","gateway api"],"title":"Project- BIG-IP K8S Gateway API","type":"post"},{"authors":["Jing Lin"],"categories":null,"content":"","date":1669907430,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"00b9208d9c67e812875704904968a087","permalink":"http://linjing.io/talk/nginx-sprint-gateway-api/","publishdate":"2023-02-03T00:00:00Z","relpermalink":"/talk/nginx-sprint-gateway-api/","section":"talk","summary":"What,Why,How and Demos. Understand Gateway API from this session.","tags":["NGINX","Gateway API","F5","BIG-IP Gateway API","feature"],"title":"NGINX Gateway API","type":"talk"},{"authors":["Jing Lin(林静)"],"categories":[],"content":"Why Egress Traffic Policy Control According to the 2021 CNCF survey, the proportion of users who use Kubernetes (K8s) in the production environment has reached 59.77%, and the number of European users has reached 68.98%. More and more users are migrating production services to the Kubernetes environment. Gartner 2021 Hype Cycle for Cloud Security also shows that container and Kubernetes security is already in the \u0026ldquo;slope of Enlightenment\u0026rdquo; stage. This shows that protecting application services in Kubernetes is becoming more and more important.\nWhen we look at a large number of microservices running in Kubernetes, we can see that microservice security has the characteristics of typical micro-boundaries and need continuous security engineering. We need consider each microservice as a boundary and protect it, whether runtime, or north-south and east-west traffic. It is necessary for each microservice to start security considerations at the beginning of coding, and to move security to the left. Security methods, and policies should be adapted to developers and Kubernetes platform operators. It also requires the ability to gain insight into all traffic, collect all runtime logs, events and other data, analyze these data through a continuous security engineering system, aggregate rules and feed them back into security policy settings.\nThe microservices in Kubernetes will not only run closed inside the cluster, it needs to access applications, databases, third-party API services, Internet services, etc. outside the cluster. The outgoing traffic may include the business traffic, open source component update traffic, or even traffic from the compromised application to the C2. Therefore, it is necessary to actively control the egress traffic of microservices in Kubernetes to ensure its security and compliance. Under the digital transformation driven by cloud-native architecture, enterprises will adopt a large number of open source technologies, which may be the easiest place to introduce security risks. Regardless of whether there is a clear open source whitelist mechanism, enterprises should pay enough attention to these open source technologies. These open source may take the initiative to visit the outside, we need control it well, and ensure safety.\nManaging outbound traffic policies in Kubernetes, a seemingly simple requirement, actually is not an easy task to do well. This article will analyze the challenges of Kubernetes outbound policies with you, analyze the advantages and disadvantages of current common solutions, and think about how enterprises should manage and control Kubernetes egress traffic policies.\nExisting challenges Dynamic From a technical point of view, this is the first challenge that exists. In a Kubernetes environment, the pods of the microservice will be highly dynamic and decentralized. IPs, network segments and physical locations will change over time. Therefore, it will be impossible to directly use IP and other characteristics for static policy setting. The strategy must rely on other abstract application labels, service names or namespaces, etc., and can dynamically perceive changes.\nGranularity In a traditional application environment, the management and control of an application\u0026rsquo;s outbound traffic policy generally only requires policy setting for a small number of deployments involved in the application. However, in the environment of microservices and containerization, an application may be composed of many microservices, and a microservice contains many pods. Different microservice units will require different outbound policy rules. For example, payment needs to connect to a third-party interface, while the comment service does not need to actively access third-party services. This means that the granularity of policy setting needs to be fine-grained to each microservice unit and ensure that all relevant pods are controlled. It can be seen that the policy control granularity is finer, the workload is larger, and the complexity is higher.\nCollaboration When we want to deploy egress policies for different microservice, who should be responsible for this, the application development department? Application operation and maintenance department? PlatformOps division of Kubernetes? Or the security department? When we look at this with a security-left shift, it is obvious that the application department should consider whether his microservices need to actively access which external services. However, if the application developer is in charge, can the platform or security department just let it go? Obviously not, application developers set up security policies for the applications they are responsible for. Global basic security policies setting, and how to quickly remedy the wrong policies set by application developers, These still need to be taken care of by other teams. In order for the development department to practice the idea of security shift left, Platform ops team or the security department must provide friendly tools and integrate the security policy setting into the DevSecOps pipeline. If the tools or methods lead to a decline in development efficiency, developers will not be happy to use it. Therefore, this is not the independent work of a certain department, it requires the cooperation of multiple teams/departments to ensure safety.\nData driven As stated at the beginning of the article, security is a continuous engineering effort, meaning that any outgoing access behavior and events should be logged into the security engineering system for analysis to ensure adequate visibility and insight. Egress security control is not only a simple policy setting, but also requires the ability to output complete logs, behaviors, and events.\nIndustry solution analysis Next, we will analyze the current industry solutions for egress policy control one by one. First, we will divide them into 6 categories of solutions, and then analyze them one by one:\n   **Category ** **Solutions or products ** **Description **     Platform based Kubernetes Network policy Openshift EgressIP Openshift Egress Router pod Openshift Egress Firewall Openshift EgressNetworkPolicy A specific feature of a platform provider   CNI based Calico Egress pod Calico Enhanced Network policy Cilium Enhanced Network policy Kube-ovn The capability of CNI   Service Mesh NGINX Service Mesh Istio A function of Service Mesh   Micro segmentation PrismaNeu Vector From ZTA perspective or use enforcer container to control egress   Fusion F5 CES(Container Egress Service) Fortinet Use k8s native method to integrate exist security assets to k8s   Others DNS interception Proxy pod Intercept coredns or use a proxy pod as forward proxy    Platform based The Network policy that comes with Kubernetes is the easiest way to think about egress security policy control. It is the native ability of K8s, which has natural affinity for developers or PlatformOps personnel, and can well adapt to the idea of security left shift. But Network policy needs CNI support. Some other disadvantages are:\n No cluster global policy capability, independent policies must be maintained under different namespaces No selection capability based on k8s svc name (can be changed to use pod label, but inflexible) No explicit rejection ability, through the isolation characteristics of the policy, and then impose a specific whitelist Rules without priority concept No dedicate external access rule type, external target services can only rely on broad ipblock pure four-layer, no seven-layer control capability No policy execution debugging capability No policy execution log The \u0026ldquo;isolation\u0026rdquo; feature of Networkpolicy makes maintenance very troublesome. For example, it only wants to control its access to the Internet, but because of isolation, additional maintenance is required All outbound (east-west) access of the pod within the cluster Does not solve the problem of k8s working with external security devices. Just imagine, after Network policy has made rule control, can an external security device open a default allow rule for the cluster?  Openshift has four features related to Egress, namely standard Network Policy, Egress IP, Egress Router, Egress Firewall and Egress NetworkPolicy.\n Network Policy, which is fully supported when Openshift uses OVN-Kubernetes as the CNI, while the traditional Openshift SDN CNI is only partially supported. It is no different from standard Kubernetes, and its advantages and disadvantages will not be analyzed here. EgressIP is a function to use deterministic source IP when Pods traffic leaves the cluster. When using Openshift SDN CNI, this function applies the Egress IP to the specified nodes as secondary IP and is used for SNAT. When using OVN-Kubernetes CNI, the snat rules are executed for specific pods through OVS. Using EgressIP itself is not a direct method for egress security policy control, but by specifying a certain source IP for different namespaces, some policies can be deployed on security devices outside the cluster to perform control. Obviously, this policy control method is relatively extensive, and cannot achieve the fine-grained granularity of different services. If the pods are scattered on different nodes, there will also be the problem that the outgoing cluster traffic of the pods must first traverse between different nodes, adding extra delay. In addition, the EgressIP must belong to the same network segment as the node\u0026rsquo;s main network address, and a node cannot have more than one EgressIP. EgressIP also does not support public cloud and Redhat Openstack Platform. Egress Router Pod, which is a special pod with two network interfaces, and uses MacVlan technology to directly connect one of the container network interface to the external network. All pods out-of-cluster traffic will pass through this pod. Different CNIs (SDN or OVN-Kubernetes) have different functions for the pod. Only redirection operations are supported under OVN-Kubernetes CNI. Generally speaking, this is not suitable for large-scale use. From the perspective of Egress security policy setting, it is still impossible to distinguish between different services, and the centralized Egress pod can easily become a performance bottleneck. EgressFirewall, which is actually a feature of OVN-Kubernetes. Allows setting outbound access rules for a project or namespace, which can be based on protocols, ports, IP, FQDN and other dimensions. The protocol only supports TCP, UDP, SCTP, and cannot support other protocol control. It only allows setting based on the namespace level. Only one rule file is allowed to be set in a namespace, and cannot set different rules for different services in the cluster. Also it limits each namespace/project to a maximum of 8000 rules. Observables or events are also not supported. Egress NetworkPolicy, similar to EgressFirewall, supports this CRD when using Openshift SDN CNI. But the Egress NetworkPolicy is more restrictive, for example, each namespace/project supports a maximum of 1000 rules, and the network policy or multitenant mode must be turned on.  \u0026raquo; Click here for continue reading(2/2)\n","date":1659744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"3bfacf3e6e2edfa439232defbfbab139","permalink":"http://linjing.io/post/why-k8s-egress-traffic-policy-control-is-critical-to-security-architecture/","publishdate":"2022-08-06T00:00:00Z","relpermalink":"/post/why-k8s-egress-traffic-policy-control-is-critical-to-security-architecture/","section":"post","summary":"Managing outbound traffic policies in Kubernetes, a seemingly simple requirement, actually is not an easy task to do well.","tags":["k8s","egress","security"],"title":"Why K8s Egress Traffic Policy Control is Critical to Security Architecture","type":"post"},{"authors":["Jing Lin(林静)"],"categories":[],"content":" In recent years, the role of open source software in promoting the digital transformation of enterprises has become more and more obvious. The country has written the construction and improvement of the open source ecosystem into the \u0026ldquo;14th Five-Year Plan\u0026rdquo;. At the same time, topics such as open source governance and secure supply chain have become a hot topic in the industry. As open source users or as open source subjects, how should we understand open source, how to understand the community, and how to participate in open source better and more safely. This article will discuss with you the meaning of open source, business models, risks and challenges, choices and governance.\n What Open Source Means for Business Let us first think about the meaning of open source and individuality from the perspective of an individual. We can summarize \u0026ldquo;selfishness and altruism\u0026rdquo; in one sentence. Using open source projects or products can help individuals quickly solve problems and challenges at work, and individuals can also gain innovative ideas and experience from open source projects or products. These are all selfish. When an individual is not satisfied with just being an open source user, and begins to participate in the contribution of an open source project, or even set up an open source project himself, it becomes altruistic, and other users will benefit from his contribution or project.\nThe same goes for businesses. When enterprises focus on their own digital transformation, it means that enterprises will pursue a more open organizational spirit. The core of digital transformation is to use digital technology and capabilities to reengineer enterprise processes, thereby driving business model innovation, enhancing enterprise competitiveness, and even changing an industry, just like \u0026ldquo;DiDi\u0026rdquo;. This requires the enterprise\u0026rsquo;s IT infrastructure and technology to not only support the rapid changes and development of the business, but also drive business innovation. Enterprises must quickly establish business, quickly iterate business, and quickly obtain business feedback. Therefore, having an IT architecture and technology that can flexibly support short-term and long-term business development is the key. Enterprises must adopt open and collaborative new technologies to continuously improve and enhance the iterative capability of technical architecture. These all mean being \u0026ldquo;fast\u0026rdquo; enough and \u0026ldquo;innovative\u0026rdquo; enough. Open source technology just responds to the needs of enterprises, because open source technology pursues the spirit of openness, collaboration and contribution. Enterprises adopting open source technology can obtain contributions from outstanding talents from all over the world, and can rapidly improve and enhance the competitiveness of enterprises through the contributions of talents from all over the world. The open ecosystem created by open source brings this value to all parties involved.\nTake the smart car industry as an example. Traditionally, car manufacturers have relied on a large number of third-party suppliers and technologies. However, when companies enter the new smart car track, car companies need to continuously innovate vehicle functions, improve user experience, and quickly occupy the market. If car companies still adopt the traditional supplier model, they will be constrained by those closed suppliers and will not be able to innovate products and quickly occupy the market. By adopting open source technologies, such as AGL (Automotive Grade Linux), it is possible to eliminate the need to develop the basic operating system of the vehicle, and instead invest valuable R\u0026amp;D technology on more competitive innovations.\nEnterprises with an open spirit will not only stop at adopting open source technologies, but will also contribute to open source. Large enterprises can help enterprises realize market strategies, occupy the market or change the game rules of the market by open-sourcing their own products or technologies, such as Google\u0026rsquo;s Android system. Innovative small enterprises can accumulate huge community users, increase their influence, and expand their own valuations through open source.\nIt can be seen that the significance of open source to the digital transformation of enterprises is obvious. On the one hand, open source is conducive to stimulating technological innovation of enterprises. Compared with the use of closed source software, open source technology makes users more creative and innovative; on the other hand, the use of open source technology can help enterprises save costs, so that more IT investments are used to deploy new technologies and accelerate digital transformation. This finding is echoed in a survey of global IT leaders on the state of open source in the enterprise 2020, with 95% of respondents saying open source is strategically important to their overall software strategy. In China, some leading Internet companies have also established special corporate open source committees to help companies achieve better open source strategies. The country has written the construction and improvement of the open source ecosystem into the \u0026ldquo;14th Five-Year Plan\u0026rdquo;.\nOpen source is sometimes given the concept of \u0026ldquo;trusted and controllable\u0026rdquo;. It is true that open source cannot be directly equated with \u0026ldquo;trustworthy and controllable\u0026rdquo;. Only when an enterprise has the ability and resources to thoroughly understand and master it through learning can it be truly trusted and controllable. However, open source, in the form of open source code, allows users to be reassured and solve problems in operation and maintenance by studying open source code when necessary.\nF5 operates open source NGINX in China and deeply understands the demands of Chinese users. The reliability and ease of development of NGINX technology ensure that enterprises can have a better and more reliable IT infrastructure, which is of great significance to the digital transformation of enterprises. Whether in distributed or microservice architecture, NGINX technology has been proven by users all over the world, and its reliability ensures the stability of IT infrastructure. In China, we can see that a large number of users use NGINX technology in production, whether it is an Internet company or a financial enterprise, such as the open banking of Agricultural Bank, the business access scheduling of Xinwang Bank, and so on. The ease of development of NGINX makes these technological innovations possible. It can be said that many customers have realized the autonomous control of soft loads with the help of NGINX. Further, by localizing open source NGINX and providing open source subscription services in China, it means that Chinese users can achieve more reliable product use through local services. This service includes basic technical support and advanced expert services. Creation, development, etc.\nOpen source business model There are many business models for open source. According to the origin, background, appeal, and subject of the project, it can generally be divided into: advertising mode, which can obtain certain benefits by placing sponsored advertisements on the website, installation process, documents, etc. Games and search projects are generally easy to take this approach.\nSelling services is a typical open source business model. The service provider itself does not provide code sales, but services, and users pay for better and more professional technical support services. The sale of services can be the original subject of the open source project or other subjects. Of course, it is generally difficult to support the development of a company by simply selling services. Generally speaking, companies will adopt a mixed business model, such as Redhat.\nSoftware redistribution , enterprises expand and enrich upstream open source projects through their own development, and form commercial products for redistribution and sales. This is a relatively common approach, such as there is a large number of commercial distributions or reintegration of enterprise products around kubernetes.\nDirect code sale , the definition of open source allows you to sell source code directly. In the early days of the Internet, revenue was made by collecting, distributing code or binary software and making it on CD-ROM. Relying on direct sales codes is obviously not easy to succeed today.\nDual license/open core , the main body of the open source project has a commercial license version of the software while publishing the source code. Generally speaking, there will be some functional differences between the two. Open source products will have the main core functionality, but some additional functionality needed for production-level enterprise deployments will be sold in commercial versions. Such companies often also sell additional services at the same time. NGINX Open Source and NGINX Plus are a dual license. NGINX Plus is completely based on open source OSS, but has added many enterprise-level features, so that users can better deploy and run in the production environment.\nSaaS , deploying open source software as a SaaS service model on the cloud, is also a popular way at present. It is also a model in which open source products are more likely to achieve commercial success in the cloud era. MongoDB\u0026rsquo;s SaaS service is this model. Of course, some open source controversies have arisen because of cloud services, which will be discussed later in the Risks and Challenges section.\nEco-partnership , commercialization in the form of an eco-partner is a hybrid business approach. Some companies have full-time employees involved in some very well-known and popular open source projects, such as Istio, Kubernetes, etc. Contribute to these upstream projects and enter the technical committees, SIGs, etc. of these upstream projects, forming a high influence in the community and field. The company itself will sell related professional service support, value-added products, etc. This is a more advanced form of business, generally found in large companies or very innovative start-ups. Companies such as Solo and Tetrate. F5 NGINX\u0026rsquo;s contribution to the community k8s Ingress Controller is also in this pattern.\nThere are many open source business models, such as donations, crowdfunding, and peripheral brands. Either way, from the user\u0026rsquo;s perspective, the product must have value in order to be paid for. For companies that rely on open source for commercial services, they must provide valuable products and services with good experience, and return to the origin of the product to achieve open source commercialization more easily. It is difficult to achieve sustainable open source commercialization only by relying on the market.\nOpen Source Risks and Challenges Open source has many benefits for businesses or users. However, in the actual use process, there will still be certain risks and challenges. From the risk point of view , there are the following four aspects: License risk , which may be the first consideration in the use of open source. Generally speaking, free software licenses are in copyleft mode. Such licenses are generally stricter and will force downstream users to keep open source. Therefore, be careful whether you will violate the license requirements after modifying the code. For example, the GPL License of HAproxy should be handled carefully. This is a typical copyleft license. When distributing the modified and compiled binary, you must attach the modified source code. Packaged products with delivery capabilities implemented using HAproxy also need a short copyright statement at the delivery prompt. Although some open source software licenses today no longer require users to open source the modified code, it is still necessary to be careful about the license scenarios and restrictive requirements. For example, whether open source code is used in prohibited usage scenarios, Redis\u0026rsquo;s RSAL restricts usage scenarios such as search engines and stream processing engines. When using open source software to build cloud service capabilities, you must be careful about open source products using the Affero GPL or SSPL protocol. He requires the relevant source code to be disclosed, which is very unfriendly to many companies similar to public clouds, so Google strictly refuses it internally. Use AGPL\u0026rsquo;s software on the public cloud.\nProject continuity risk , due to the uneven main body of open source, some projects are the results of some enterprise KPI-oriented, and some are the results of individuals based on hobbies or work stages (it can be called: open source smoothly). These items may not be durable and have a short life cycle. If an enterprise chooses such a project, it must fully understand such risks, and the enterprise needs to be able to develop and maintain it continuously. Persistent risks may also be manifested in some geopolitical issues. Although the Open Source Initiative (OSI) mentions \u0026ldquo;non-discrimination against individuals or groups\u0026rdquo; in its 10 definitions of open source, such concerns may still be encountered under certain circumstances. Sometimes these concerns are based on personal emotions or based on personal perception. For example, some time ago, F5\u0026rsquo;s statement on stopping the work of F5\u0026rsquo;s Russian office staff made it emotionally unacceptable to a small number of people, misunderstanding that NGINX originated in Russia, but F5 stopped Russians\u0026rsquo; contributions to NGINX. In fact, this is just a decision made by F5 based on the regional war for the safety of F5\u0026rsquo;s internal staff. The source code of NGINX has been hosted on github and mercurial multiple service systems, and contributions, access, and downloads from Internet users around the world have not been affected.\nProject quality risk , open source projects pursue openness, and developers\u0026rsquo; experience levels are not completely consistent, which may lead to insufficient code testing, code security risks, and incomplete use cases. Some large and popular open source projects often improve software quality by standardizing developer contributions, setting up special testers, documentation personnel, and security teams. But not all projects have such resources and capabilities. Enterprises should do sufficient research and testing when introducing open source projects.\nOpen source nesting risks , such risks need to be considered from two perspectives. One is the license. When citing other open source projects in your own project, you should pay attention to the relationship between the reference method and the license, and pay attention to whether there is a compatibility risk between the license of your own project and the license of the referenced project. The second is to pay attention to the loss of quality control caused by serial nesting. When project A cites B, and B cites C and other multi-level references, it is necessary to comprehensively judge all the above-mentioned risks.\nFrom a challenge perspective , its coverage is much broader. Generally speaking, the digital transformation of enterprises involves three aspects: culture, technology and process. Likewise, the challenges of enterprise use of open source can also be considered from these three perspectives. Culturally, the lack of motivation for companies to build an open source culture is a challenge. Enterprises often emphasize the stability of operation. Whether it is a process or KPI assessment, stability is often pursued for IT systems. From the bidding, testing, launching, and operation and maintenance of the project, stability is the first. In such a culture, the technical system and personnel ideas tend to become rigid: the almost static and stable IT system limits the IT system’s support for business innovation, resulting in slow business launch; technical personnel will rely on the technical support of commercial products, resulting in a lack of innovation Spirit. On the other hand, the lack of motivation for open source culture is that enterprises lack the spirit of open source contribution. They only ask for use, do not contribute to the upstream of open source, and are even more afraid to share their innovations with the community.\nOn the technical side , there are two interrelated challenges: the ability to master open source technology, and the talent to master the technology. Open source products are often not ready to use out of the box. Enterprises need to re-develop according to their own conditions. At the same time, in order to achieve business capabilities, they often need to adopt a variety of open source technologies. This requires enterprises to have more development talents and more innovative talents, who need these talents to analyze and study these open source products, understand and master core technologies. This is often a big challenge for companies that adopt outsourcing models, and such companies lack enough talents to master these technologies. Even for enterprises with a certain development scale, how to transform talents, establish a good talent promotion channel, and retain high-end talents who master key open source technologies and understand open source technologies are actually very big challenges.\nIn terms of processes , companies need to adapt existing processes to open source, which is often difficult. Using open source technology means that processes oriented towards closed source software need to be transformed and adapted to the changes brought about by open source technology, whether it is business processes, asset management, technical support, governance processes, etc. We have seen that some enterprises still encounter some problems in the process of purchasing open source-related technical support services after using open source.\nOpen Source Selection and Governance Open source subjects and open source users think about open source selection and governance in two different categories. Because it\u0026rsquo;s a question of two directions, even though the roles of the two sometimes intersect.\nOpen source choice, for open source subjects , the first thing to do is to make a decision on whether or not to open source their projects. The person in charge of the project or company needs to think about it based on the cognitive understanding of open source, combined with the characteristics of the industry, the analysis of competition in the field, and its own actual situation, and comprehensively analyze the impact of open source or not open source. When you decide to open source, you also need to decide whether to open source internally or externally. Intra-enterprise open source is a practice of some leading Internet or technology-leading large enterprises. Generally speaking, the internal open source of an enterprise will go through the spontaneous stage of individuals or groups, and then to the stage of unified open source management and coordination at the global level of the enterprise by setting up an internal open source management department in the enterprise.\nWhen the official decision to open source is made, then it is necessary to turn to thinking about open source governance. For open source entities, open source governance includes two aspects, one is the governance of project engineering, and the other is community governance.\n(1) Project engineering governance. In any case, an open source project is ultimately a software engineering, but it is based on a larger scope of collaboration, trust and contribution. Therefore, the management of project engineering quality and code is also applicable to open source projects. It is necessary to consider the scope management, schedule management, quality management, change control, etc. of the project, and ensure the quality, progress, and safety of the code through these managements. We can see that some open source projects will give developer guidance, Code of conduct, etc., which are used to ensure code quality. At the same time, it is also necessary to build a good DevOps automation pipeline to make the contribution process of developers smoother, to ensure that the submitted code undergoes relevant reviews, automated inspections, automated tests, etc., and the results are fed back to contributors in a timely manner. In addition, risk management needs to be done well. We can see that many mature open source projects require developers to sign a Developer Contribution Agreement (CLA) before submitting PR. These are to prevent copyright, non-original and other risks. Risk management also includes license compliance management for other open source components used in the project to avoid introducing risks. Tools like FOSSA are often used for this management.\n(2) Project community governance. The biggest feature of open source projects is decentralization and diverse personnel. They come from all over the world, with different backgrounds and cultures. Therefore, the governance of the community is essentially the management of \u0026ldquo;stakeholders\u0026rdquo;, and the management of people is the biggest challenge in open source projects. It can be said that the quality of community governance is a very critical factor for the success of the project, so the Apache Foundation particularly emphasizes the concept of \u0026ldquo;Community over code\u0026rdquo;. A community should have clear rules and a tone from the start, which ensures that the community always brings together those who share the same understanding. The governance of the community will involve choosing which governance model, such as foundation custody or self-management. Generally speaking, joining the foundation is beneficial to the operation of the project, because these professional open source foundations can help guide the operation of the project, and can also help the project go global quickly, help build the project ecology, and form a relationship between different projects through the power of the foundation. cross support. Of course, the foundation also runs many activities, which can help the project to increase its visibility, attract more developers to become users, and eventually become contributors. Self-management requires the project owner or the organization behind it to have strong community management capabilities. For example, NGINX is self-managed, and F5 manages the community through a professional community operation team. No matter what kind of governance method, the core is to help the project walk on the right track and direction, ensure the sustainable development of the project, and solve various stakeholder problems in the process of the project. The work required for community governance can include product evangelism, event operation, developer relationship maintenance, Issues/PR management, license management, community contract and rule management, document management, ecological construction, legal affairs, etc.\nOpen source selection. For open source users , especially for enterprise users, the first rule of open source selection is to establish access control. Enterprises can consider establishing a whitelist of open source software assets to prevent developers from randomly introducing open source software or projects. The software provided by the purchased service provider is also subject to relevant whitelist checks. Although this increases the cost to a certain extent, it is indeed very necessary for the enterprise\u0026rsquo;s security risk control. Enterprises should conduct sufficient research and analysis on open source projects to understand the status, activity, supporting force behind the project, operation mode, user base, contributor popularity, license restrictions, technical roadshows, software architecture, code quality, etc., and do a good job Adequate pre-introduction testing. Open source projects should also be introduced objectively to avoid the introduction of \u0026ldquo;relational open source projects\u0026rdquo; due to the technical feelings or inclinations of a small number of people.\nLet\u0026rsquo;s look at open source governance . As with the challenges of using open source above, enterprises can conduct open source governance in terms of culture, technology, and process.\n(1) In terms of culture, enterprises should establish a culture of advocating and respecting open source. While actively encouraging the adoption of open source technologies, strengthen employee awareness of open source. Such as respecting copyright and avoiding legal risks. Knowing open source does not mean free, and using open source does not mean cheating. Knowing open source doesn\u0026rsquo;t mean you can be autonomous and controllable. Open source does not mean customization, and any modifications and enhancements that are beneficial to the product should be fed back to the upstream. Enterprises should objectively evaluate their current ability to control open source according to their own actual situation, and should not rashly advance. For example, enterprises may need to shape open source cultural genes step by step. At this time, it is more suitable for enterprises to adopt open source software usage models with professional support services. By introducing the support of third parties or open source service providers to help enterprises avoid technical risks and achieve pragmatic independent availability control. Taking soft load products as an example, enterprises can try open source practices by introducing NGINX support services. For departments that have just undergone open source practice transformation, such as operation and maintenance departments, they can consider adopting commercial products + manufacturers\u0026rsquo; open source expansion solutions to ensure that they gradually enter open source operation and maintenance under the premise of controllable risks.\n(2) In terms of technology, establish a good development construction and testing platform and security testing platform in the development link, and conduct code scanning and inspection on relevant open source codes. Identify dependencies of related libraries and discover potential vulnerabilities in the code itself and associated dependencies. Check for possible license compliance issues and cross-problems through open source license management software. During delivery and operation, use additional security devices or strategies to strengthen the environment in which open source components run reinforcement. Strengthen the technical team\u0026rsquo;s learning and skill improvement of open source technology, and establish a professional open source technology component support team.\n(3) In terms of process, enterprises can consider establishing a whole process mechanism from introduction, development, delivery, operation and maintenance to exit for open source management. From the aspects of organizational mechanism and management system, the open source software introduction specification, development specification, deployment specification, operation and maintenance specification, exit management and other specifications are formed. The introduction of specifications can be combined with the above-mentioned open source selection part to identify open source access, establish access conditions, and make the first pass of the entrance. The development specification can consider defining the use language, paradigm, boundary, modification process, documentation process, etc. of open source software code. Deployment specifications can be considered around delivery, dependency management, security hardening, and standardized environments. Operation and maintenance specifications can consider the operation and maintenance tools, troubleshooting processes, best practices and other aspects of open source software. In addition, enterprises should also form a closed-loop management system, and establish an identification and inspection mechanism for the use and operation of open source. For example, identify open source software and related projects that are already running, and evaluate them, make corrections in terms of culture, process, and technology for the problems found, and exit open source software that is not running well in time to ensure that the governance of open source is always Stay on track to avoid open source sprawl and runaway.\nSummarize It can be seen that, whether it is an open source subject or an open source user, the understanding, choice, risk, challenge, and governance of open source are all systematic projects and capabilities. In recent years, under the strategic background of the country\u0026rsquo;s vigorous promotion of open source, the concept of \u0026ldquo;trusted open source\u0026rdquo; has been proposed in China, and its main goal is still how to better play the role of open source and avoid possible risks in open source. In any case, if an open source project can always adhere to its original intention and insist on being user-centered, it can eliminate users\u0026rsquo; concerns and risks in open source in many aspects. As Zhang Yiqiang, general manager of F5 China, said at the \u0026ldquo;2022 F5 Multi-Cloud Application Service Technology Summit\u0026rdquo;: Focus on user needs and build an open source ecosystem around product features and community platforms. This is the core that ensures that NGINX can go a long way in China, the core that F5 provides value to users, and the core that users trust F5. I think the same applies to our understanding of other open source.\n","date":1656288000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"0144dfe9d382a33a3e95b2c2c1678164","permalink":"http://linjing.io/post/analysis-and-thinking-of-enterprise-opensource/","publishdate":"2022-06-27T00:00:00Z","relpermalink":"/post/analysis-and-thinking-of-enterprise-opensource/","section":"post","summary":"As open source users or as open source subjects, how should we understand open source, how to understand the community, and how to participate in open source better and more safely. This article will discuss with you the meaning of open source, business models, risks and challenges, choices and governance.","tags":["NGINX","Opensource","Community"],"title":"Analysis and Thinking of Enterprise Open Source","type":"post"},{"authors":["Jing Lin(林静)"],"categories":[],"content":"This is the first NGINX book after F5 acquiring NGINX. It not only just focus on how to use NGINX directives, It helps you to understand NGINX by vary scenarios. Pls order it in jd.com, Chinese book name： NGINX经典教程\n","date":1652659200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"125302f8d5a9c535f66c1c535ef79826","permalink":"http://linjing.io/post/nginx-book/","publishdate":"2022-05-16T00:00:00Z","relpermalink":"/post/nginx-book/","section":"post","summary":"NGINX Classic Tutorial is a new nginx tutorial book, include NGINX basic and many useful scenarios and solutions. It is a book full of practical experience.","tags":["NGINX","Book"],"title":"New NGINX book published!","type":"post"},{"authors":["Jing Lin (林静)"],"categories":null,"content":"","date":1652659200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"478089022b0d83abb245377254e141e0","permalink":"http://linjing.io/publication/nginx-book-publish/","publishdate":"2022-05-16T00:00:00Z","relpermalink":"/publication/nginx-book-publish/","section":"publication","summary":"This a book with full of experience and practice for NGINX. Include NGINX basic, and many use cases that many customers are using.","tags":["nginx","Tutorial"],"title":"NGINX Classic Tutorial","type":"publication"},{"authors":["Jing Lin"],"categories":null,"content":"","date":1647954030,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"8aae75744a6cc3a825798716f46a6504","permalink":"http://linjing.io/talk/f5-fcc-slb-industry-trend/","publishdate":"2022-03-18T00:00:00Z","relpermalink":"/talk/f5-fcc-slb-industry-trend/","section":"talk","summary":"SLB technology and trends in the financial industry","tags":["SLB","feature"],"title":"SLB technology and trends","type":"talk"},{"authors":["Jing Lin(林静)"],"categories":[],"content":"Solution architecture Components The CES solution includes the following components:\n CES controller: a container running in k8s. This component is the control plane, responsible for converting the outbound policies that deployed in k8s into the external data plane component(here is F5 AFM). F5 BIG-IP AFM: Data plane components running outside of k8s. Accept the configuration issued by the CES controller and execute specific access control rules, such as access control lists, bandwidth limiting, traffic programming, etc. CNI: CNI is a choice of the user environment itself and is not included in the CES plan. However, different CNIs will have different effects on the functions of the CES solution. Use kube-ovn CNI to get the full functionality of CES.  Architecture diagram Policy scope and role CES provides three policy scopes cluster global namespace and service. Its meaning and user role relationship are as follows:\n   scope meaning Adaptation role     Cluster global It is the global level policy of the cluster, which is used to control the general and overall access control of the cluster. For example, the cluster\u0026rsquo;s access to basic public services such as NTP and DNS of the enterprise. The scope policy is applied to the outbound access control of all services in the cluster. Cluster administrator, Security team   namespace This policy level is effective for a single namespace or project. It is used to control the access of all services in specific NS or project to access the services out of the cluster. Policies in different namespaces or projects do not affect each other. *This function requires the support of CNI. Project team, application operation team   service level The policy control the k8s servcies to the external services. Only valid for specific services. So if the CNI can not support namespace level policy, set svc level policy is an alternative way. Project team, application operation, microservice owner    Tenant isolation The CES solution supports strong isolation of network + namespace. Supports the administrative isolation of configuration objects on the data plane, and also supports strict traffic isolation at the network level. Support different namespaces to use overlapping CIDR.\nNeed CNI support network isolation. For example kube-ovn's per ns subnet Solution value Challenges solved  High-frequency changes in outbound traffic caused by container IP dynamics Different role groups have different requirements for the scope setting of the policy, and the policy needs to match the role in multiple dimensions Dynamic bandwidth limit requirements for outbound traffic Protocol in-depth security inspection requirements Advanced requirements for flow programmable based on access control events Visualization requirements for outbound traffic  Provided capabilities  Dynamic IP ACL control with Cluster/Pod/NS granularity Cluster/Pod/NS granular FQDN ACL control Time-based access control Matched flow event trigger and programmable Matched traffic redirection Protocol security and compliance testing IP intelligence Traffic matching log Traffic matching visualization report Protocol detection visual report TCP/IP Errors report NAT control and logging Data flow visualization tracking Visual simulation of access rules Transparent detection mode High-speed log outgoing  Partial functions will evolve along with version iterations Next step:\nUnderstanding CES installation\n","date":1643673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"1cc10fd5e207b1979f3c523f0110ce6a","permalink":"http://linjing.io/post/f5-container-egress-service-ces/","publishdate":"2022-02-01T00:00:00Z","relpermalink":"/post/f5-container-egress-service-ces/","section":"post","summary":"CES is an open source project. Help users better manage the outgoing traffic of k8s. Solve the egress challenge in high dynamic IP scenarios,provides a wealth of outgoing control capability.","tags":["F5","k8s","ces","egress traffic controlling","afm"],"title":"Project- Container Egress Service(CES)","type":"post"},{"authors":["Gao Yuxian[zhiding.cn]"],"categories":[],"content":"To implement cloud native, you need such an infrastructure When a ten thousand zhang tall building starts from the ground, only when the foundation piles are deeply driven and the cornerstones are firmly laid, can the building be built higher and more stable. Digital transformation is not the case - all kinds of system applications at the top layer are ultimately inseparable from the support of the underlying infrastructure. It\u0026rsquo;s just that this base must change according to needs and times, instead of building a \u0026ldquo;pillar\u0026rdquo; and building a \u0026ldquo;building\u0026rdquo;.\nTake cloud native applications that are very popular right now, if they are also built on the centralized and complex traditional infrastructure, it is equivalent to \u0026ldquo;new wine in old bottles\u0026rdquo;, and accidentally \u0026ldquo;sprinkled wine in a bottle\u0026rdquo;. Get busy.\nIn this regard, Lin Jing, senior solution architect of F5 Networks, said in an interview with a reporter from Zhiding.com that the unique characteristics of cloud-native applications such as flexibility, agility, and simplification have put forward many new requirements for enterprise IT architecture. In three aspects: First, the orchestration of IT service capabilities. Since IT services are abstracted into various atomic services, this puts forward higher requirements for enterprises in event-based automation and operation and maintenance data capability mining; second, the IT architecture is flattened. More and more assembleable architectures are integrated into the underlying network system, which will weaken the previous network-centric thinking, and the capabilities of the platform will become more and more important; third, IT talents are mixed. Talent lines are no longer bounded by obvious networks, systems, etc., and technology-mixed talents will be increasingly strengthened in the scenario of IT architecture platformization.\n​\tLin Jing, Solutions Architect, F5 Networks\n\u0026ldquo;This means that enterprises need to use new technologies and use cloud-native standards, microservices, containers, etc. to build a modern application architecture to meet the current urgent needs.\u0026rdquo; Lin Jing emphasized. In this process, F5 has been deeply involved in the application network for many years. To help enterprises build an infrastructure that can meet the needs of digital transformation and support the implementation of their cloud-native applications, it should be said that they are very familiar with it.\nThree footholds, one big platform\nFrom the perspective of F5, it is decomposed from the perspective of F5. Specifically, it pays more attention to three aspects in the context of cloud native: firstly, how to transform the traditional infrastructure into a programmable mode to make the architecture more flexible and scalable; secondly It is how to build a modern service architecture based on new technologies such as microservices and containers; the third is to integrate the two.\nFor the first point, we see that the focus of F5 in traditional infrastructure in the past was mainly from the boundary of the data center entrance, to the authentication of data center services, the load balancing of background applications, and then to the release and policy control of application services. , all products and services revolve around applications. Now, as long as F5 endows the platform carrying these services with programmable capabilities and releases such capabilities to the upper layer, it can well meet the needs of enterprises in terms of flexible application invocation.\n\u0026ldquo;First of all, at the infrastructure layer, we have tenanted the underlying service resources and hardware resources of F5, and provided automated orchestration tools such as Ansible and Terrafrom to help enterprises achieve rapid resource allocation through interfaces; at the abstraction layer, using DO Business deployment with AS3, using F5OS-API to help users adapt to the division of underlying resources, etc.\u0026rdquo; Lin Jing explained.\nFor the second point, enterprises often start by building an assembleable architecture, that is, building their own private cloud, or directly using public cloud services. In order to integrate into this new modern cloud-native architecture, F5 has introduced many new capabilities for itself - for example, through the acquisition of NGINX, it has improved its capabilities including service mesh and PaaS entry, and truly penetrated into cloud-native; Through the acquisition of Volterra, a unified cloud-native platform interaction capability from public cloud, private cloud to edge is built; through the acquisition of Threat Stack, the full-stack security capabilities under the cloud-native system are further complemented.\n\u0026ldquo;For example, in terms of operation, we can provide a multi-language operation server through the NGINX standard APP Server and Unit, and provide a standard Kubernetes Ingress controller under the Kubernetes system; secondly, in Kubernetes, we will also provide NGINX. Proxy at the containerization layer such as Service Proxy, and API management provided by NGINX, help enterprises manage the full life cycle of APIs.” According to Lin Jing, in addition to the PaaS layer, F5 also provides many SaaS services, involving security, analysis and insight , Smart DNS and other applications.\nFor the integration of traditional architecture and modern application architecture, F5 believes that the key lies in the collaboration between the two different architectures. In this regard, F5 also creatively proposed the concepts of \u0026ldquo;internal cloud native application service\u0026rdquo; and \u0026ldquo;external cloud native application service\u0026rdquo;. The former refers to service capabilities around technical scenarios such as containers and Kubernetes; the latter refers to providing more external capabilities under the above conventional services, such as connecting and managing internal application services with external APIs.\n\u0026ldquo;At the boundary of the data center, from security to compliance operations, we used to look at the data center from the perspective of virtual machines and the grid as the core. But under the new PaaS system, all IPs are very dynamic. , to achieve real-time monitoring, security policies and norms will be challenged, therefore, integration between traditional infrastructure and PaaS must be carried out.” Lin Jing emphasized.\nComplete technical and role challenges\nToday, F5 has put this core idea into practice in the process of serving corporate customers. Take a bank as an example: Previously, the bank drove the construction of its own PaaS system through the cloud management center. However, in the process of business release, they found that all release processes would eventually return to the traditional management and control model of the network department. \u0026ldquo;At this time, the cooperation of the two departments is required, and the fast and agile characteristics of the cloud itself will be greatly weakened.\u0026rdquo; Lin Jing said.\nIn this regard, F5 proposed an innovative Hub model, which is the \u0026ldquo;one center\u0026rdquo; model. Specifically, a simulated space area is listed on top of Kubernetes, which is managed uniformly by the network team, and all services released by the business department can eventually pass through this central area and be quickly written to the foundation with the help of the F5 controller. facility. In this way, the technical use threshold of the business department is lowered, and the original release mode of the network team is retained, enabling better collaboration between the two departments. The solution used in it, F5 is called \u0026ldquo;the solution of the entrance Ingress\u0026rdquo;, namely Container Ingress Services.\nCorrespondingly, F5 also proposed the Egress solution, which mainly aims at the technical and role challenges of enterprises in the process of implementing cloud-native applications. The technical challenge is mainly reflected in the outbound traffic of the container. Since the IP address of the container is constantly changing during the outbound traffic, the traditional firewall cannot perform fine adjustment, which means that the location of all control policies must be able to dynamically sense the container; role challenges It is mainly reflected in the differences in demands between different departments. For example, the business department and the network department will have different security demands, and who should determine the policy standards in the end, which is a very real problem.\nTo this end, F5 provides two targeted solutions - solving technical problems through automation controllers, and reducing the difficulty of safe landing through differentiated classification of security policies. \u0026ldquo;In other words, we can divide security policy rules into three categories: first, enterprise-level basic key policies, such as DNS, NTP, auditing system, etc.; second, specific policies for each project; third, under microservices, local unit services. Refinement control strategy, for example, some microservices have unique requirements, and after starting one of the microservices, it is connected to a third party, so you can configure refined items for independent microservice units. Lin Jing explained to reporters , \u0026ldquo;Because the attention of each layer of policy is different and the security roles are separated, through the layered design, it is possible to make better cooperation between traditional security personnel and modern organizational structure implementers to avoid inefficiencies. Communicate to help enterprises achieve cloud native more efficiently. \u0026quot;\nFrom technology to talents, give full play to the existing strengths of F5\nAll in all, F5 covers almost all of these capabilities, from traditional infrastructure services to upper-layer application delivery, from all-center application solutions to corresponding digital experiences. For itself, it not only penetrates into the cloud native system, but also builds a bridge between traditional architecture and cloud native architecture for enterprises. In Lin Jing\u0026rsquo;s words, F5 has regarded cloud native as a very important part of its strategic planning.\nIn this process, F5\u0026rsquo;s goal is to start from four aspects: infrastructure network, application network, security and application operation, \u0026ldquo;to help enterprises build applications for better digital experience\u0026rdquo;. For example, delivering multi-cloud application capabilities such as consistent deployment, multi-cloud workload management, edge application management, modern application security, and application insight for enterprises; providing platform-level O\u0026amp;M capabilities, better service agents, service governance, and DevOps foundations At the same time, it also needs to ensure full-stack security including network, host, application and other layers.\nHowever, this does not mean a complete overthrow of F5\u0026rsquo;s past products, but to give new capabilities to old technologies. \u0026ldquo;For example, with the help of the F5 CRS controller technology, the traditional F5 solution technology can be introduced into the PaaS platform or modern system to help the business release better and faster.\u0026rdquo; Lin Jing said. \u0026ldquo;For another example, AI\u0026rsquo;s insights into data can also help enterprises improve the adaptive capabilities of applications, enhance the digital experience of applications, help users better manage applications on hybrid clouds and edges, and optimize and protect application security.\u0026rdquo;\n\u0026ldquo;Of course, we don\u0026rsquo;t just focus on cloud-native technologies, but also in terms of technology, culture, or talent, etc., and, based on F5\u0026rsquo;s deep understanding of traditional infrastructure, to help users truly understand the data center perspective. , do a good job of cloud native in every field.\u0026rdquo; Lin Jing concluded, \u0026ldquo;In other words, F5 is using its deep understanding of enterprises and industries to provide more and more modern and new solutions, which It is a very big advantage of F5 in the cloud-native field.\u0026rdquo; In its essence, you will find that whether it is communication control or service management, these are the original strengths of F5, but they are just switched to a new scenario. \u0026ldquo;So, for F5, we have never left, but have been cultivating.\u0026rdquo;\n","date":1632960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"4eebc6e29e917f71a0ed81374b5382da","permalink":"http://linjing.io/post/f5-cloudnative-media-interview-zhiding/","publishdate":"2021-09-30T00:00:00Z","relpermalink":"/post/f5-cloudnative-media-interview-zhiding/","section":"post","summary":"Various system applications at the top layer are ultimately inseparable from the support of the underlying infrastructure.","tags":["F5","platform","Cloud native","Infrastructure","DigitalX"],"title":"To implement cloud native, you need such an infrastructure","type":"post"},{"authors":["Jing Lin (林静)"],"categories":null,"content":"Check here for full article The link.\n","date":1632960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"cd14104871b86cd337d3420b6eaf4859","permalink":"http://linjing.io/publication/f5-cloudnative-media-interview/","publishdate":"2021-09-30T00:00:00Z","relpermalink":"/publication/f5-cloudnative-media-interview/","section":"publication","summary":"Various system applications at the top layer are ultimately inseparable from the support of the underlying infrastructure.","tags":["cloud native","f5","digital transformation","Infrastructure"],"title":"To implement cloud native, you need such an infrastructure","type":"publication"},{"authors":["Jing Lin"],"categories":null,"content":"","date":1631977830,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"b445c8cf424a96b248725272a46364bf","permalink":"http://linjing.io/talk/f5-accelerate-io-innovation/","publishdate":"2021-09-16T00:00:00Z","relpermalink":"/talk/f5-accelerate-io-innovation/","section":"talk","summary":"How F5 solutions help you to build cloud native better.","tags":["SOAP","cloud natvie","enterprise","feature"],"title":"F5 accelerate IO innovation","type":"talk"},{"authors":["Jing Lin (林静)"],"categories":[],"content":"Born to be simple(Load Balancing) In the 1990s, the rapid development of the Internet gave birth to a large number of online websites, and the number of Web visits increased rapidly. At that time, a simple appeal was how to improve the access speed and ability of Web sites.\nAt that time, in the Six Arms bar on the slopes of downtown Seattle, several young people were here every night to enthusiastically discuss their entrepreneurial dreams. They were obsessed with human-computer interfaces and studied how to break through the limits of immersive virtual reality. . Michael Almquist was one of them. He found that the servers at the time could not meet their needs, so they studied the use of load balancing to help solve the problems they encountered.\nIn 1996, F5 Labs was established in a dilapidated office on the fifth floor of the Seattle Tower. Michael Almquist was the founder. Such a technology was discovered by investors, bringing F5 Labs from the field of virtual reality technology to a world that helps to achieve trouble-free and efficient Internet communication.\nAlteon and Radware were also established in the same year as F5, but these two companies had stories with each other more than ten years later. Juniper was also established this year, and has had a consistent market with F5 in the following years.\nBefore the Internet bubble burst, this field basically revolved around how to load balance and optimize Web sites. Therefore, in the early days, there will be the term \u0026ldquo;Web switch\u0026rdquo;. The basic idea is to achieve greater access capabilities by distributing connections to more different servers. When one server goes down, users can still access other available servers. The core technology is Load Balancing, and some Web optimization capabilities are added. The basic technical deployment patterns are as follows:\nIn 1997, F5 released the BIG-IP product. The earliest name of BIG-IP is actually called BIG/IP, which is derived from the name TCP/IP. BIG expresses the meaning of a super IP representing many backing service IPs. In the same year that BIG-IP was released, a company called ArrowPoint was established, mainly for web optimization.\nIn 1998, F5 released the 3DNS product. On Load Balancing, DNS has always been an original technology. 3DNS products expand the concept of space (source, target) and time (availability) on top of the basic technology of DNS polling and resolution, forming three dimensions (3D), which is also 3DNS The origin of the naming was later changed to Global Traffic Management (GTM). In recent years, it was also named DNS to express a complete and comprehensive enterprise DNS architecture. We can actually see the focus of the market direction at different stages from the name change. The use of smart DNS technology has helped to further enhance the Web access experience, allowing users to access the nearest available site in time. The technical concepts used in 3DNS are still widely used today, whether it is global traffic management or enterprise basic DNS. In the same year, the industry also established two companies, uRoam and Netscaler. One was later acquired by F5, and the other was a company in the same field of F5.\nSuccess in ADC The Internet bubble reached its peak in 2000, and this year was also the year when the most relevant manufacturers in this field were established. Fineground, a web optimization, application acceleration and security vendor; application front-end optimization vendor Redline; WAN optimization vendor Peribit. Application security vendor Magnifire. At the same time Array was also established this year. If we look through the information, we will find that at this stage the market will have a lot of terms about products. In addition to the \u0026ldquo;Web switches\u0026rdquo; mentioned above, there are also \u0026ldquo;content switches\u0026rdquo;, four-layer switches, and seven-layer switches. Manufacturers of different technical backgrounds are engaged in a secret struggle.\nIn 2001, the U.S. stock market plummeted and the Internet company bubble burst. The business model of simply relying on simple Load Balancing for Internet Web sites is no longer sustainable. Combing the acquisitions in this field from 2000 to 2005, we can see that the market has become complicated, with a large number of manufacturers established and a large number of manufacturers acquiring:\n In 2000, Cisco acquired ArrowPoint, and Fineground, which was created in the same year, was also acquired by Cisco in 2005. Through this acquisition, Cisco finally completed the construction of its application content network (AON) technology products. In 2003, F5 acquired uRoam and built an APM module for SSL VPN and access identity and policy management. In 2004, F5 acquired Magnifire to build WAF product capabilities. That is, the current Advance WAF module. In 2005, F5 acquired Swan Labs to enrich the capabilities of WAN acceleration, the later WOM module. In 2005, Citrix acquired Netscaler, which became its later application delivery product. In 2005, Juniper built its application-oriented product line through the acquisition of Peribit and Redline.  And behind this frenzy, a standardized market area is being shaped. It can be seen from the acquisition technology direction of the above-mentioned vendors that the technology trend at the time was relatively clear, and the market was focusing on how to access applications faster and more securely, and to ensure that the applications were available for construction.\nIn 2003, Gartner defined the Application Delivery Controller (ADC) concept for the first time. In the early days, the definition of ADC was still mainly a combination of load balancing technology and offloading technology, and it was Web-oriented. The latest definition is:\n The Application Delivery Controller (ADC) is deployed in the data center and optimizes application performance, security, and resource efficiency by offloading servers, providing in-depth payload inspection, and making full use of complex protocols. They were originally deployed for external-facing Web applications and are now used to provide services for many types of business applications and protocols.\n It can be seen that later ADC products are more oriented towards the processing of complex applications in enterprises. This is why there are arguments that ADC should become a platform, which has attributes similar to middleware to help companies better deliver applications.\nThe stock market crash caused companies in this field to consider shifting technology application scenarios from Internet Web sites to enterprise applications. 2002 was the most critical year for F5. This year, F5 established TMOS (Traffic Management Operating System) as the foundation of BIG-IP. This real-time event-driven traffic operating system established F5\u0026rsquo;s leading position in the application delivery network (ADN) field. The three consecutive acquisitions in 2003, 2004, and 2005 helped quickly form a complete ADC product line.\nThe TMOS V9 version was released in 2004, bringing the market into a new development track. In mid-2005, Gartner announced that F5 had achieved the highest ADC market share.\n2006 is a sign of the maturity of the ADC market. The ADC technology represented by F5 has formed a de facto standard in the field. The products have formed a wealth of connection management, protocol control, SSL offloading, Web compression and optimization, traffic shaping, DoS protection, Web security, IPv6, link load, GSLB, etc. Application delivery capabilities. The technical architecture deployment is basically similar to the following figure:\nConsolidating a mature market is not an easy task. It requires continuous investment in technology research and development to ensure competitiveness in the industry. The period from 2006 to 2008 was a period of very high growth in F5 R\u0026amp;D investment in history. Although it was during the global economic crisis, the quarter-on-year growth of R\u0026amp;D investment remained between 30%-40%.\nAt this time, several large companies in the same field are disproportionate in their R\u0026amp;D investment and market revenue. Whether it is due to lack of investment or technical route issues, they eventually withdraw from the market due to lack of technical competitiveness.\n Juniper abandoned its DX product line in 2008 and announced its withdrawal Nortel ended in 2009, Radware acquired Alteon assets In 2010, Cisco stopped selling AON and ACE XML gateway products In 2012, Cisco officially stopped ACE research and development  The failure cases of Nortel, Cisco, and Juniper fully illustrate that the ADC field is a high-tech market. It requires continuous technological accumulation and continuous technological breakthroughs. For a long time, F5\u0026rsquo;s annual R\u0026amp;D investment accounts for approximately 17%-18% of its revenue, which is higher than the 15.7% average of the software and Internet industries. The annual R\u0026amp;D investment is close to 5 times the revenue of the F5 Chinese market in the same year. Continuous high R\u0026amp;D investment has ensured F5\u0026rsquo;s leading position in technology in the industry.\nIt is precisely because of the maturity of ADC products that around 2009, the market once made the argument that Load Balancing was dead to emphasize that companies should attach importance to the capabilities of ADC products. F5 ADC products have rich application-oriented capabilities, such as rich and in-depth protocol control, event-based programmable architecture, connection-oriented refined management, high dynamic configuration without reload, comprehensive automation and API interfaces, and rich The observable ability. Enterprises can fully open up these capabilities and provide them to application teams and middleware teams.\nAt this stage of the rapid development of ADC products, another field is also constantly developing, which is the soft load field represented by NGINX and HAproxy.\nNGINX began to develop in September 2004, and HAproxy began to develop in December 2005. The origins of these two products are similar to those of F5, and they are both developed for the actual needs of their own business. NGINX is to solve the high concurrency problem of the website, and HAproxy is to solve the problem of application session retention of the author\u0026rsquo;s own security company. Eventually evolved into today\u0026rsquo;s typical reverse proxy software.\nIn terms of time, since ADC hardware products were established in 2003, soft load products have developed together with hardware ADC products. The use of soft load by cloud and top Internet companies has accelerated the application of soft load product scenarios, exposing it to the public and being understood by more people. Whether it is LVS, Tengine, Openresty, ELB, etc.\n2016 is the inflection point of the enterprise market\u0026rsquo;s perception of soft load. With the further development of enterprises\u0026rsquo; digital transformation, DevOps, dual-mode IT, elastic architecture, and enterprise private cloud, soft loads have begun to be widely mentioned and applied.\nBased on the understanding of the soft load market, F5 has released the Virtual Edition (VE) of TMOS since 2009, actively building the cloud initialization capabilities of related products, strengthening the ecological construction of DevOps tools such as Ansible/Terraform modules, etc., open command and statement -Style interface to achieve more Gitops capabilities. These capabilities allow companies to deploy F5 VE soft ADC products faster and better to meet business needs. There is an interesting number. F5 has deployed 50,000 sets of hardware devices in China in 19 years, with an average of more than 2,600 units per year. During the 2020 Spring Festival epidemic alone, it quickly helped users deploy 3000 sets of software ADCs. The advantages of easy deployment of soft loads have been greatly brought into play.\nSubsequently, in 2019, F5 acquired NGINX to further strengthen the soft load market.\nBack to Simple- Service Proxy With the development of application architecture, applications are transforming from traditional monolithic applications to distributed or microservices. Whether it is a distributed or microservice architecture, its core is to split multiple services of an application to form a relatively independent service unit. The direct result of the split is that an additional mechanism is needed to ensure that these independent work units can coordinate and unified work, which is inseparable from distributed computing, storage, messaging, and so on. When these independent service units need to communicate with each other, it is necessary to think about how to make these services that communicate through the network more reliable, safer, and more optimized. This is what the field of application delivery is concerned about, but it has changed from user-oriented and network-oriented to service-oriented. We call it Service Proxy.\nAccess gateways in distributed systems or API gateways for microservices are typical ADC requirements, such as identity recognition, SSL offloading, content routing, application security, current and speed limiting, DDOS, etc. These scenarios have been driven by developers for a long time. Due to the characteristics of the software, it is easier for developers to access software products like NGINX. This is a typical change in user roles compared to traditional ADC products.\nIn environments such as microservices and cloud natives, the communication interface between services is simpler and more unified, which makes the technical requirements for reverse proxy software simpler, and no longer need such a complex and rich special protocol support , No longer need complex network technical characteristics requirements. What is needed is for soft load products to have more dynamic configuration, which can be linked with the registration center and configuration center to realize the discovery of services and the introduction of strategies. The products need to be lightweight and easy to deploy and suitable for virtual machines, containers, etc. The use of these scenarios requires fast enough performance, sufficient observable data, and sufficient flexible deployment capabilities.\n(Under cloud native, it is difficult to directly see a concrete load balancer)\nAround 2017, with the development of cloud native, Service Proxy began to appear in large numbers. There are endless products around Ingress Controller, Sidecar, API Gateway, such as Linkerd, Envoy, Gloo, Mosn and so on. From traditional ADC to today\u0026rsquo;s service-centric modern lightweight decoupled Service Proxy, the technology is returning to a simple Web-oriented load balancing era, client-side load balancing or server-side load balancing.\nAt the end of 2017, F5 launched Aspen Mesh, a commercial service mesh solution product based on Istio. Help users use service grid technology more reliably.\nIn 2019, F5 acquired NGINX. Based on NGINX to create modern application API gateway, K8S Ingress Controller, cloud native application protection, NGINX service grid and other product solutions.\nIn 2021, F5 acquired the start-up Volterra. Help enterprises realize multi-cloud and edge application management based on K8S technology.\nThe launch of these products allows F5 to quickly cover the three directions of cloud-native Service Proxy development.\n(Three directions of Service Proxy development under cloud native)\nFacing the current- Enterprise Cloud Native Application Service When we return to the actual situation of the enterprise and use a picture to express the changes in this related field, we can see that the deployment position of products in the related field is constantly improving, from basic network hardware to a cloud environment. The service component has become a logical resource object in the cloud native environment. From visible and tangible to visible and intangible, from visible and intangible to invisible and intangible. Enterprises should pay full attention to the selection of soft load products that can cover all scenarios to ensure that they can evolve their enterprise application architecture under unified technology and professional services to avoid technical risks.\n(Load balancing, an ever-increasing position)\nCloud native architecture is the future direction of enterprises, but the cloud native architecture of enterprises will not be achieved overnight. It must evolve slowly on top of the company\u0026rsquo;s existing IT infrastructure. In such an evolutionary process, the cloud native environment that the company is building needs to use the company\u0026rsquo;s existing infrastructure. The existing infrastructure of the enterprise must also be changed to the cloud-native environment, and the two need to be integrated with each other.\nThis is true for infrastructure and so are people. With the improvement of enterprise platform-based capabilities, we can clearly see that I\u0026amp;O personnel are becoming the main force of future data center technology innovation. The leading role personnel in this field have changed from network personnel to developers, and ultimately to platform personnel.\nConclusion It can be seen that from 1996 to 2006, and then to 2016. Every 10 years of changes in the application delivery field have echoed the changes in market demand and are in line with the changes in application architecture. From simple Web load balancing to complex enterprise application delivery, from monolithic applications to distributed, microservice architecture. The target audience also ranges from network personnel to application personnel to today\u0026rsquo;s platform and infrastructure personnel. Whether it is the complexity of ADC functions or the simplicity and efficiency of Service Proxy, products in the application delivery field have become the most important infrastructure components for enterprises.\n","date":1626739200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"1481ab1eb3f0387b565e6741069fd8b5","permalink":"http://linjing.io/post/from-lb-to-cloud-native-application-services/","publishdate":"2021-07-20T00:00:00Z","relpermalink":"/post/from-lb-to-cloud-native-application-services/","section":"post","summary":"The history of ADC, the future of Service Proxy, how do you understand the importance of ADC/Service Proxy in your infrastructure.","tags":["F5","ADC","Service Proxy","platform","Cloud native application service"],"title":"From load balancing to cloud native application services","type":"post"},{"authors":["Jing Lin"],"categories":null,"content":"","date":1622556630,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"940ed52fee194f3fecbcdc1652f690b9","permalink":"http://linjing.io/talk/k8s-ingress-gateway-api-evolution/","publishdate":"2021-07-12T00:00:00Z","relpermalink":"/talk/k8s-ingress-gateway-api-evolution/","section":"talk","summary":"Understand the issue of current ingress, knowing the new gateway API for ingress","tags":["Ingress","Egress","feature"],"title":"The evolution of K8s Ingress gateway API","type":"talk"},{"authors":["Jing Lin"],"categories":null,"content":"","date":1622124630,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"1fe7c1df93dfeb85b2f5512a78bd79fe","permalink":"http://linjing.io/talk/f5-kube-ovn/","publishdate":"2021-06-11T00:00:00Z","relpermalink":"/talk/f5-kube-ovn/","section":"talk","summary":"ingress,egress solution for PaaS","tags":["Ingress","Egress","feature"],"title":"Integration of PaaS and infrastructure (F5 and Kube-OVN joint solution introduction)","type":"talk"},{"authors":["Jing Lin (林静)"],"categories":[],"content":"The port and protocol in the Gateway resource define the listener port and protocol in ingressgateway (envoy).\nHowever, the port in Gateway can be set to the port or targetPort of the ingressgateway svc, and finally the targetPort is used in envoy.\nFor example below, the port is defined as 443 in Gateway:\napiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: namespace: istio-bookinfo name: bookinfo-gateway spec: selector: istio: ingressgateway # use istio default controller servers: - port: number: 8080 name: http protocol: HTTP hosts: - \u0026quot;*\u0026quot; - port: number: 443 #####use for assembling the route name that under the listener name: https #####use for assembling the route name that under the listener protocol: HTTPS #####use for assembling the route name that under the listener tls: mode: SIMPLE serverCertificate: /etc/istio/ingressgateway-certs/tls.crt privateKey: /etc/istio/ingressgateway-certs/tls.key hosts: - \u0026quot;*\u0026quot; While, when you check the envoy configurations, the listener port actually is 8443\n[root@k8s-master-v1-16 networking]# istioctl proxy-config listener istio-ingressgateway-7b869dcfb5-lfqz9.istio-system --port 8443 -o json [ { \u0026quot;name\u0026quot;: \u0026quot;0.0.0.0_8443\u0026quot;, \u0026quot;address\u0026quot;: { \u0026quot;socketAddress\u0026quot;: { \u0026quot;address\u0026quot;: \u0026quot;0.0.0.0\u0026quot;, \u0026quot;portValue\u0026quot;: 8443 《《《《《8443！！ } }, \u0026quot;filterChains\u0026quot;: [ { \u0026quot;filters\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;envoy.http_connection_manager\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.network.http_connection_manager.v2.HttpConnectionManager\u0026quot;, \u0026quot;statPrefix\u0026quot;: \u0026quot;outbound_0.0.0.0_8443\u0026quot;, \u0026quot;rds\u0026quot;: { \u0026quot;configSource\u0026quot;: { \u0026quot;ads\u0026quot;: {} }, ###The route name is assembled by protocol + port number + portname, Note here: use 443,not 8443 \u0026quot;routeConfigName\u0026quot;: \u0026quot;https.443.https.bookinfo-gateway.istio-bookinfo\u0026quot; }, This is because the ingressgateway\u0026rsquo;s 443 svc port is corresponding to targetPort 8443:\n - name: https nodePort: 30975 port: 443 protocol: TCP targetPort: 8443 If the port is defined as 8443 in the gateway, the result is same, will generate 8443 listener in envoy.\nWhen there is only one gateway definition, it is ok to use port or the corresponding targetport of the ingressgateway, both will get the same listener port in evnoy lastly. But please be noted, if there are multiple gateway definitions and set same protocol, then the port in the gateways must be same. Otherwise, the listener will only associate the routeConfigName generated by the gateway that created afterwards, and the associated route will not contain the virtualservice logic that related to the first created gateway.\nFor example, configure HTTP:8080 in the gateway in the istio-bookinfo namespace (the svc 80 of ingressgateway corresponds to the 8080 of the pod):\napiVersion: v1 items: spec: selector: istio: ingressgateway servers: - hosts: - '*' port: name: http number: 8080 protocol: HTTP - hosts: - istiobookinfo.lab.f5se.io port: name: https number: 443 protocol: HTTPS The gateway in the httpbin namespace configures HTTP：80，\n[root@k8s-master-v1-16 httpbin]# kubectl get gateways.networking.istio.io -n httpbin -o yaml apiVersion: v1 items: spec: selector: istio: ingressgateway servers: - hosts: - httpbin.lab.f5se.io port: name: http-httpbin number: 80 protocol: HTTP This leads to the fact that the envoy listener is actually actually associated with the later created http.80 route:\n[root@k8s-master-v1-16 ~]# istioctl proxy-config listener istio-ingressgateway-7b869dcfb5-gh2vr.istio-system --port 8080 -o json [ { \u0026quot;name\u0026quot;: \u0026quot;0.0.0.0_8080\u0026quot;, \u0026quot;address\u0026quot;: { \u0026quot;socketAddress\u0026quot;: { \u0026quot;address\u0026quot;: \u0026quot;0.0.0.0\u0026quot;, \u0026quot;portValue\u0026quot;: 8080 } }, \u0026quot;filterChains\u0026quot;: [ { \u0026quot;filters\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;envoy.http_connection_manager\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.network.http_connection_manager.v2.HttpConnectionManager\u0026quot;, \u0026quot;statPrefix\u0026quot;: \u0026quot;outbound_0.0.0.0_8080\u0026quot;, \u0026quot;rds\u0026quot;: { \u0026quot;configSource\u0026quot;: { \u0026quot;ads\u0026quot;: {} }, \u0026quot;routeConfigName\u0026quot;: \u0026quot;http.80\u0026quot; Therefore, in these multi gateways configuration, which ultimately shares the listener port, the port number and protocol name need to be the same (BEST practice is using the port number that envoy actually listens to), but the port must be named differently (if the port name is the same, envoy will show the conflicting configuration logs):\n2020-07-10T09:56:26.192152Z\twarning\tenvoy config\t[external/envoy/source/common/config/grpc_subscription_impl.cc:101] gRPC config for type.googleapis.com/envoy.api.v2.Listener rejected: Error adding/updating listener(s) 0.0.0.0_8080: duplicate listener 0.0.0.0_8080 found Gateways with the same protocol and the same port, no matter whether they are in the same namespace, can only share one listener in envoy, so they will also share same route. If you accidentally configure the same virtualservice under different namespaces at this time, it will cause envoy to generate two identical match conditions in the same route (and the associated cluster is different namespace suffix, This resulting in abnormal access)\nCheck more istio practice detail at my tech blog https://imesh.club\n","date":1594598400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"a522238c0c63d42cbb51083a954b0bff","permalink":"http://linjing.io/post/istio-ingressgateay-port-relationship/","publishdate":"2020-07-13T00:00:00Z","relpermalink":"/post/istio-ingressgateay-port-relationship/","section":"post","summary":"Dont set wrong port in Gateway.","tags":["istio","envoy","gateway port","ingressgateway"],"title":"The rule of Istio Gateway port definition","type":"post"},{"authors":["Jing Lin (林静)"],"categories":[],"content":"Foreword Envoy, messenger, envoy, representative! Just like the meaning of the word itself, with a sense of authority, a sense of sacred full agent. Combined with its own use and role, it is really \u0026ldquo;people as their name\u0026rdquo;, can\u0026rsquo;t help but like Lyft, I don\u0026rsquo;t know which master got the name to get this name. In the current era of fiery microservices, Envoy is an absolute star, and it is no exaggeration to describe it as everyone knows. Someone once asked me how to look at Envoy and whether Envoy will replace F5 instead of NGINX in the cloud-native era. As a veteran who has experienced two waves of change in the field of application delivery technology, in this article I will talk about Envoy in the future From a perspective to understand and answer this question. Why talk a little bit, this is really not modesty, but objectively, there is really no such in-depth large-scale long-term use and research of all technical details of Envoy, so I will combine my professional experience and experience to make an Envoy Talk.\nStar-studded Envoy First, let\u0026rsquo;s take a look at how Envoy officially introduced Envoy:\n ENVOY IS AN OPEN SOURCE EDGE AND SERVICE PROXY, DESIGNED FOR CLOUD-NATIVE APPLICATIONS\n From this description on the homepage of the website, we can clearly see the official definition of Envoy, which is simply a proxy for east-west, north-south traffic in the cloud native era. Lfyt is the pioneer of the microservice application architecture. We can see Lfyt in a large number of microservice sermon articles. After a large-scale shift from monolithic applications to microservice architecture, a serious problem was placed in development. In front of the architects, on the one hand, Lyft\u0026rsquo;s services are developed in multiple languages, and the use of class libraries to solve various problems under the distributed architecture requires a lot of language adaptation and code intrusion. On the other hand, Lyft\u0026rsquo;s business Both are deployed on AWS, relying heavily on AWS\u0026rsquo; ELB and EC2, but the traffic control, insight, and problem elimination between the services provided by ELB and AWS at that time could not meet Lyft\u0026rsquo;s needs. It is based on this background, Lfyt is Envoy development started in May 2015. It was first deployed as an edge agent and began to replace ELB, and then began to be deployed as a sidecar method for large-scale deployment. On September 14, 2016, Lyft officially announced this project on its blog: Envoy C++ L7 proxy and communication bus . For a while, Envoy received a lot of attention, and companies such as Google began to contribute to this project, and donated the project to CNCF one year later in September 2017. With a good mom like Lyft, and the succession to CNCF as a rich dad, plus the half-brother Istio star brother\u0026rsquo;s blessing, it can be said that Envoy has a good scene for a while, earning enough eyeball and developer support, I graduated from CNCF in just over a year.\nContainer technology has helped enterprises practice Devops and microservice transformation. The k8s container orchestration platform allows enterprises to move more business from traditional architectures to modern container-based infrastructures with more confidence. k8s solves container orchestration and applications. Issues such as publishing, but when the communication between services has changed from the previous call between memory to TCP-based network communication, the impact of the network on application services has become more huge and uncertain, based on traditional application architecture operation and maintenance The means cannot adapt and solve the huge and complex communication insights and troubleshooting between services. In order to solve such problems, the service mesh application was born and quickly became a hot topic of concern. The Istio project is the most important player in this ecosystem. Istio\u0026rsquo;s architecture is a typical management plane and data separation architecture. The choice of data plane is open, but Istio chooses Envoy as the data plane by default. The two popular stars joined forces to make Linkerd eclipsed almost at the same time. At this point in time, NGINX also briefly carried out the Nginmesh project, trying to make NGINX as the data plane of Istio, but eventually gave up at the end of 2018, why did you give up, this article will be mentioned later.\nIn addition to Istio\u0026rsquo;s selection of Envoy as the data plane, there are many projects based on Envoy, such as multiple Ingress Controller projects of k8s: Gloo, Contur, Ambassador. Istio\u0026rsquo;s own Ingress gateway and Egress gateway also choose Envoy. Take a look at the Envoy users listed on their official homepage and say that starlight is not too much. Note that F5 in the list is very interesting.\n(Envoy end user list)\nEnvoy: born for the times Below I will look at the technical aspects of why Envoy is so valued by the community. It will be summarized from the following aspects:\n Technical characteristics Deployment architecture Software Architecture  Technical characteristics  Interface and API Dynamic Scalability Observability Modernity  Interface and API When I first opened the configuration of Envoy, my first feeling was, God, how should such a product user configure and use. Under the intuitive experience, in an uncomplicated experimental environment, the number of lines of an Envoy\u0026rsquo;s actual configuration file actually reached 20,000 lines.\n# kubectl exec -it productpage-v1-7f4cc988c6-qxqjs -n istio-bookinfo -c istio-proxy -- sh $ curl http://127.0.0.1:15000/config_dump | wc -l % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 634k 0 634k 0 0 10.1M 0 --:--:-- --:--:-- --:--:-- 10.1M 20550 Although this is a dynamic configuration in the Istio environment, although there are ways to optimize it to reduce the actual configuration amount, or that we will not do such a large amount of configuration when using the static configuration method for configuration, but when we see the following actual The configuration structure output will feel that for such a software, it is obviously impractical to configure and maintain in a normal way. Its configuration is completely json structured and has a large number of descriptive configurations. Compared to NGINX and other such reverse For agent software, its configuration structure is too complicated.\n(Complex configuration structure)\nObviously, Envoy\u0026rsquo;s design is not designed for manual, so Envoy designed a large number of xDS protocol interfaces, users need to design an xDS server to implement all configuration processing, Envoy supports gRPC or REST to communicate with the server to update Own configuration. xDS is the general name of the Envoy DS (discover service) protocol, which can be divided into Listener DS (LDS), Route DS (RDS), Cluster DS (CDS), Endpoint DS (EDS), and Secret DS in order to ensure consistent configuration DS-ADS of polymerization and the like, may be more xDS view here . These interfaces are used to automatically generate various specific configuration objects. It can be seen that this is a highly dynamic runtime configuration. To use it well, you must develop a server with sufficient capabilities. Obviously this is not the design thinking of traditional reverse proxy software.\n(Picture from https://gist.github.com/nikhilsuvarna/bd0aa0ef01880270c13d145c61a4af22 )\nDynamic As mentioned earlier, Envoy\u0026rsquo;s configuration relies heavily on interface automation to generate various configurations. These configurations can be modified by Runtime without reloading files. In modern application architectures, the life cycle of a service endpoint becomes shorter and its operation Uncertainty or resilience has become greater, so the ability to make runtime changes to the configuration without having to reload the configuration file is particularly valuable in modern application architectures, which is an important consideration for Istio\u0026rsquo;s choice of Envoy as the data plane. Envoy also has a hot restart capability, which makes it more elegant when an upgrade or a restart is necessary, and existing connections can be protected more.\nIn the Istio scenario, Envoy\u0026rsquo;s container runs two processes, one called pilot-agent and one is envoy-proxy itself. The pilot-agent is responsible for managing and starting Envoy, and generates an envoy under /etc/istio/proxy/ -rev0.json Initial configuration file, this file defines how Envoy should communicate with the pilot server to obtain the configuration, and use this configuration file to finally start the Envoy process. However, the final configuration of Envoy is not only the content in envoy-rev0.json, it contains all the dynamic configurations discovered through the xDS protocol mentioned above.\n# kubectl exec -it productpage-v1-7f4cc988c6-qxqjs -n istio-bookinfo -c istio-proxy -- sh $ ps -ef UID PID PPID C STIME TTY TIME CMD istio-p+ 1 0 0 Jun25 ? 00:00:33 /usr/local/bin/pilot-agent proxy sidecar --domain istio-bookinfo.svc.cluster.local --serviceCluster productpage.istio-bookinfo --proxyLogLevel=warning --proxyComp istio-p+ 14 1 0 Jun25 ? 00:05:31 /usr/local/bin/envoy -c etc/istio/proxy/envoy-rev0.json --restart-epoch 0 --drain-time-s 45 --parent-shutdown-time-s 60 --service-cluster productpage.istio-bookin istio-p+ 142 0 0 15:38 pts/0 00:00:00 sh istio-p+ 148 142 0 15:38 pts/0 00:00:00 ps -ef In the envoy overall configuration dump of the following figure, you can see that the contents of bootstrap and other static and dynamic configurations are included:\n(Envoy configuration structure)\nCombined with the following figure, you can see the basic Envoy configuration structure and its logic, whether it is an entrance listener (similar to F5\u0026rsquo;s VS and part of the profile configuration, NGINX\u0026rsquo;s listener and some Server paragraph configuration) or routing control logic (similar to F5 LTM policy, NGINX\u0026rsquo;s Various Locations matching, etc., or Clusters (similar to F5 pool, NGINX upstream), Endpoints (similar to F5 pool member, NGINX upstream server), and even SSL certificates can be automatically discovered from the service side through the interface\n(picture (From https://gist.github.com/nikhilsuvarna/bd0aa0ef01880270c13d145c61a4af22 )\nScalability A lot of filters can be seen in the configuration of Envoy. These are the performance of its scalability. Envoy learned the architecture of F5 and NGINX, and used a lot of plug-ins to make it easier for developers to develop. From the start of listener, it supports the use of filter, and supports developers to develop L3, L4, L7 plug-ins to achieve protocol expansion and more control.\nIn practice, companies may not have as many C++ development reserves as languages ​​such as JavaScript, so Envoy also supports Lua and Webassembly extensions. This aspect eliminates the need to frequently recompile binaries and restart, and on the other hand reduces enterprise plug-in development. Difficulty, so that companies can use more Webassembly compatible languages ​​for plug-in writing, and then compile to Webassenmbly machine code to achieve efficient operation. At present, Envoy and Istio are still in the early stages of using Webassembly for expansion, and it will take some time to mature.\n(Picture from https://www.servicemesher.com/istio-handbook/concepts/envoy.html )\nAs can be seen from the above figure, such a request processing structure is very close to the design idea of ​​the F5 TMOS system, and is similar to NGINX to a certain extent. Connections and requests correspond to different processing components at different protocol levels and stages, and these components are themselves extensible and programmable, which in turn enables flexible programming control of the data flow.\nObservability It is said that Envoy is born with the characteristics of cloud native. One of the characteristics is the emphasis on observability. You can see the three observable components: logs, metrics, and tracing are all supported by Envoy by default.\nEnvoy allows users to define flexible log formats in flexible locations in a flexible manner. These changes can be delivered through dynamic configuration to achieve immediate effect, and allows the definition of sampling of logs. In Metrics, it provides many indicators that can be integrated with Prometheus. It is worth mentioning that Envoy allows the filter itself to expand these indicators. For example, in the filter such as current limiting or verification, the plug-in itself is allowed to define its own indicators to help users better. Use and quantify the operational status of the plugin. In terms of Tracing, Envoy supports integration with third parties such as zipkin, jaeger, datadog, lightStep, etc. Envoy can produce a uniform request ID and keep it spread throughout the network structure. It also supports external x-client-trace-id to achieve A description of the relationship topology between microservices.\nEach span generated by Envoy contains the following data:\n Set by the \u0026ndash;service-clusteroriginal service cluster information. The start time and duration of the request. Set by the \u0026ndash;service-nodeoriginal host information. By x-envoy-downstream-service-clusterdownstream cluster header set. HTTP request URL, method, protocol and user agent. By custom_tagsanother custom label settings. The upstream cluster name and address. HTTP response status code. GRPC response status and messages (if available). Error flag when HTTP status is 5xx or GRPC status is not \u0026ldquo;OK\u0026rdquo;. Track system-specific metadata.  Modernity In fact, it is obviously correct nonsense to say that Envoy has modernity. Envoy was born for modern application architecture. Here we mainly want to explain from several aspects that we can most easily feel. The first is its special structural design. In Envoy, it supports the use of iptables to intercept the traffic and do transparent processing. It can use getsockopt () to extract the original destination information in the NAT entry, and allow listeners to listen on the listener. The transferred port listener jumps to an unbound listener that actually matches the original destination information. Although from the perspective of a reverse proxy, this is a bit like F5\u0026rsquo;s VS internal jump, NGINX\u0026rsquo;s subrequest, but its biggest feature and ability lies in transparent connection, which is especially important in the deployment Pod sidecar mode, refer to specific principles herein .\nFor the gray-scale publishing, traffic mirroring, circuit breaker, global current limiting and other functions that are favorite for modern applications, its configuration is also very simple. Although F5/NGINX and other software can also accomplish similar tasks, they are native Envoy has greater advantages in terms of ease of configuration and ease of configuration.\nAnother manifestation of modernity is the support of the protocol. Look at the following supported protocols. Students who are familiar with application delivery and reverse proxy software may not help but express their admiration. The support of these protocols on the other hand shows Envoy’s A feature that is more oriented towards developers and SRE.\n gRPC HTTP2 MongoDB DynamoDB Redis Postgres Kafka Dubbo Thrift ZooKeeper RockeMQ  Deployment architecture After understanding the technical characteristics of Envoy, let\u0026rsquo;s look at Envoy from the perspective of deployment architecture.\nComplete Sidecar model deployment, which is the biggest deployment feature of Envoy. The communication between services is completely transformed into the communication between Envoy agents, so that many non-business functions are removed from the service code to external proxy components. Envoy is responsible for network communication control Observable with flow. It can also be deployed as a simplified sidecar, which only acts as a proxy for the inbound direction of service without additional traffic manipulation. This structure is used in the external observability based on NGINX to achieve business observability Hub type, which is the same as the Router-mesh type concept in NGINX\u0026rsquo;s MRA. All services use a centralized Envoy to communicate. This deployment structure is generally suitable for small and medium-sized services. Service flow can be directed by adapting to service registration. To Envoy Envoy can also be used as an Ingress edge gateway or Egress gateway. In this scenario, Envoy is generally used for Ingress controller or API gateway. You can see that many such implementations like to use Envoy as the underlying layer, such as Gloo, Ambassador, etc. The following deployment structure should be familiar to everyone. As an Edge gateway, Envoy also deploys an additional layer of microservice gateway (or proxy platform layer) Finally, this is to integrate all forms of Envoy deployment. This architecture may be in the middle of the process of migrating services from traditional architecture to microservice architecture Ok, take a look at how Envoy is used in Istio In summary, due to the cross-platform nature of Envoy, it has the same flexible deployment structure as NGINX, but in fact the deployment structure often has a strong relationship with the final configuration implementation mechanism, can the software\u0026rsquo;s ability adapt to the flexibility under this structure Implementation with simple configuration is the ultimate test. Objectively speaking, Envoy has an advantage in this respect.\nSoftware Architecture Envoy adopts a single-process multi-thread design structure, and the main thread is responsible for configuration updates and process signal processing. Requests are handled by multiple worker threads. In order to simplify and avoid processing complexity, a connection is always handled by one thread, which can minimize some lock operations caused by data sharing between threads. Envoy avoids state sharing between threads as much as possible, and designed the Thread Local Store mechanism for this purpose. In the log writing, the worker thread actually writes to the memory cache, and finally the file refresh thread is responsible for writing to the disk, which can improve efficiency to a certain extent. Overall, Envoy is still more focused on simplifying complexity and emphasizing flexibility, so unlike NGINX, it does not put the pursuit of performance in the first place, which can be obtained in the relevant official blog of Envoy verification.\nSimilar to NGINX, Envoy is an asynchronous, non-blocking design, using an event-driven approach. Each thread is responsible for each listener, SO_REUSEPORT can also be used to share sockets, NGINX also has a similar mechanism.\nAfter the listener listens and starts processing, the connection will be processed by subsequent L3, 4, 7 and other filters according to the configuration.\nF5/NGINX: the sword is not out After understanding the technical characteristics and architecture of Envoy, we return to the original point of this article. Envoy has been carrying the genes of modern application architecture from birth, does it mean that these front waves such as NGINX/F5 are out of date.\nI remember the author of NGINX, Igor, at the F5 China 520 conference to explain why NGINX is so successful. He said that he did not expect to be so successful because the reason is that he developed the right software at the right time. We know that during the period around 2003, there was still no talk about distributed architecture and microservices. At that time, the main problem to be solved was stand-alone performance. Based on this background, NGINX is strict in terms of architecture design and code quality. Demanding performance. In terms of functionality, NGINX was originally a Web Server software, L7 reverse proxy is an extension of its capabilities, and L4 proxy capabilities increase even later. In view of this background, from the perspective of modern application architecture, there are indeed some Capability is more difficult to cover. Similarly, Envoy was born and developed in the era of modern application architecture. As Envoy self-explained, it refers to a large number of existing hardware and software reverse proxy and load balancing products. From the above technical analysis, it can also be seen that Envoy has many NGINX and F5 Architectural concept, it can be said that Envoy draws many essences from mature reverse proxy products, and fully considers the needs of modern application architecture when designing, it is also a correct software at the right time.\nUnder the microservices architecture, many problems have become how to control the communication and traffic insights between services. This is a typical application delivery field. As a frontier in this field, on the one hand, we must actively embrace and adapt to the new era of application architecture. On the one hand Need to innovate and continue to lead new directions. There have been two technological innovations in this field in history. The first was around 2006, when the topic of \u0026ldquo;load balancing was dead\u0026rdquo; was fired. The essence was that the market began to change at that time, and everyone was no longer satisfied with simple loads. Balanced, demand is derived from more complex scenarios such as application security, network optimization, application optimization, access control, and flow control. The concept of application delivery began to be proposed. It can be said that before 2006, the main concepts and technical directions of the market were based on The four-layer switch is the core concept of load balancing technology. Most players are traditional network manufacturers. The thinking and concepts are based on network switching. F5 is like a strange guy. The product design thinking is completely on another dimension. The TMOS V9 operating system, which has been released since 2004, has led the market since then, and no one has surpassed it for 10 years thereafter. The second technological innovation occurred around 2016. Affected by the cloud and microservices, software and lightweight became the mainstream of the market. At the same time, Devops thought means that the role of users has changed. The traditional design for network operation and maintenance personnel It began to become difficult to meet market demand. The field dominated by F5 has also undergone new changes in the market. Gartner no longer publishes magic quadrant analysis in the field of application delivery, and instead forms guidance in the way of Guide.\nLooking at the present, history is always surprisingly similar.\nThe modern application architecture is developing rapidly, and a large number of applications are beginning to be micro-serviced. However, from the perspective of the overall chain of business access, Envoy cannot solve all problems, such as application security protection, complex enterprise protocols, and different needs caused by different organizational relationships. It can be seen that the application delivery products represented by F5/NGINX have also begun to actively realize product integration under the Devops tide. F5 has released a complete automated tool chain, from the product’s bootstrap to network configuration, to application service configuration, to the final Monitoring and telemetry have formed a complete interface, and use declarative interface to promote product management to a higher role crowd and management system. NGINX also builds its own API and Controller plane, and provides a declarative API interface to the outside world. Developers can better use the interface to integrate into their own control plane. These changes are for developers or SRE to better use F5/NGINX. For details, please refer to my \u0026ldquo;From Traditional ADC to Cloud Native ADC\u0026rdquo; series of articles.\nAfter acquiring NGINX and Shape, F5 put forward a new view that will make full use of the widely accessible data plane capabilities, and use AI to further tap the data potential to help users better grasp and understand application behavior and performance, and provide references for business operations. , And feedback to component configuration and operation management to form a closed loop.\nAn important scenario for modern application delivery is still indispensable, that is, application security. Although Istio and other products have made many attempts in secure communication, identity, and strategy, application security itself is relatively lacking. F5 is a leading manufacturer in the field of WAF security Through the transfer of security capabilities to NGINX, a new NGINX APP Protect is formed, which uses its cross-platform capabilities to help users better manage application security capabilities in microservice scenarios and help enterprises better implement DevSecOps.\nIf we compare the technical features of Envoy with F5, we can see that F5 lacks scalability and modernity to a certain extent. F5 has good programming control capabilities, but it is relatively larger than the development of larger plug-ins. Insufficient, this and modernity can often be linked together. For example, if you want to make a complex 7-layer filter similar to Envoy for a very new protocol, it is impossible to achieve, although iRule or iRuleLX can do something to a certain extent. However, in any case, the final product form of F5 itself determines that F5\u0026rsquo;s BIGIP cannot be completely cross-platform, because it cannot run as a container. It is worth expecting that such morphological restrictions will be broken by F5\u0026rsquo;s next-generation TMOS system.\nService Mesh is the current popular technology direction. F5 builds an enterprise-level Aspen Mesh service mesh product based on Istio, which helps enterprises deploy and use Istio better and easier. Aspen mesh team members enter the Istio Technical Oversight Committee with only 7 positions and are responsible for the important responsibilities of Istio\u0026rsquo;s RFCs/Designs/APIs. Although Istio has absolute ecology and popularity in the field of service mesh, this does not mean that Istio is the only choice. In many cases, customers may want to adopt a more concise Service Mesh to achieve most of the required functions instead of deploying one. The entire complex Istio solution, NGINX Service Mesh (NSM) based on NGINX components will bring new choices to users, a more simple and easy to use Service Mesh product, this is the reason why we mentioned NGINX to terminate Nginmesh at the beginning of the article .\nConclusion Technology development is an inevitable process. In 2006, it evolved from traditional load balancing technology to application delivery. In addition to load balancing, it introduced many aspects such as security, access control, access control, and flow control. Around 2016, new technological changes have occurred in this field again. The emergence of a large number of new generation reverse proxy open source software has a new impact on traditional application delivery products. Active adaptation and change and innovation are the key to winning. Envoy has excellent capabilities as a new representative, but it is not a silver bullet to solve all problems. Envoy has a steeper learning curve and higher development and maintenance costs. For enterprises, they should choose the appropriate solution and Products to solve different problems in the architecture, to avoid catching the trend and let yourself fall into the trap.\nF5 needs more to let developers understand the huge potential of TMOS system (especially the subversion of the next generation products in architecture and form), understand its excellent all-agent architecture and program control at any level, so that developers, SRE develops with F5 TMOS as a capability platform and middleware, and better utilizes F5\u0026rsquo;s own application delivery capabilities to quickly realize its own needs.\nFinally, again quote a sentence from the homepage of the official Envoy website:\n As microservice practitioners soon realized, most of the operational problems that arise when moving to a distributed architecture are ultimately based on two aspects: network and observability.\n And to ensure more reliable network delivery and better observability is the strength of Qianlang. Innovate, Qianlang.\nWritten at the end: No matter how the technology changes, the human factor is still the core, regardless of the company or the manufacturer, in such a wave of technology, it should have sufficient technical reserves, just like the traditional financial industry through the establishment of technology companies to seek transformation, Manufacturers also need to be transformed. F5 China\u0026rsquo;s SE has almost 100% passed the CKA certification. Regardless of the relative proportion or absolute number, it should be unique in the industry. The transformation is not only in products, but also in thinking.\nCheck more istio practice detail at my tech blog https://imesh.club\n","date":1593475200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"30d23fc35c54861f575702fe3fce3d74","permalink":"http://linjing.io/post/f5-envoy-cloud-native/","publishdate":"2020-06-30T00:00:00Z","relpermalink":"/post/f5-envoy-cloud-native/","section":"post","summary":"How to understand envoy, compare to F5/NGINX.","tags":["f5","nginx","envoy"],"title":"How an application delivery veteran see Envoy in the era of cloud native","type":"post"},{"authors":["Jing Lin (林静)"],"categories":null,"content":"Check here for full article The link.\n","date":1593475200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"bd3748974692947a32ee94a47b7a983a","permalink":"http://linjing.io/publication/envoy-2020-6/","publishdate":"2020-06-30T00:00:00Z","relpermalink":"/publication/envoy-2020-6/","section":"publication","summary":"What’s right direction for ADN evolution during the dramatic market change? Lots of different noises and arguments are arising.","tags":["envoy","cloud native","istio","f5","nginx"],"title":"What changes does envoy bring to ADN","type":"publication"},{"authors":["Jing Lin (林静)"],"categories":[],"content":"Istio injected iptables Istio implements the hijacking and processing of traffic by injecting the init container and envoy proxy container into the business pod. After the init container runs, the following NAT table rules for iptables will be generated in the corresponding linux namespace\n\u0026amp;#91;root@k8s-node1-v1-16 ~]# iptables -t nat -L -v Chain PREROUTING (policy ACCEPT 192K packets, 12M bytes) pkts bytes target prot opt in out source destination 192K 12M ISTIO_INBOUND tcp -- any any anywhere anywhere Chain INPUT (policy ACCEPT 192K packets, 12M bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 40673 packets, 3694K bytes) pkts bytes target prot opt in out source destination 8917 535K ISTIO_OUTPUT tcp -- any any anywhere anywhere Chain POSTROUTING (policy ACCEPT 40673 packets, 3694K bytes) pkts bytes target prot opt in out source destination Chain ISTIO_INBOUND (1 references) pkts bytes target prot opt in out source destination 0 0 RETURN tcp -- any any anywhere anywhere tcp dpt:ssh 356 21360 RETURN tcp -- any any anywhere anywhere tcp dpt:15090 192K 11M RETURN tcp -- any any anywhere anywhere tcp dpt:15021 0 0 RETURN tcp -- any any anywhere anywhere tcp dpt:15020 34 2040 ISTIO_IN_REDIRECT tcp -- any any anywhere anywhere Chain ISTIO_IN_REDIRECT (3 references) pkts bytes target prot opt in out source destination 34 2040 REDIRECT tcp -- any any anywhere anywhere redir ports 15006 Chain ISTIO_OUTPUT (1 references) pkts bytes target prot opt in out source destination 0 0 RETURN all -- any lo 127.0.0.6 anywhere 0 0 ISTIO_IN_REDIRECT all -- any lo anywhere !localhost owner UID match 1337 0 0 RETURN all -- any lo anywhere anywhere ! owner UID match 1337 8917 535K RETURN all -- any any anywhere anywhere owner UID match 1337 0 0 ISTIO_IN_REDIRECT all -- any lo anywhere !localhost owner GID match 1337 0 0 RETURN all -- any lo anywhere anywhere ! owner GID match 1337 0 0 RETURN all -- any any anywhere anywhere owner GID match 1337 0 0 RETURN all -- any any anywhere localhost 0 0 ISTIO_REDIRECT all -- any any anywhere anywhere Chain ISTIO_REDIRECT (1 references) pkts bytes target prot opt in out source destination 0 0 REDIRECT tcp -- any any anywhere anywhere redir ports 15001 Outbound flow control When the business container sends the request to the outside, such as productpage to reviews: 9080 port access, this connection will be redirected by iptables to port 127.0.0.1:115001, and then processed by envoy.\n REDIRECT This target is only valid in the nat table, in the PREROUTING and OUTPUT chains, and user-defined chains which are only called from those chains. It redirects the packet to the machine itself by changing the destination IP to the primary address of the incoming interface (locally-generated packets are mapped to the localhost address, 127.0.0.1 for IPv4 and ::1 for IPv6).\nhttps://ipset.netfilter.org/iptables-extensions.man.html#lbDK\n The virtualOutbound in envoy will be hit. This is a special listener. It contains the Original Destination listener filter. Note \u0026ldquo;useOriginalDst\u0026rdquo;: truethat after such configuration in the following configuration , envoy will re-find the matching listener in the configuration. If found, press the hit. The listener performs follow-up processing. If it cannot find it, it sends the request to the cluster in this listener. Here is a passthrough cluster. This cluster will forward the packet directly to the fourth layer.\nroot@k8s-master-v1-16 ~]# istioctl proxy-config listener productpage-v1-7f4cc988c6-qxqjs.istio-bookinfo --port 15001 -o json \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;virtualOutbound\u0026quot;, \u0026quot;address\u0026quot;: { \u0026quot;socketAddress\u0026quot;: { \u0026quot;address\u0026quot;: \u0026quot;0.0.0.0\u0026quot;, \u0026quot;portValue\u0026quot;: 15001 } }, \u0026quot;filterChains\u0026quot;: \u0026amp;#91; { \u0026quot;filters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;istio.stats\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.extensions.filters.network.wasm.v3.Wasm\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;config\u0026quot;: { \u0026quot;configuration\u0026quot;: \u0026quot;{\\n \\\u0026quot;debug\\\u0026quot;: \\\u0026quot;false\\\u0026quot;,\\n \\\u0026quot;stat_prefix\\\u0026quot;: \\\u0026quot;istio\\\u0026quot;\\n}\\n\u0026quot;, \u0026quot;root_id\u0026quot;: \u0026quot;stats_outbound\u0026quot;, \u0026quot;vm_config\u0026quot;: { \u0026quot;code\u0026quot;: { \u0026quot;local\u0026quot;: { \u0026quot;inline_string\u0026quot;: \u0026quot;envoy.wasm.stats\u0026quot; } }, \u0026quot;runtime\u0026quot;: \u0026quot;envoy.wasm.runtime.null\u0026quot;, \u0026quot;vm_id\u0026quot;: \u0026quot;tcp_stats_outbound\u0026quot; } } } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.tcp_proxy\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.network.tcp_proxy.v2.TcpProxy\u0026quot;, \u0026quot;statPrefix\u0026quot;: \u0026quot;PassthroughCluster\u0026quot;, \u0026quot;cluster\u0026quot;: \u0026quot;PassthroughCluster\u0026quot;, \u0026quot;accessLog\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;envoy.file_access_log\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.accesslog.v2.FileAccessLog\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/dev/stdout\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;\u0026amp;#91;%START_TIME%] \\\u0026quot;%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%\\\u0026quot; %RESPONSE_CODE% %RESPONSE_FLAGS% \\\u0026quot;%DYNAMIC_METADATA(istio.mixer:status)%\\\u0026quot; \\\u0026quot;%UPSTREAM_TRANSPORT_FAILURE_REASON%\\\u0026quot; %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \\\u0026quot;%REQ(X-FORWARDED-FOR)%\\\u0026quot; \\\u0026quot;%REQ(USER-AGENT)%\\\u0026quot; \\\u0026quot;%REQ(X-REQUEST-ID)%\\\u0026quot; \\\u0026quot;%REQ(:AUTHORITY)%\\\u0026quot; \\\u0026quot;%UPSTREAM_HOST%\\\u0026quot; %UPSTREAM_CLUSTER% %UPSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_REMOTE_ADDRESS% %REQUESTED_SERVER_NAME% %ROUTE_NAME%\\n\u0026quot; } } ] } } ], \u0026quot;name\u0026quot;: \u0026quot;virtualOutbound-catchall-tcp\u0026quot; } ], \u0026quot;useOriginalDst\u0026quot;: true, \u0026quot;trafficDirection\u0026quot;: \u0026quot;OUTBOUND\u0026quot; } ] The above listener will hand over the connection to the listener that matches the original destination IP and port. In the bookinfo example, it will be handed over to the 9080 listener. There is a question to consider here. From the perspective of envoy, the destination port of this link is already 15001, why can it match the following port 0.0.0.0:9080. This is because the NAT is done in the system kernel when iptables is redirected. The system kernel has this converted storage. Envoy obtains the real destination port through getsockopt() , so that it can correctly match the business listener.\n\u0026amp;#91;root@k8s-master-v1-16 ~]# istioctl proxy-config listener productpage-v1-7f4cc988c6-qxqjs.istio-bookinfo --port 9080 -o json \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;0.0.0.0_9080\u0026quot;, \u0026quot;address\u0026quot;: { \u0026quot;socketAddress\u0026quot;: { \u0026quot;address\u0026quot;: \u0026quot;0.0.0.0\u0026quot;, \u0026quot;portValue\u0026quot;: 9080 } }, \u0026quot;filterChains\u0026quot;: \u0026amp;#91; { \u0026quot;filterChainMatch\u0026quot;: { \u0026quot;applicationProtocols\u0026quot;: \u0026amp;#91; \u0026quot;http/1.0\u0026quot;, \u0026quot;http/1.1\u0026quot;, \u0026quot;h2c\u0026quot; ] }, \u0026quot;filters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;envoy.http_connection_manager\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.network.http_connection_manager.v2.HttpConnectionManager\u0026quot;, \u0026quot;statPrefix\u0026quot;: \u0026quot;outbound_0.0.0.0_9080\u0026quot;, \u0026quot;rds\u0026quot;: { \u0026quot;configSource\u0026quot;: { \u0026quot;ads\u0026quot;: {} }, \u0026quot;routeConfigName\u0026quot;: \u0026quot;9080\u0026quot; }, \u0026amp;#91;root@k8s-master-v1-16 ~]# istioctl proxy-config listener productpage-v1-7f4cc988c6-qxqjs.istio-bookinfo ADDRESS PORT TYPE 10.102.252.88 15012 TCP 10.96.122.225 31400 TCP 10.96.0.10 53 TCP 10.110.88.185 15443 TCP 10.96.122.225 15443 TCP 10.110.88.185 443 TCP 10.102.252.88 443 TCP 10.106.109.172 9001 TCP 10.96.0.1 443 TCP 10.96.122.225 443 TCP 10.106.109.172 9000 TCP 10.105.130.171 14267 HTTP+TCP 10.96.81.27 5601 HTTP+TCP 0.0.0.0 15014 HTTP+TCP 10.105.130.171 14250 HTTP+TCP 0.0.0.0 20001 HTTP+TCP 0.0.0.0 9411 HTTP+TCP 10.111.37.34 9090 HTTP+TCP 10.105.145.36 80 HTTP+TCP 10.105.130.171 14268 HTTP+TCP 10.96.0.10 9153 HTTP+TCP 10.110.244.188 80 HTTP+TCP 10.102.252.88 853 HTTP+TCP 10.99.139.251 16686 HTTP+TCP 0.0.0.0 12345 HTTP+TCP 10.103.155.149 80 HTTP+TCP 0.0.0.0 8000 HTTP+TCP 0.0.0.0 15010 HTTP+TCP 10.96.122.225 15020 HTTP+TCP 0.0.0.0 9090 HTTP+TCP 10.107.150.251 80 HTTP+TCP 0.0.0.0 14250 HTTP+TCP 0.0.0.0 80 HTTP+TCP 0.0.0.0 3000 HTTP+TCP 10.110.28.96 8181 HTTP+TCP 10.102.69.143 9200 HTTP+TCP 0.0.0.0 9080 HTTP+TCP 《《《《《《《《《《《《 0.0.0.0 15001 TCP 《《《《《《《《《《《《 0.0.0.0 15006 HTTP+TCP 0.0.0.0 15090 HTTP 0.0.0.0 15021 HTTP Related passthrough cluster:\nroot@k8s-master-v1-16 ~]# istioctl proxy-config cluster productpage-v1-7f4cc988c6-qxqjs.istio-bookinfo --fqdn PassthroughCluster -o json \u0026amp;#91; 。。。。忽略。。。 { \u0026quot;name\u0026quot;: \u0026quot;PassthroughCluster\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;ORIGINAL_DST\u0026quot;, \u0026quot;connectTimeout\u0026quot;: \u0026quot;10s\u0026quot;, \u0026quot;lbPolicy\u0026quot;: \u0026quot;CLUSTER_PROVIDED\u0026quot;, \u0026quot;circuitBreakers\u0026quot;: { \u0026quot;thresholds\u0026quot;: \u0026amp;#91; { \u0026quot;maxConnections\u0026quot;: 4294967295, \u0026quot;maxPendingRequests\u0026quot;: 4294967295, \u0026quot;maxRequests\u0026quot;: 4294967295, \u0026quot;maxRetries\u0026quot;: 4294967295 } ] }, \u0026quot;filters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;istio.metadata_exchange\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.tcp.metadataexchange.config.MetadataExchange\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;protocol\u0026quot;: \u0026quot;istio-peer-exchange\u0026quot; } } } ] } ] Inbound flow control When it is an inbound request, the destination address of the packet is the IP of the pod, and the destination port is the real port of the business (9080, non-svc mapping port). Since the link destination port of iptables is changed to 15006, it will Hit virtual inbound listener (0.0.0.0:15006), this listener has a series of filterchain, and the virtualoutbound listener configuration method is different, virtualinbound contains a series of actual service filters for specific ports, the connection will find specific in these fitlers Business matching. So how does it match the real 9080 business? For example, the following output: addressPrefix can be matched. If the pod actually has multiple ports, only addressPrefix does not match. It also needs to match the application layer protocol, but the DestinationPort in the Match condition is not matched . In fact, it is similar to Virtualoutbound. The filter of the original destination listener is also used, so envoy will obtain the real destination port and IP from the kernel. This configuration method is different from the virtual outbound \u0026ldquo;useOriginalDst\u0026rdquo;: true configuration method, because this is an updated configuration method.\u0026rdquo; useOriginalDst\u0026rdquo;: true This configuration is about to be abandoned.\n\u0026quot;listenerFilters\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;envoy.listener.original_dst\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.listener.original_dst.v2.OriginalDst\u0026quot; } },\n(According to https://www.envoyproxy.io/docs/envoy/latest/api-v2/api/v2/listener/listener_components.proto, the filtermatch condition is that all must match)\n { \u0026quot;filterChainMatch\u0026quot;: { \u0026quot;destinationPort\u0026quot;: 9080, \u0026quot;prefixRanges\u0026quot;: \u0026amp;#91; { \u0026quot;addressPrefix\u0026quot;: \u0026quot;10.244.2.138\u0026quot;, \u0026quot;prefixLen\u0026quot;: 32 } ], ### 根据https://istio.io/latest/zh/docs/ops/deployment/requirements/ , ### 同一个业务端口是不能被两个用不同协议的svc来发布的，因此这帮助避免了同端口同协议的match在整个配置文件里的出现。 \u0026quot;applicationProtocols\u0026quot;: \u0026amp;#91; \u0026quot;istio\u0026quot;, \u0026quot;istio-http/1.0\u0026quot;, \u0026quot;istio-http/1.1\u0026quot;, \u0026quot;istio-h2\u0026quot; ] }, \u0026quot;filters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;istio.metadata_exchange\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.tcp.metadataexchange.config.MetadataExchange\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;protocol\u0026quot;: \u0026quot;istio-peer-exchange\u0026quot; } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.http_connection_manager\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.network.http_connection_manager.v2.HttpConnectionManager\u0026quot;, \u0026quot;statPrefix\u0026quot;: \u0026quot;inbound_10.244.2.138_9080\u0026quot;, \u0026quot;routeConfig\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;inbound|9080|http|productpage.istio-bookinfo.svc.cluster.local\u0026quot;, \u0026quot;virtualHosts\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;inbound|http|9080\u0026quot;, \u0026quot;domains\u0026quot;: \u0026amp;#91; \u0026quot;*\u0026quot; ], \u0026quot;routes\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;match\u0026quot;: { \u0026quot;prefix\u0026quot;: \u0026quot;/\u0026quot; }, \u0026quot;route\u0026quot;: { \u0026quot;cluster\u0026quot;: \u0026quot;inbound|9080|http|productpage.istio-bookinfo.svc.cluster.local\u0026quot;, \u0026quot;timeout\u0026quot;: \u0026quot;0s\u0026quot;, \u0026quot;maxGrpcTimeout\u0026quot;: \u0026quot;0s\u0026quot; }, \u0026quot;decorator\u0026quot;: { \u0026quot;operation\u0026quot;: \u0026quot;productpage.istio-bookinfo.svc.cluster.local:9080/*\u0026quot; } } ] } ], Last Attach the actual configuration of 15006\n\u0026amp;#91;root@k8s-master-v1-16 ~]# istioctl proxy-config listener productpage-v1-7f4cc988c6-qxqjs.istio-bookinfo --port 15006 -o json \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;virtualInbound\u0026quot;, \u0026quot;address\u0026quot;: { \u0026quot;socketAddress\u0026quot;: { \u0026quot;address\u0026quot;: \u0026quot;0.0.0.0\u0026quot;, \u0026quot;portValue\u0026quot;: 15006 } }, \u0026quot;filterChains\u0026quot;: \u0026amp;#91; { \u0026quot;filterChainMatch\u0026quot;: { \u0026quot;prefixRanges\u0026quot;: \u0026amp;#91; { \u0026quot;addressPrefix\u0026quot;: \u0026quot;0.0.0.0\u0026quot;, \u0026quot;prefixLen\u0026quot;: 0 } ], \u0026quot;transportProtocol\u0026quot;: \u0026quot;tls\u0026quot;, \u0026quot;applicationProtocols\u0026quot;: \u0026amp;#91; \u0026quot;istio-peer-exchange\u0026quot;, \u0026quot;istio\u0026quot; ] }, \u0026quot;filters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;istio.metadata_exchange\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.tcp.metadataexchange.config.MetadataExchange\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;protocol\u0026quot;: \u0026quot;istio-peer-exchange\u0026quot; } } }, { \u0026quot;name\u0026quot;: \u0026quot;istio.stats\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.extensions.filters.network.wasm.v3.Wasm\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;config\u0026quot;: { \u0026quot;configuration\u0026quot;: \u0026quot;{\\n \\\u0026quot;debug\\\u0026quot;: \\\u0026quot;false\\\u0026quot;,\\n \\\u0026quot;stat_prefix\\\u0026quot;: \\\u0026quot;istio\\\u0026quot;\\n}\\n\u0026quot;, \u0026quot;root_id\u0026quot;: \u0026quot;stats_inbound\u0026quot;, \u0026quot;vm_config\u0026quot;: { \u0026quot;code\u0026quot;: { \u0026quot;local\u0026quot;: { \u0026quot;inline_string\u0026quot;: \u0026quot;envoy.wasm.stats\u0026quot; } }, \u0026quot;runtime\u0026quot;: \u0026quot;envoy.wasm.runtime.null\u0026quot;, \u0026quot;vm_id\u0026quot;: \u0026quot;tcp_stats_inbound\u0026quot; } } } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.tcp_proxy\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.network.tcp_proxy.v2.TcpProxy\u0026quot;, \u0026quot;statPrefix\u0026quot;: \u0026quot;InboundPassthroughClusterIpv4\u0026quot;, \u0026quot;cluster\u0026quot;: \u0026quot;InboundPassthroughClusterIpv4\u0026quot;, \u0026quot;accessLog\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;envoy.file_access_log\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.accesslog.v2.FileAccessLog\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/dev/stdout\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;\u0026amp;#91;%START_TIME%] \\\u0026quot;%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%\\\u0026quot; %RESPONSE_CODE% %RESPONSE_FLAGS% \\\u0026quot;%DYNAMIC_METADATA(istio.mixer:status)%\\\u0026quot; \\\u0026quot;%UPSTREAM_TRANSPORT_FAILURE_REASON%\\\u0026quot; %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \\\u0026quot;%REQ(X-FORWARDED-FOR)%\\\u0026quot; \\\u0026quot;%REQ(USER-AGENT)%\\\u0026quot; \\\u0026quot;%REQ(X-REQUEST-ID)%\\\u0026quot; \\\u0026quot;%REQ(:AUTHORITY)%\\\u0026quot; \\\u0026quot;%UPSTREAM_HOST%\\\u0026quot; %UPSTREAM_CLUSTER% %UPSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_REMOTE_ADDRESS% %REQUESTED_SERVER_NAME% %ROUTE_NAME%\\n\u0026quot; } } ] } } ], \u0026quot;transportSocket\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;envoy.transport_sockets.tls\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.api.v2.auth.DownstreamTlsContext\u0026quot;, \u0026quot;commonTlsContext\u0026quot;: { \u0026quot;tlsCertificateSdsSecretConfigs\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;sdsConfig\u0026quot;: { \u0026quot;apiConfigSource\u0026quot;: { \u0026quot;apiType\u0026quot;: \u0026quot;GRPC\u0026quot;, \u0026quot;grpcServices\u0026quot;: \u0026amp;#91; { \u0026quot;envoyGrpc\u0026quot;: { \u0026quot;clusterName\u0026quot;: \u0026quot;sds-grpc\u0026quot; } } ] } } } ], \u0026quot;combinedValidationContext\u0026quot;: { \u0026quot;defaultValidationContext\u0026quot;: {}, \u0026quot;validationContextSdsSecretConfig\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;ROOTCA\u0026quot;, \u0026quot;sdsConfig\u0026quot;: { \u0026quot;apiConfigSource\u0026quot;: { \u0026quot;apiType\u0026quot;: \u0026quot;GRPC\u0026quot;, \u0026quot;grpcServices\u0026quot;: \u0026amp;#91; { \u0026quot;envoyGrpc\u0026quot;: { \u0026quot;clusterName\u0026quot;: \u0026quot;sds-grpc\u0026quot; } } ] } } } }, \u0026quot;alpnProtocols\u0026quot;: \u0026amp;#91; \u0026quot;istio-peer-exchange\u0026quot;, \u0026quot;h2\u0026quot;, \u0026quot;http/1.1\u0026quot; ] }, \u0026quot;requireClientCertificate\u0026quot;: true } }, \u0026quot;name\u0026quot;: \u0026quot;virtualInbound\u0026quot; }, { \u0026quot;filterChainMatch\u0026quot;: { \u0026quot;prefixRanges\u0026quot;: \u0026amp;#91; { \u0026quot;addressPrefix\u0026quot;: \u0026quot;0.0.0.0\u0026quot;, \u0026quot;prefixLen\u0026quot;: 0 } ] }, \u0026quot;filters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;istio.metadata_exchange\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.tcp.metadataexchange.config.MetadataExchange\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;protocol\u0026quot;: \u0026quot;istio-peer-exchange\u0026quot; } } }, { \u0026quot;name\u0026quot;: \u0026quot;istio.stats\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.extensions.filters.network.wasm.v3.Wasm\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;config\u0026quot;: { \u0026quot;configuration\u0026quot;: \u0026quot;{\\n \\\u0026quot;debug\\\u0026quot;: \\\u0026quot;false\\\u0026quot;,\\n \\\u0026quot;stat_prefix\\\u0026quot;: \\\u0026quot;istio\\\u0026quot;\\n}\\n\u0026quot;, \u0026quot;root_id\u0026quot;: \u0026quot;stats_inbound\u0026quot;, \u0026quot;vm_config\u0026quot;: { \u0026quot;code\u0026quot;: { \u0026quot;local\u0026quot;: { \u0026quot;inline_string\u0026quot;: \u0026quot;envoy.wasm.stats\u0026quot; } }, \u0026quot;runtime\u0026quot;: \u0026quot;envoy.wasm.runtime.null\u0026quot;, \u0026quot;vm_id\u0026quot;: \u0026quot;tcp_stats_inbound\u0026quot; } } } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.tcp_proxy\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.network.tcp_proxy.v2.TcpProxy\u0026quot;, \u0026quot;statPrefix\u0026quot;: \u0026quot;InboundPassthroughClusterIpv4\u0026quot;, \u0026quot;cluster\u0026quot;: \u0026quot;InboundPassthroughClusterIpv4\u0026quot;, \u0026quot;accessLog\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;envoy.file_access_log\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.accesslog.v2.FileAccessLog\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/dev/stdout\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;\u0026amp;#91;%START_TIME%] \\\u0026quot;%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%\\\u0026quot; %RESPONSE_CODE% %RESPONSE_FLAGS% \\\u0026quot;%DYNAMIC_METADATA(istio.mixer:status)%\\\u0026quot; \\\u0026quot;%UPSTREAM_TRANSPORT_FAILURE_REASON%\\\u0026quot; %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \\\u0026quot;%REQ(X-FORWARDED-FOR)%\\\u0026quot; \\\u0026quot;%REQ(USER-AGENT)%\\\u0026quot; \\\u0026quot;%REQ(X-REQUEST-ID)%\\\u0026quot; \\\u0026quot;%REQ(:AUTHORITY)%\\\u0026quot; \\\u0026quot;%UPSTREAM_HOST%\\\u0026quot; %UPSTREAM_CLUSTER% %UPSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_REMOTE_ADDRESS% %REQUESTED_SERVER_NAME% %ROUTE_NAME%\\n\u0026quot; } } ] } } ], \u0026quot;name\u0026quot;: \u0026quot;virtualInbound\u0026quot; }, { \u0026quot;filterChainMatch\u0026quot;: { \u0026quot;prefixRanges\u0026quot;: \u0026amp;#91; { \u0026quot;addressPrefix\u0026quot;: \u0026quot;0.0.0.0\u0026quot;, \u0026quot;prefixLen\u0026quot;: 0 } ], \u0026quot;transportProtocol\u0026quot;: \u0026quot;tls\u0026quot;, \u0026quot;applicationProtocols\u0026quot;: \u0026amp;#91; \u0026quot;http/1.0\u0026quot;, \u0026quot;http/1.1\u0026quot;, \u0026quot;h2c\u0026quot;, \u0026quot;istio-http/1.0\u0026quot;, \u0026quot;istio-http/1.1\u0026quot;, \u0026quot;istio-h2\u0026quot; ] }, \u0026quot;filters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;istio.metadata_exchange\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.tcp.metadataexchange.config.MetadataExchange\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;protocol\u0026quot;: \u0026quot;istio-peer-exchange\u0026quot; } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.http_connection_manager\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.network.http_connection_manager.v2.HttpConnectionManager\u0026quot;, \u0026quot;statPrefix\u0026quot;: \u0026quot;InboundPassthroughClusterIpv4\u0026quot;, \u0026quot;routeConfig\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;InboundPassthroughClusterIpv4\u0026quot;, \u0026quot;virtualHosts\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;inbound|http|0\u0026quot;, \u0026quot;domains\u0026quot;: \u0026amp;#91; \u0026quot;*\u0026quot; ], \u0026quot;routes\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;match\u0026quot;: { \u0026quot;prefix\u0026quot;: \u0026quot;/\u0026quot; }, \u0026quot;route\u0026quot;: { \u0026quot;cluster\u0026quot;: \u0026quot;InboundPassthroughClusterIpv4\u0026quot;, \u0026quot;timeout\u0026quot;: \u0026quot;0s\u0026quot;, \u0026quot;maxGrpcTimeout\u0026quot;: \u0026quot;0s\u0026quot; }, \u0026quot;decorator\u0026quot;: { \u0026quot;operation\u0026quot;: \u0026quot;:0/*\u0026quot; } } ] } ], \u0026quot;validateClusters\u0026quot;: false }, \u0026quot;httpFilters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;istio.metadata_exchange\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.extensions.filters.http.wasm.v3.Wasm\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;config\u0026quot;: { \u0026quot;configuration\u0026quot;: \u0026quot;{}\\n\u0026quot;, \u0026quot;vm_config\u0026quot;: { \u0026quot;code\u0026quot;: { \u0026quot;local\u0026quot;: { \u0026quot;inline_string\u0026quot;: \u0026quot;envoy.wasm.metadata_exchange\u0026quot; } }, \u0026quot;runtime\u0026quot;: \u0026quot;envoy.wasm.runtime.null\u0026quot; } } } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.cors\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.http.cors.v2.Cors\u0026quot; } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.fault\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.http.fault.v2.HTTPFault\u0026quot; } }, { \u0026quot;name\u0026quot;: \u0026quot;istio.stats\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.extensions.filters.http.wasm.v3.Wasm\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;config\u0026quot;: { \u0026quot;configuration\u0026quot;: \u0026quot;{\\n \\\u0026quot;debug\\\u0026quot;: \\\u0026quot;false\\\u0026quot;,\\n \\\u0026quot;stat_prefix\\\u0026quot;: \\\u0026quot;istio\\\u0026quot;\\n}\\n\u0026quot;, \u0026quot;root_id\u0026quot;: \u0026quot;stats_inbound\u0026quot;, \u0026quot;vm_config\u0026quot;: { \u0026quot;code\u0026quot;: { \u0026quot;local\u0026quot;: { \u0026quot;inline_string\u0026quot;: \u0026quot;envoy.wasm.stats\u0026quot; } }, \u0026quot;runtime\u0026quot;: \u0026quot;envoy.wasm.runtime.null\u0026quot;, \u0026quot;vm_id\u0026quot;: \u0026quot;stats_inbound\u0026quot; } } } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.router\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.http.router.v2.Router\u0026quot; } } ], \u0026quot;tracing\u0026quot;: { \u0026quot;clientSampling\u0026quot;: { \u0026quot;value\u0026quot;: 100 }, \u0026quot;randomSampling\u0026quot;: { \u0026quot;value\u0026quot;: 100 }, \u0026quot;overallSampling\u0026quot;: { \u0026quot;value\u0026quot;: 100 } }, \u0026quot;serverName\u0026quot;: \u0026quot;istio-envoy\u0026quot;, \u0026quot;streamIdleTimeout\u0026quot;: \u0026quot;0s\u0026quot;, \u0026quot;accessLog\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;envoy.file_access_log\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.accesslog.v2.FileAccessLog\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/dev/stdout\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;\u0026amp;#91;%START_TIME%] \\\u0026quot;%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%\\\u0026quot; %RESPONSE_CODE% %RESPONSE_FLAGS% \\\u0026quot;%DYNAMIC_METADATA(istio.mixer:status)%\\\u0026quot; \\\u0026quot;%UPSTREAM_TRANSPORT_FAILURE_REASON%\\\u0026quot; %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \\\u0026quot;%REQ(X-FORWARDED-FOR)%\\\u0026quot; \\\u0026quot;%REQ(USER-AGENT)%\\\u0026quot; \\\u0026quot;%REQ(X-REQUEST-ID)%\\\u0026quot; \\\u0026quot;%REQ(:AUTHORITY)%\\\u0026quot; \\\u0026quot;%UPSTREAM_HOST%\\\u0026quot; %UPSTREAM_CLUSTER% %UPSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_REMOTE_ADDRESS% %REQUESTED_SERVER_NAME% %ROUTE_NAME%\\n\u0026quot; } } ], \u0026quot;useRemoteAddress\u0026quot;: false, \u0026quot;generateRequestId\u0026quot;: true, \u0026quot;forwardClientCertDetails\u0026quot;: \u0026quot;APPEND_FORWARD\u0026quot;, \u0026quot;setCurrentClientCertDetails\u0026quot;: { \u0026quot;subject\u0026quot;: true, \u0026quot;dns\u0026quot;: true, \u0026quot;uri\u0026quot;: true }, \u0026quot;upgradeConfigs\u0026quot;: \u0026amp;#91; { \u0026quot;upgradeType\u0026quot;: \u0026quot;websocket\u0026quot; } ], \u0026quot;normalizePath\u0026quot;: true } } ], \u0026quot;transportSocket\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;envoy.transport_sockets.tls\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.api.v2.auth.DownstreamTlsContext\u0026quot;, \u0026quot;commonTlsContext\u0026quot;: { \u0026quot;tlsCertificateSdsSecretConfigs\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;sdsConfig\u0026quot;: { \u0026quot;apiConfigSource\u0026quot;: { \u0026quot;apiType\u0026quot;: \u0026quot;GRPC\u0026quot;, \u0026quot;grpcServices\u0026quot;: \u0026amp;#91; { \u0026quot;envoyGrpc\u0026quot;: { \u0026quot;clusterName\u0026quot;: \u0026quot;sds-grpc\u0026quot; } } ] } } } ], \u0026quot;combinedValidationContext\u0026quot;: { \u0026quot;defaultValidationContext\u0026quot;: {}, \u0026quot;validationContextSdsSecretConfig\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;ROOTCA\u0026quot;, \u0026quot;sdsConfig\u0026quot;: { \u0026quot;apiConfigSource\u0026quot;: { \u0026quot;apiType\u0026quot;: \u0026quot;GRPC\u0026quot;, \u0026quot;grpcServices\u0026quot;: \u0026amp;#91; { \u0026quot;envoyGrpc\u0026quot;: { \u0026quot;clusterName\u0026quot;: \u0026quot;sds-grpc\u0026quot; } } ] } } } }, \u0026quot;alpnProtocols\u0026quot;: \u0026amp;#91; \u0026quot;h2\u0026quot;, \u0026quot;http/1.1\u0026quot; ] }, \u0026quot;requireClientCertificate\u0026quot;: true } }, \u0026quot;name\u0026quot;: \u0026quot;virtualInbound-catchall-http\u0026quot; }, { \u0026quot;filterChainMatch\u0026quot;: { \u0026quot;prefixRanges\u0026quot;: \u0026amp;#91; { \u0026quot;addressPrefix\u0026quot;: \u0026quot;0.0.0.0\u0026quot;, \u0026quot;prefixLen\u0026quot;: 0 } ], \u0026quot;applicationProtocols\u0026quot;: \u0026amp;#91; \u0026quot;http/1.0\u0026quot;, \u0026quot;http/1.1\u0026quot;, \u0026quot;h2c\u0026quot; ] }, \u0026quot;filters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;istio.metadata_exchange\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.tcp.metadataexchange.config.MetadataExchange\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;protocol\u0026quot;: \u0026quot;istio-peer-exchange\u0026quot; } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.http_connection_manager\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.network.http_connection_manager.v2.HttpConnectionManager\u0026quot;, \u0026quot;statPrefix\u0026quot;: \u0026quot;InboundPassthroughClusterIpv4\u0026quot;, \u0026quot;routeConfig\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;InboundPassthroughClusterIpv4\u0026quot;, \u0026quot;virtualHosts\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;inbound|http|0\u0026quot;, \u0026quot;domains\u0026quot;: \u0026amp;#91; \u0026quot;*\u0026quot; ], \u0026quot;routes\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;match\u0026quot;: { \u0026quot;prefix\u0026quot;: \u0026quot;/\u0026quot; }, \u0026quot;route\u0026quot;: { \u0026quot;cluster\u0026quot;: \u0026quot;InboundPassthroughClusterIpv4\u0026quot;, \u0026quot;timeout\u0026quot;: \u0026quot;0s\u0026quot;, \u0026quot;maxGrpcTimeout\u0026quot;: \u0026quot;0s\u0026quot; }, \u0026quot;decorator\u0026quot;: { \u0026quot;operation\u0026quot;: \u0026quot;:0/*\u0026quot; } } ] } ], \u0026quot;validateClusters\u0026quot;: false }, \u0026quot;httpFilters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;istio.metadata_exchange\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.extensions.filters.http.wasm.v3.Wasm\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;config\u0026quot;: { \u0026quot;configuration\u0026quot;: \u0026quot;{}\\n\u0026quot;, \u0026quot;vm_config\u0026quot;: { \u0026quot;code\u0026quot;: { \u0026quot;local\u0026quot;: { \u0026quot;inline_string\u0026quot;: \u0026quot;envoy.wasm.metadata_exchange\u0026quot; } }, \u0026quot;runtime\u0026quot;: \u0026quot;envoy.wasm.runtime.null\u0026quot; } } } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.cors\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.http.cors.v2.Cors\u0026quot; } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.fault\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.http.fault.v2.HTTPFault\u0026quot; } }, { \u0026quot;name\u0026quot;: \u0026quot;istio.stats\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.extensions.filters.http.wasm.v3.Wasm\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;config\u0026quot;: { \u0026quot;configuration\u0026quot;: \u0026quot;{\\n \\\u0026quot;debug\\\u0026quot;: \\\u0026quot;false\\\u0026quot;,\\n \\\u0026quot;stat_prefix\\\u0026quot;: \\\u0026quot;istio\\\u0026quot;\\n}\\n\u0026quot;, \u0026quot;root_id\u0026quot;: \u0026quot;stats_inbound\u0026quot;, \u0026quot;vm_config\u0026quot;: { \u0026quot;code\u0026quot;: { \u0026quot;local\u0026quot;: { \u0026quot;inline_string\u0026quot;: \u0026quot;envoy.wasm.stats\u0026quot; } }, \u0026quot;runtime\u0026quot;: \u0026quot;envoy.wasm.runtime.null\u0026quot;, \u0026quot;vm_id\u0026quot;: \u0026quot;stats_inbound\u0026quot; } } } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.router\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.http.router.v2.Router\u0026quot; } } ], \u0026quot;tracing\u0026quot;: { \u0026quot;clientSampling\u0026quot;: { \u0026quot;value\u0026quot;: 100 }, \u0026quot;randomSampling\u0026quot;: { \u0026quot;value\u0026quot;: 100 }, \u0026quot;overallSampling\u0026quot;: { \u0026quot;value\u0026quot;: 100 } }, \u0026quot;serverName\u0026quot;: \u0026quot;istio-envoy\u0026quot;, \u0026quot;streamIdleTimeout\u0026quot;: \u0026quot;0s\u0026quot;, \u0026quot;accessLog\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;envoy.file_access_log\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.accesslog.v2.FileAccessLog\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/dev/stdout\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;\u0026amp;#91;%START_TIME%] \\\u0026quot;%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%\\\u0026quot; %RESPONSE_CODE% %RESPONSE_FLAGS% \\\u0026quot;%DYNAMIC_METADATA(istio.mixer:status)%\\\u0026quot; \\\u0026quot;%UPSTREAM_TRANSPORT_FAILURE_REASON%\\\u0026quot; %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \\\u0026quot;%REQ(X-FORWARDED-FOR)%\\\u0026quot; \\\u0026quot;%REQ(USER-AGENT)%\\\u0026quot; \\\u0026quot;%REQ(X-REQUEST-ID)%\\\u0026quot; \\\u0026quot;%REQ(:AUTHORITY)%\\\u0026quot; \\\u0026quot;%UPSTREAM_HOST%\\\u0026quot; %UPSTREAM_CLUSTER% %UPSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_REMOTE_ADDRESS% %REQUESTED_SERVER_NAME% %ROUTE_NAME%\\n\u0026quot; } } ], \u0026quot;useRemoteAddress\u0026quot;: false, \u0026quot;generateRequestId\u0026quot;: true, \u0026quot;forwardClientCertDetails\u0026quot;: \u0026quot;APPEND_FORWARD\u0026quot;, \u0026quot;setCurrentClientCertDetails\u0026quot;: { \u0026quot;subject\u0026quot;: true, \u0026quot;dns\u0026quot;: true, \u0026quot;uri\u0026quot;: true }, \u0026quot;upgradeConfigs\u0026quot;: \u0026amp;#91; { \u0026quot;upgradeType\u0026quot;: \u0026quot;websocket\u0026quot; } ], \u0026quot;normalizePath\u0026quot;: true } } ], \u0026quot;name\u0026quot;: \u0026quot;virtualInbound-catchall-http\u0026quot; }, { \u0026quot;filterChainMatch\u0026quot;: { \u0026quot;destinationPort\u0026quot;: 15021, \u0026quot;prefixRanges\u0026quot;: \u0026amp;#91; { \u0026quot;addressPrefix\u0026quot;: \u0026quot;10.244.2.155\u0026quot;, \u0026quot;prefixLen\u0026quot;: 32 } ] }, \u0026quot;filters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;istio.metadata_exchange\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.tcp.metadataexchange.config.MetadataExchange\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;protocol\u0026quot;: \u0026quot;istio-peer-exchange\u0026quot; } } }, { \u0026quot;name\u0026quot;: \u0026quot;istio.stats\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.extensions.filters.network.wasm.v3.Wasm\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;config\u0026quot;: { \u0026quot;configuration\u0026quot;: \u0026quot;{\\n \\\u0026quot;debug\\\u0026quot;: \\\u0026quot;false\\\u0026quot;,\\n \\\u0026quot;stat_prefix\\\u0026quot;: \\\u0026quot;istio\\\u0026quot;\\n}\\n\u0026quot;, \u0026quot;root_id\u0026quot;: \u0026quot;stats_inbound\u0026quot;, \u0026quot;vm_config\u0026quot;: { \u0026quot;code\u0026quot;: { \u0026quot;local\u0026quot;: { \u0026quot;inline_string\u0026quot;: \u0026quot;envoy.wasm.stats\u0026quot; } }, \u0026quot;runtime\u0026quot;: \u0026quot;envoy.wasm.runtime.null\u0026quot;, \u0026quot;vm_id\u0026quot;: \u0026quot;tcp_stats_inbound\u0026quot; } } } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.tcp_proxy\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.network.tcp_proxy.v2.TcpProxy\u0026quot;, \u0026quot;statPrefix\u0026quot;: \u0026quot;inbound|15021|mgmt-15021|mgmtCluster\u0026quot;, \u0026quot;cluster\u0026quot;: \u0026quot;inbound|15021|mgmt-15021|mgmtCluster\u0026quot;, \u0026quot;accessLog\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;envoy.file_access_log\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.accesslog.v2.FileAccessLog\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/dev/stdout\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;\u0026amp;#91;%START_TIME%] \\\u0026quot;%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%\\\u0026quot; %RESPONSE_CODE% %RESPONSE_FLAGS% \\\u0026quot;%DYNAMIC_METADATA(istio.mixer:status)%\\\u0026quot; \\\u0026quot;%UPSTREAM_TRANSPORT_FAILURE_REASON%\\\u0026quot; %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \\\u0026quot;%REQ(X-FORWARDED-FOR)%\\\u0026quot; \\\u0026quot;%REQ(USER-AGENT)%\\\u0026quot; \\\u0026quot;%REQ(X-REQUEST-ID)%\\\u0026quot; \\\u0026quot;%REQ(:AUTHORITY)%\\\u0026quot; \\\u0026quot;%UPSTREAM_HOST%\\\u0026quot; %UPSTREAM_CLUSTER% %UPSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_REMOTE_ADDRESS% %REQUESTED_SERVER_NAME% %ROUTE_NAME%\\n\u0026quot; } } ] } } ], \u0026quot;name\u0026quot;: \u0026quot;10.244.2.155_15021\u0026quot; }, { \u0026quot;filterChainMatch\u0026quot;: { \u0026quot;destinationPort\u0026quot;: 9080, \u0026quot;prefixRanges\u0026quot;: \u0026amp;#91; { \u0026quot;addressPrefix\u0026quot;: \u0026quot;10.244.2.155\u0026quot;, \u0026quot;prefixLen\u0026quot;: 32 } ], \u0026quot;applicationProtocols\u0026quot;: \u0026amp;#91; \u0026quot;istio\u0026quot;, \u0026quot;istio-http/1.0\u0026quot;, \u0026quot;istio-http/1.1\u0026quot;, \u0026quot;istio-h2\u0026quot; ] }, \u0026quot;filters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;istio.metadata_exchange\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.tcp.metadataexchange.config.MetadataExchange\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;protocol\u0026quot;: \u0026quot;istio-peer-exchange\u0026quot; } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.http_connection_manager\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.network.http_connection_manager.v2.HttpConnectionManager\u0026quot;, \u0026quot;statPrefix\u0026quot;: \u0026quot;inbound_10.244.2.155_9080\u0026quot;, \u0026quot;routeConfig\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;inbound|9080|http|productpage.istio-bookinfo.svc.cluster.local\u0026quot;, \u0026quot;virtualHosts\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;inbound|http|9080\u0026quot;, \u0026quot;domains\u0026quot;: \u0026amp;#91; \u0026quot;*\u0026quot; ], \u0026quot;routes\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;match\u0026quot;: { \u0026quot;prefix\u0026quot;: \u0026quot;/\u0026quot; }, \u0026quot;route\u0026quot;: { \u0026quot;cluster\u0026quot;: \u0026quot;inbound|9080|http|productpage.istio-bookinfo.svc.cluster.local\u0026quot;, \u0026quot;timeout\u0026quot;: \u0026quot;0s\u0026quot;, \u0026quot;maxGrpcTimeout\u0026quot;: \u0026quot;0s\u0026quot; }, \u0026quot;decorator\u0026quot;: { \u0026quot;operation\u0026quot;: \u0026quot;productpage.istio-bookinfo.svc.cluster.local:9080/*\u0026quot; } } ] } ], \u0026quot;validateClusters\u0026quot;: false }, \u0026quot;httpFilters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;istio.metadata_exchange\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.extensions.filters.http.wasm.v3.Wasm\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;config\u0026quot;: { \u0026quot;configuration\u0026quot;: \u0026quot;{}\\n\u0026quot;, \u0026quot;vm_config\u0026quot;: { \u0026quot;code\u0026quot;: { \u0026quot;local\u0026quot;: { \u0026quot;inline_string\u0026quot;: \u0026quot;envoy.wasm.metadata_exchange\u0026quot; } }, \u0026quot;runtime\u0026quot;: \u0026quot;envoy.wasm.runtime.null\u0026quot; } } } } }, { \u0026quot;name\u0026quot;: \u0026quot;istio_authn\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/istio.envoy.config.filter.http.authn.v2alpha1.FilterConfig\u0026quot;, \u0026quot;policy\u0026quot;: { \u0026quot;peers\u0026quot;: \u0026amp;#91; { \u0026quot;mtls\u0026quot;: { \u0026quot;mode\u0026quot;: \u0026quot;PERMISSIVE\u0026quot; } } ] } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.cors\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.http.cors.v2.Cors\u0026quot; } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.fault\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.http.fault.v2.HTTPFault\u0026quot; } }, { \u0026quot;name\u0026quot;: \u0026quot;istio.stats\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.extensions.filters.http.wasm.v3.Wasm\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;config\u0026quot;: { \u0026quot;configuration\u0026quot;: \u0026quot;{\\n \\\u0026quot;debug\\\u0026quot;: \\\u0026quot;false\\\u0026quot;,\\n \\\u0026quot;stat_prefix\\\u0026quot;: \\\u0026quot;istio\\\u0026quot;\\n}\\n\u0026quot;, \u0026quot;root_id\u0026quot;: \u0026quot;stats_inbound\u0026quot;, \u0026quot;vm_config\u0026quot;: { \u0026quot;code\u0026quot;: { \u0026quot;local\u0026quot;: { \u0026quot;inline_string\u0026quot;: \u0026quot;envoy.wasm.stats\u0026quot; } }, \u0026quot;runtime\u0026quot;: \u0026quot;envoy.wasm.runtime.null\u0026quot;, \u0026quot;vm_id\u0026quot;: \u0026quot;stats_inbound\u0026quot; } } } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.router\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.http.router.v2.Router\u0026quot; } } ], \u0026quot;tracing\u0026quot;: { \u0026quot;clientSampling\u0026quot;: { \u0026quot;value\u0026quot;: 100 }, \u0026quot;randomSampling\u0026quot;: { \u0026quot;value\u0026quot;: 100 }, \u0026quot;overallSampling\u0026quot;: { \u0026quot;value\u0026quot;: 100 } }, \u0026quot;serverName\u0026quot;: \u0026quot;istio-envoy\u0026quot;, \u0026quot;streamIdleTimeout\u0026quot;: \u0026quot;0s\u0026quot;, \u0026quot;accessLog\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;envoy.file_access_log\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.accesslog.v2.FileAccessLog\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/dev/stdout\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;\u0026amp;#91;%START_TIME%] \\\u0026quot;%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%\\\u0026quot; %RESPONSE_CODE% %RESPONSE_FLAGS% \\\u0026quot;%DYNAMIC_METADATA(istio.mixer:status)%\\\u0026quot; \\\u0026quot;%UPSTREAM_TRANSPORT_FAILURE_REASON%\\\u0026quot; %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \\\u0026quot;%REQ(X-FORWARDED-FOR)%\\\u0026quot; \\\u0026quot;%REQ(USER-AGENT)%\\\u0026quot; \\\u0026quot;%REQ(X-REQUEST-ID)%\\\u0026quot; \\\u0026quot;%REQ(:AUTHORITY)%\\\u0026quot; \\\u0026quot;%UPSTREAM_HOST%\\\u0026quot; %UPSTREAM_CLUSTER% %UPSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_REMOTE_ADDRESS% %REQUESTED_SERVER_NAME% %ROUTE_NAME%\\n\u0026quot; } } ], \u0026quot;useRemoteAddress\u0026quot;: false, \u0026quot;generateRequestId\u0026quot;: true, \u0026quot;forwardClientCertDetails\u0026quot;: \u0026quot;APPEND_FORWARD\u0026quot;, \u0026quot;setCurrentClientCertDetails\u0026quot;: { \u0026quot;subject\u0026quot;: true, \u0026quot;dns\u0026quot;: true, \u0026quot;uri\u0026quot;: true }, \u0026quot;upgradeConfigs\u0026quot;: \u0026amp;#91; { \u0026quot;upgradeType\u0026quot;: \u0026quot;websocket\u0026quot; } ], \u0026quot;normalizePath\u0026quot;: true } } ], \u0026quot;transportSocket\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;envoy.transport_sockets.tls\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.api.v2.auth.DownstreamTlsContext\u0026quot;, \u0026quot;commonTlsContext\u0026quot;: { \u0026quot;tlsCertificateSdsSecretConfigs\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;sdsConfig\u0026quot;: { \u0026quot;apiConfigSource\u0026quot;: { \u0026quot;apiType\u0026quot;: \u0026quot;GRPC\u0026quot;, \u0026quot;grpcServices\u0026quot;: \u0026amp;#91; { \u0026quot;envoyGrpc\u0026quot;: { \u0026quot;clusterName\u0026quot;: \u0026quot;sds-grpc\u0026quot; } } ] } } } ], \u0026quot;combinedValidationContext\u0026quot;: { \u0026quot;defaultValidationContext\u0026quot;: {}, \u0026quot;validationContextSdsSecretConfig\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;ROOTCA\u0026quot;, \u0026quot;sdsConfig\u0026quot;: { \u0026quot;apiConfigSource\u0026quot;: { \u0026quot;apiType\u0026quot;: \u0026quot;GRPC\u0026quot;, \u0026quot;grpcServices\u0026quot;: \u0026amp;#91; { \u0026quot;envoyGrpc\u0026quot;: { \u0026quot;clusterName\u0026quot;: \u0026quot;sds-grpc\u0026quot; } } ] } } } }, \u0026quot;alpnProtocols\u0026quot;: \u0026amp;#91; \u0026quot;h2\u0026quot;, \u0026quot;http/1.1\u0026quot; ] }, \u0026quot;requireClientCertificate\u0026quot;: true } }, \u0026quot;name\u0026quot;: \u0026quot;10.244.2.155_9080\u0026quot; }, { \u0026quot;filterChainMatch\u0026quot;: { \u0026quot;destinationPort\u0026quot;: 9080, \u0026quot;prefixRanges\u0026quot;: \u0026amp;#91; { \u0026quot;addressPrefix\u0026quot;: \u0026quot;10.244.2.155\u0026quot;, \u0026quot;prefixLen\u0026quot;: 32 } ] }, \u0026quot;filters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;istio.metadata_exchange\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.tcp.metadataexchange.config.MetadataExchange\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;protocol\u0026quot;: \u0026quot;istio-peer-exchange\u0026quot; } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.http_connection_manager\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.network.http_connection_manager.v2.HttpConnectionManager\u0026quot;, \u0026quot;statPrefix\u0026quot;: \u0026quot;inbound_10.244.2.155_9080\u0026quot;, \u0026quot;routeConfig\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;inbound|9080|http|productpage.istio-bookinfo.svc.cluster.local\u0026quot;, \u0026quot;virtualHosts\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;inbound|http|9080\u0026quot;, \u0026quot;domains\u0026quot;: \u0026amp;#91; \u0026quot;*\u0026quot; ], \u0026quot;routes\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;match\u0026quot;: { \u0026quot;prefix\u0026quot;: \u0026quot;/\u0026quot; }, \u0026quot;route\u0026quot;: { \u0026quot;cluster\u0026quot;: \u0026quot;inbound|9080|http|productpage.istio-bookinfo.svc.cluster.local\u0026quot;, \u0026quot;timeout\u0026quot;: \u0026quot;0s\u0026quot;, \u0026quot;maxGrpcTimeout\u0026quot;: \u0026quot;0s\u0026quot; }, \u0026quot;decorator\u0026quot;: { \u0026quot;operation\u0026quot;: \u0026quot;productpage.istio-bookinfo.svc.cluster.local:9080/*\u0026quot; } } ] } ], \u0026quot;validateClusters\u0026quot;: false }, \u0026quot;httpFilters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;istio.metadata_exchange\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.extensions.filters.http.wasm.v3.Wasm\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;config\u0026quot;: { \u0026quot;configuration\u0026quot;: \u0026quot;{}\\n\u0026quot;, \u0026quot;vm_config\u0026quot;: { \u0026quot;code\u0026quot;: { \u0026quot;local\u0026quot;: { \u0026quot;inline_string\u0026quot;: \u0026quot;envoy.wasm.metadata_exchange\u0026quot; } }, \u0026quot;runtime\u0026quot;: \u0026quot;envoy.wasm.runtime.null\u0026quot; } } } } }, { \u0026quot;name\u0026quot;: \u0026quot;istio_authn\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/istio.envoy.config.filter.http.authn.v2alpha1.FilterConfig\u0026quot;, \u0026quot;policy\u0026quot;: { \u0026quot;peers\u0026quot;: \u0026amp;#91; { \u0026quot;mtls\u0026quot;: { \u0026quot;mode\u0026quot;: \u0026quot;PERMISSIVE\u0026quot; } } ] } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.cors\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.http.cors.v2.Cors\u0026quot; } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.fault\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.http.fault.v2.HTTPFault\u0026quot; } }, { \u0026quot;name\u0026quot;: \u0026quot;istio.stats\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/udpa.type.v1.TypedStruct\u0026quot;, \u0026quot;typeUrl\u0026quot;: \u0026quot;type.googleapis.com/envoy.extensions.filters.http.wasm.v3.Wasm\u0026quot;, \u0026quot;value\u0026quot;: { \u0026quot;config\u0026quot;: { \u0026quot;configuration\u0026quot;: \u0026quot;{\\n \\\u0026quot;debug\\\u0026quot;: \\\u0026quot;false\\\u0026quot;,\\n \\\u0026quot;stat_prefix\\\u0026quot;: \\\u0026quot;istio\\\u0026quot;\\n}\\n\u0026quot;, \u0026quot;root_id\u0026quot;: \u0026quot;stats_inbound\u0026quot;, \u0026quot;vm_config\u0026quot;: { \u0026quot;code\u0026quot;: { \u0026quot;local\u0026quot;: { \u0026quot;inline_string\u0026quot;: \u0026quot;envoy.wasm.stats\u0026quot; } }, \u0026quot;runtime\u0026quot;: \u0026quot;envoy.wasm.runtime.null\u0026quot;, \u0026quot;vm_id\u0026quot;: \u0026quot;stats_inbound\u0026quot; } } } } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.router\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.http.router.v2.Router\u0026quot; } } ], \u0026quot;tracing\u0026quot;: { \u0026quot;clientSampling\u0026quot;: { \u0026quot;value\u0026quot;: 100 }, \u0026quot;randomSampling\u0026quot;: { \u0026quot;value\u0026quot;: 100 }, \u0026quot;overallSampling\u0026quot;: { \u0026quot;value\u0026quot;: 100 } }, \u0026quot;serverName\u0026quot;: \u0026quot;istio-envoy\u0026quot;, \u0026quot;streamIdleTimeout\u0026quot;: \u0026quot;0s\u0026quot;, \u0026quot;accessLog\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;envoy.file_access_log\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.accesslog.v2.FileAccessLog\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/dev/stdout\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;\u0026amp;#91;%START_TIME%] \\\u0026quot;%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%\\\u0026quot; %RESPONSE_CODE% %RESPONSE_FLAGS% \\\u0026quot;%DYNAMIC_METADATA(istio.mixer:status)%\\\u0026quot; \\\u0026quot;%UPSTREAM_TRANSPORT_FAILURE_REASON%\\\u0026quot; %BYTES_RECEIVED% %BYTES_SENT% %DURATION% %RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)% \\\u0026quot;%REQ(X-FORWARDED-FOR)%\\\u0026quot; \\\u0026quot;%REQ(USER-AGENT)%\\\u0026quot; \\\u0026quot;%REQ(X-REQUEST-ID)%\\\u0026quot; \\\u0026quot;%REQ(:AUTHORITY)%\\\u0026quot; \\\u0026quot;%UPSTREAM_HOST%\\\u0026quot; %UPSTREAM_CLUSTER% %UPSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_LOCAL_ADDRESS% %DOWNSTREAM_REMOTE_ADDRESS% %REQUESTED_SERVER_NAME% %ROUTE_NAME%\\n\u0026quot; } } ], \u0026quot;useRemoteAddress\u0026quot;: false, \u0026quot;generateRequestId\u0026quot;: true, \u0026quot;forwardClientCertDetails\u0026quot;: \u0026quot;APPEND_FORWARD\u0026quot;, \u0026quot;setCurrentClientCertDetails\u0026quot;: { \u0026quot;subject\u0026quot;: true, \u0026quot;dns\u0026quot;: true, \u0026quot;uri\u0026quot;: true }, \u0026quot;upgradeConfigs\u0026quot;: \u0026amp;#91; { \u0026quot;upgradeType\u0026quot;: \u0026quot;websocket\u0026quot; } ], \u0026quot;normalizePath\u0026quot;: true } } ], \u0026quot;name\u0026quot;: \u0026quot;10.244.2.155_9080\u0026quot; } ], \u0026quot;listenerFilters\u0026quot;: \u0026amp;#91; { \u0026quot;name\u0026quot;: \u0026quot;envoy.listener.original_dst\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.listener.original_dst.v2.OriginalDst\u0026quot; } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.listener.tls_inspector\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.listener.tls_inspector.v2.TlsInspector\u0026quot; } }, { \u0026quot;name\u0026quot;: \u0026quot;envoy.listener.http_inspector\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/envoy.config.filter.listener.http_inspector.v2.HttpInspector\u0026quot; } } ], \u0026quot;listenerFiltersTimeout\u0026quot;: \u0026quot;1s\u0026quot;, \u0026quot;continueOnListenerFiltersTimeout\u0026quot;: true, \u0026quot;trafficDirection\u0026quot;: \u0026quot;INBOUND\u0026quot; } ] Check more istio practice detail at my tech blog https://imesh.club\n","date":1593043200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"fb77916de5e12a7d3d19f2354df82b80","permalink":"http://linjing.io/post/istio-traffic-control-deepdive/","publishdate":"2020-06-25T00:00:00Z","relpermalink":"/post/istio-traffic-control-deepdive/","section":"post","summary":"How istio manipulates the traffic.","tags":["istio","envoy"],"title":"Istio sidecar iptables and traffic steering detail","type":"post"},{"authors":["Jing Lin"],"categories":null,"content":"","date":1592921430,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"77dab66e174040344bc3e387035f213a","permalink":"http://linjing.io/talk/redhat-f5-devops-2020/","publishdate":"2020-06-23T14:10:30Z","relpermalink":"/talk/redhat-f5-devops-2020/","section":"talk","summary":"New finance, new applications, new delivery","tags":["talks","API","feature"],"title":"Devops drives the financial industry to accelerate innovation","type":"talk"},{"authors":["Jing Lin (林静)"],"categories":[],"content":"In the Istio system, in order to ensure the unity of policy coordination and experience, users will consider using Istio\u0026rsquo;s own Ingressgateway as the entrance to north-south traffic. Ingressgateway is generally deployed by deployment of multiple pods, scattered on multiple nodes of the cluster, depending on Due to the specific exposure type, especially in on-prem deployment, it is still necessary to deploy relevant load balancers outside the k8s cluster to load balance these ingressgateways, on the one hand, it can avoid access difficulties and operation and maintenance difficulties caused by multiple entrances. On the other hand, the high-performance and high-reliability F5 BIGIP can provide more function control and security value-added services for k8s cluster entrance traffic, which is similar to the Ingress controller.\nUnlike exposing ordinary service svc to external BIG-IP, ingressgateway itself is a collection point of various service ports. It may itself listen to many ports, so it is not easy to treat ingressgateway as a single ordinary svc. This article mainly explains how to combine Istio ingressgateway with BIG-IP to enhance the entrance business capability.\nThe possible methods on the network structure are:\nExternal load balancer \u0026mdash; access to \u0026ndash;\u0026gt; ingressgateway\u0026rsquo;s nodeport port\nExternal load balancer \u0026mdash; access to \u0026ndash;\u0026gt; ingressgateway direct endpoints port (direct to pod)\nFrom the point of view of performance, it is naturally the second direct pod method mentioned above that has better performance, depending on the network model of the k8s cluster. If the external and pod can be directly routed or the two-layer direct connection is naturally the easiest, if it cannot be directly routed, it needs to be based on vxlan and other tunnels to achieve pod direct. F5 BIGIP supports Layer 2 direct, dynamic routing or vxlan tunnel mode. Refer to this article for detailed network deployment structure , or search for related articles in this blog. In the following, we assume that F5 BIGIP has implemented vxlan with k8s cluster, which can reach the pod directly. The final data path is as follows:\nclient\u0026ndash;\u0026gt;F5BIGIP\u0026ndash;\u0026gt;Istio ingressgateway pod\u0026ndash;\u0026gt;endpoints\nThe underlying implementation of Istio Ingressgateway is envoy. When we publish a service to Ingressgateway through Gateway+VirtualService resource, Ingressgateway will listen to the port specified in Gateway. Therefore, once a new service is released, there may be a new listening port. However, when we deploy the ingressgateway pod, we will not configure all the external mappings in advance. That is to say, the port that the container in the pod listens to is not configured in the deployment of the pod. Don’t worry, it can be directly accessed at this time. This listening port on the pod, although the deployment port is not specified in advance.\nSo how to load balance for Ingressgateway through BIGIP and dynamically discover these new monitoring services? The answer is naturally the solution described in this article. F5 BIGIP provides a controller that runs inside k8s and automatically pushes these changes to BIGIP. on. Since the same k8s svc contains one more port, you need to pay attention to the servicePort parameter when publishing this k8s svc to F5. The specific publishing process refers to the following steps:\n  Deploy Istio Gateway+VirtualService resources\n  Edit the k8s svc corresponding to the existing Ingressgateway and add new port and target port configurations\n  Configure a new F5 configmap resource and specify the corresponding servicePort to publish the new service\n  DEMO:  First check the existing Ingressgateway pod ports are as follows, port 32400 is not exposed in the container port   name: istio-proxy ports: - containerPort: 15020 protocol: TCP - containerPort: 8080 protocol: TCP - containerPort: 8443 protocol: TCP - containerPort: 31400 protocol: TCP - containerPort: 15443 protocol: TCP - containerPort: 15011 protocol: TCP - containerPort: 15012 protocol: TCP - containerPort: 8060 protocol: TCP - containerPort: 853 protocol: TCP - containerPort: 15090 name: http-envoy-prom protocol: TCP Deploy Istio Gateway and VirtualService  apiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: name: tcp-echo-gateway spec: selector: istio: ingressgateway servers: - port: number: 32400 name: tcp protocol: TCP hosts: - \u0026quot;*\u0026quot; --- apiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata: name: tcp-echo-destination spec: host: tcp-echo subsets: - name: v1 labels: version: v1 - name: v2 labels: version: v2 --- apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: tcp-echo spec: hosts: - \u0026quot;*\u0026quot; gateways: - tcp-echo-gateway tcp: - match: - port: 32400 ###########32400端口监听 route: - destination: host: tcp-echo port: number: 9000 subset: v1 After the deployment is complete, check envoy to confirm that the monitoring has been issued   { \u0026quot;name\u0026quot;: \u0026quot;0.0.0.0_32400\u0026quot;, \u0026quot;address\u0026quot;: { \u0026quot;socketAddress\u0026quot;: { \u0026quot;address\u0026quot;: \u0026quot;0.0.0.0\u0026quot;, \u0026quot;portValue\u0026quot;: 32400 } }, \u0026quot;filterChains\u0026quot;: \u0026amp;#91; { \u0026quot;filters\u0026quot;: \u0026amp;#91; 。。。。。。。。。。省略。。。。。。。。。。 { \u0026quot;name\u0026quot;: \u0026quot;envoy.tcp_proxy\u0026quot;, \u0026quot;typedConfig\u0026quot;: { \u0026quot;@type\u0026quot;: 。。。。。 \u0026quot;cluster\u0026quot;: \u0026quot;outbound|9000|v1|tcp-echo.istio-io-tcp-traffic-shifting.svc.cluster.local\u0026quot;, 。。。。。 } } ] } ], \u0026quot;trafficDirection\u0026quot;: \u0026quot;OUTBOUND\u0026quot; }, Modify the existing Ingressgateway svc, increase the external exposure of 32400 port  kubectl edit svc istio-ingressgateway -n istio-system -o yaml 修改前： ports: - name: status-port nodePort: 31702 port: 15020 protocol: TCP targetPort: 15020 - name: http2 nodePort: 31547 port: 80 protocol: TCP targetPort: 8080 - name: https nodePort: 31956 port: 443 protocol: TCP targetPort: 8443 - name: tcp nodePort: 30775 port: 31400 protocol: TCP targetPort: 31400 - name: tls nodePort: 30536 port: 15443 protocol: TCP targetPort: 15443 selector: app: istio-ingressgateway istio: ingressgateway sessionAffinity: None type: LoadBalancer 修改后： ports: - name: status-port nodePort: 31702 port: 15020 protocol: TCP targetPort: 15020 - name: http2 nodePort: 31547 port: 80 protocol: TCP targetPort: 8080 - name: https nodePort: 31956 port: 443 protocol: TCP targetPort: 8443 - name: tcp nodePort: 30775 port: 31400 protocol: TCP targetPort: 31400 - name: tcp2 nodePort: 30776 port: 32400 protocol: TCP targetPort: 32400 #########新增端口 - name: tls nodePort: 30536 port: 15443 protocol: TCP targetPort: 15443 root@k8s-master-v1-16 ~]# kubectl get svc -n istio-system NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE grafana ClusterIP 10.96.165.101 \u0026amp;lt;none\u0026gt; 3000/TCP 2d istio-egressgateway ClusterIP 10.110.88.185 \u0026amp;lt;none\u0026gt; 80/TCP,443/TCP,15443/TCP 2d istio-ingressgateway LoadBalancer 10.96.122.225 \u0026amp;lt;pending\u0026gt; 15020:31702/TCP,80:31547/TCP,443:31956/TCP,31400:30775/TCP,32400:30776/TCP,15443:30536/TCP 2d istiod ClusterIP 10.102.252.88 \u0026amp;lt;none\u0026gt; 15010/TCP,15012/TCP,443/TCP,15014/TCP,53/UDP,853/TCP 2d jaeger-agent ClusterIP None \u0026amp;lt;none\u0026gt; 5775/UDP,6831/UDP,6832/UDP 2d jaeger-collector ClusterIP 10.105.130.171 \u0026amp;lt;none\u0026gt; 14267/TCP,14268/TCP,14250/TCP 2d jaeger-collector-headless ClusterIP None \u0026amp;lt;none\u0026gt; 14250/TCP 2d jaeger-query ClusterIP 10.99.139.251 \u0026amp;lt;none\u0026gt; 16686/TCP 2d kiali ClusterIP 10.101.189.237 \u0026amp;lt;none\u0026gt; 20001/TCP 2d prometheus ClusterIP 10.109.157.108 \u0026amp;lt;none\u0026gt; 9090/TCP 2d tracing ClusterIP 10.101.62.56 \u0026amp;lt;none\u0026gt; 80/TCP 2d zipkin ClusterIP 10.98.181.246 \u0026amp;lt;none\u0026gt; 9411/TCP Publish the 32400 servicePort to F5, at this time you need to add an F5 configmap, pay attention to the Chinese comments  kind: ConfigMap apiVersion: v1 metadata: name: istio-ingressgateway.32400.vs namespace: istio-system labels: f5type: virtual-server data: # See the f5-schema table for schema-controller compatibility # https://clouddocs.f5.com/containers/latest/releases_and_versioning.html#f5-schema schema: \u0026quot;f5schemadb://bigip-virtual-server_v0.1.7.json\u0026quot; data: | { \u0026quot;virtualServer\u0026quot;: { \u0026quot;backend\u0026quot;: { \u0026quot;serviceName\u0026quot;: \u0026quot;istio-ingressgateway\u0026quot;, \u0026quot;servicePort\u0026quot;: 32400 ####It is important here. The port of the corresponding k8s svc is filled in here. The F5 CIS controller will automatically find the targetPort (CIS cluster mode) or nodeport (CIS nodeport mode) corresponding to the servicePort }, \u0026quot;frontend\u0026quot;: { \u0026quot;virtualAddress\u0026quot;: { \u0026quot;port\u0026quot;: 31400, \u0026quot;bindAddr\u0026quot;: \u0026quot;172.16.100.195\u0026quot; }, \u0026quot;partition\u0026quot;: \u0026quot;k8s\u0026quot;, \u0026quot;balance\u0026quot;: \u0026quot;least-connections-member\u0026quot;, \u0026quot;mode\u0026quot;: \u0026quot;tcp\u0026quot; } } } F5 will automatically generate the following configuration in the red box:\nSimulate access to the business from the outside, you can see that it can be accessed normally\n# jlin @ Mac in ~ \u0026amp;#91;myf5.net] $ for i in {1..2000}; do (date; sleep 1) | nc istiobookinfo.lab.f5se.io 32400; done one Mon Jun 22 22:24:17 CST 2020 one Mon Jun 22 22:24:18 CST 2020 one Mon Jun 22 22:24:19 CST 2020 At this point, the newly released service monitor on Istio Ingressgateway is successfully automatically posted to BIGIP. Users only need to access BIGIP\u0026rsquo;s VS to access services within k8s (on Istio Ingressgateway).\nFor the subsequent release of other new port services, repeat the above steps.\n Note: The above configuration uses the non-F5 AS3 configmap configuration method, if you are using CIS 2.0, you need to pay attention to this issue https://github.com/F5Networks/k8s-bigip-ctlr/issues/1341\n Check more istio practice detail at my tech blog https://imesh.club\n","date":1592784000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"bbd13d8e9f83bee2bd540caa508e35ac","permalink":"http://linjing.io/post/f5-istio-work-together/","publishdate":"2020-06-22T00:00:00Z","relpermalink":"/post/f5-istio-work-together/","section":"post","summary":"F5 make istio works better","tags":["istio","envoy","f5"],"title":"F5 BIG-IP links Istio to enhance ingress service capabilities","type":"post"},{"authors":["Jing Lin (林静)"],"categories":[],"content":"Nowadays, the Internet has penetrated various life and business scenarios. Just like people have never been a simple individual in real life, we need to have many complicated relationship networks. The same is true of Internet applications, and it is now difficult to see which application can develop completely independently without having a relationship with its surroundings. Therefore, today\u0026rsquo;s applications are very particular about their own ecology, and they need to share a lot of information with each other. These complex relationships raise a very important issue: identity authentication, resource authorization, and account maintenance. Of course there is API authentication access control.\nFor example, in your daily life, you may need to use dozens of apps. Each of these apps has an independent account and password. You need to maintain different accounts and passwords. You may have one set of accounts for all apps in order to save trouble. Password, so after the application A was violently vaulted, you are forced to change all the passwords of the accounts of these dozens of apps. You may also be more concerned about the security of your account, so you use a fixed + changing password to combine dozens of APP accounts, which is very good, can help alleviate a large part of security issues, and at the same time reduce your password maintenance. Question (Is the memory okay), but these apps may not be able to follow the fixed + change mode you envisioned as you wish, some may only support numbers, some support numbers plus passwords, and some still It requires a minimum length and a more complicated combination, so you start to use a small book to record the password format of different applications (well, at least there was a stage where I did this, recorded in a description language on the computer, when forgotten At that time, go to find this hint in the computer).\nIs there a better way?\nIf you trust a company that has done well in security and has a good reputation system, can you use this account to run the Internet? I believe we already have the answer. Today, we may have used it a lot of times. When you log in to the XX application, you are used to skip user registration and go to click \u0026ldquo;log in with ***\u0026rdquo;, in the pop-up interface Here is a very sacred point under \u0026ldquo;Agree\u0026rdquo;. So you no longer need to remember so many application accounts. This is actually a typical open authorization (Open Authorization) referred to as oAuth (current version is 2, also known as oAuth2).\nUm, you seem to be lying to me. You have said so much, it seems to be all about authentication, why it is said to be Authorization. Yes, you are right, but I did not lie to you, but there are some silly problems that are not easy to distinguish. The original purpose of this oAuth design is to solve the problem of data access between interest groups, just like us As mentioned at the beginning, there is a problem of mutual access to a large amount of data between applications of different companies. For example, company A has developed an online photo printing application, but this company does not operate photo storage services. Your photos may exist in B, C, D. On the network disks of different companies (Yes, in order to take advantage of the early days, I did occupy a lot of the network disks of many companies. Later, some of their network disks used rogues to send a notice and couldn\u0026rsquo;t do anything. Fortunately, I used RAID1), so this caused problems. How do you send photos to this online printing company, download them from the BCD network disk and send them to them? Give the account number and password of the network disk to the printing company? Obviously these methods will not work. If you rely on downloading and uploading, it is estimated that you are too lazy to get it. If you are giving an account password, unless you are not sober.\nFor printing companies and network disk service providers, they also have similar troubles. If users are allowed to upload and download, the user experience is too bad, and they also maintain a whole set of such systems. Therefore, printing companies hope that there is a simple way to connect at the same time. BCD network disk company, as long as one of the users of these network disks agrees, it will automatically pull down the user photos from these network disks to print, and own 0 inventory. For the BCD network disk company, storing cold data alone is obviously not the purpose. Moreover, you are still in piao, you have to do tricks, so the network disk company also wants to dock these companies that print pictures, but for them It is necessary to solve the user\u0026rsquo;s security issues on accounts and photos.\nSo it can be seen that for these three different stakeholders, there is a desire to have something to solve their problems at the same time. This is authorization. When the user wants to print the photo, the printing company guides the customer to enter the network disk interface. The user is Log in to the network disk and authorize the network disk to allow which of my resources to be shared with the photo printing company. For example, share your beautiful photos to print, and the original photos are not allowed to be accessed by the printing company, which is very safe. So we can summarize:\noAuth is used to solve such a scenario, so you can see that it is an authorization process. But you haven’t said why it was a certification at the beginning, hmmm. After all, I also spent a lot of time to learn it. It is also a process after finishing it. Just like this article, it is a series. Only the following articles can be finished:\n NGINX as (Client) role and resource service role proxy in oAuth, Authorization code mode (with oAuth proxy service)-this article NGINX as (Client) role and resource service role proxy in oAuth, Authorization code mode (Without the help of oAuth proxy service) NGINX authenticates and recognizes id_token in OIDC (Implicit mode) NGINX acts as a resource service role in oAuth, proxy authentication and identity information recognition (Token introspection)  Why is authentication involved here? In fact, you will find that during the authorization process, the identity is obviously inescapable. The authorization must be based on a certain user, so the oAuth specification does not emphasize that you can’t do this. In addition to authorization, plus sometimes, we really do not need authorization scenarios, but want to reduce our account maintenance, use one company account to log in many products of other companies, so there are a lot of oAuth For authentication scenarios, of course, it is precisely because oAuth does not make many standardized definitions for authentication, which leads to different designs of programs of different companies when implementing authentication. There is no standard way to obtain user information. A common standard scope, based on this, OpenID Connect (OIDC) appeared. OIDC is based on oAuth. The communication process of several parties is the same. The difference is that OIDC is sending to IdP (the party that stores the account and performs verification). When the request is initiated, the openid tag will be brought in the scope. In the end, the information returned by the IdP will also carry an ID token (JWT) in addition to the oAuth normal access_token, and the application can use it as a login after getting this ID token. If you need more additional information, you can take the access_token and go to the userinfo endpoint to get more user information. In addition, OIDC is a protocol family and contains many other specifications, such as session management and registration discovery. Because oAuth and OIDC are very similar in communication mechanism, we often confuse the two. We often say that oAuth authentication should actually be oAuthZ, and OIDC is oAuthN.\nBack to this article, in this article, we will follow the interaction of a standard oAuth authorization code mode to see what NGINX can help users do here, and why NGINX is needed to do such a thing.\nFirst, we need to sort out the entire interaction process in the oAuth authorization code mode. In order to avoid the obscurity of RFC , let\u0026rsquo;s assume a scenario.\nYou are in a startup company, such as a company engaged in AI and big data (of course, it is not listed yet, it is listed, and you may not have time to read this article), your company uses a lot of cloud service examples, buy servers to engage in computer rooms , Engage in infrastructure, that is not a thing. You have used open source to build a lot of systems, and quickly put your business online. Everyone knows that open source systems have a great feature, which is friendly to developers. What does it mean, how is it convenient (that is, developers are lazy, non- To be straight\u0026hellip;), so you see that many open source systems don’t think about authentication, and you visit it after installing it. It seems that there is no account authentication as a matter of course. At first, it didn’t matter, because you were alone, what You have to do everything, as more and more systems, employees begin to increase, you need to make some restrictions on access to different systems for different people, and you are still going to go public, as a public company, your system There is no account, so it is unreasonable. Then you have some application development systems that need to connect to the github API. You need to allow only some advanced developers to access a private repo. And you have no time to build a new user management system yourself. Fortunately, these people have github accounts, so you can use these github accounts to do the simplest and fastest things. These requirements can be summarized as:\nA function needs to be implemented on different systems to enable these systems to interface with github, and use the github account to determine whether employees can access a certain system Log in with the github account on the application development system, and apply for resource authorization from github to include the person’s repo and other information. If the person does not have the private repo permission, the natural application development system cannot obtain the private under the permission of this employee. repo content These requirements oAuth can help solve, but there is a problem. If you join the oAuth mechanism, you need to develop on the system. So many open source systems, the development language is different, and even some systems dare not rush to redevelop. It is actually very difficult to achieve and the workload is actually very large.\nBefore looking at what NGINX can do, let\u0026rsquo;s take a look at the oAuth process without NGINX and the above requirements.\nFrom the above process, it can be seen that for users, they log in and authorize once on github, and the browser makes two jumps. The really useful access_token is between the back-end application server and github. The user and the browser itself cannot see the content of this access_token, which is called the backend channel and is relatively safe. So what does the application do after getting this access_token?\n-If it is limited to obtaining some basic information of the user, and the returned access_token is JWT, then the application server can obtain the content in the JWT by itself, so that the user information extraction is associated with some local user IDs, which can be used as Used for login (of course, if it is pure identity authentication and this joint login scenario, in fact, OIDC should still be considered). Of course, if the access_token here is opaque, then the application server also needs to do token introspection, that is, it needs to be verified again with the authorized party before the relevant information can be used.\n-If it is not limited to obtaining user information, but to obtain additional resources, such as the need to obtain the person\u0026rsquo;s repo content, then the application server needs to access this access_token to access a github repo resource server (resource server and The authorization servers are not necessarily the same, and large-scale scenes are usually not the same) to obtain the person\u0026rsquo;s repo content, then the above picture becomes like this:\nSo, you will find that the web application backend is very critical. It participates in the entire oAuth process and finally obtains the access_token. Imagine, as you said at the beginning of the company, many open source are developed in different languages. System, you have to transform to add this ability. At this time, you actually only want to decide based on the user\u0026rsquo;s information that the system must be logged in through the oAuth process before it can be accessed, or the system determines who can access based on the user name.\nThis work can actually be achieved by placing NGINX in front of the web application backend, which means that NGINX is allowed to participate in the oAuth authentication process on behalf of the backend application, and then NGINX can decide whether to allow or reject certain users based on access_token, or Transparently transmit user information to back-end applications for more processing.\nCarefully observe the entire verification process above, which requires NGINX to participate in the construction of the jump return, and use the authorization code to construct the request to directly access the github authorization server. If these tasks are done purely on NGINX, it is actually very difficult. Development through njs is a way but requires the ability to authenticate JWT (so NGINX Plus does not need to install an oauth proxy service like the demo in this article, It can be realized by directly using the njs module + KV module + JWT module. For details, please refer to the second part of this series), but in fact, it can be achieved with the help of the ability of auth_request and an oAuth proxy, which means that we need to be in various The implementation code of the oAuth authentication process created on the open source system is abstracted to it, and a general one is involved. The oAuth proxy agent participates in this oAuth process, and finally the obtained access_token is parsed out. The relevant claims information is returned to NGINX, NGINX Based on this information, we will control whether to allow access to a resource, or transparently pass relevant user information to the final application. So its implementation logic is as follows:\nThe idea and principle of implementation (the following serial number has nothing to do with the figure):\n Configure NGINX to publish protected applications Configure auth_request under the location section of the relevant application In this way, when the request reaches NGINX, NGINX will initiate the sub-request authentication by auth_request The sub-request will be proxy_pass to an interface of the oauth proxy service According to the characteristics of auth_request, it is necessary for oauth proxy to return the relevant status code to indicate whether NGINX is released or returns 401 Therefore, after receiving the sub-request, the oauth proxy will determine whether the user has previously completed the relevant oauth authentication work. If the user has not logged in, or the validity period has expired, then the oauth proxy returns 401 (here depends on whether the user browser carries the oauth proxy Issued by a cookie information to check) NGINX intercepts the status of 401, and implements the definition of error_page to send a 302 jump to the user\u0026rsquo;s browser if 401 is returned. The address of this jump is actually a special interface of oauth proxy used to trigger the subsequent oAuth process. The subsequent process is no different from normal oAuth. After the oAuth proxy completes the entire oAuth process, it returns a 302 jump to the user browser, and this return will also carry the relevant cookie to allow it to revisit the protected application After NGINX receives the request, it triggers auth_request again. auth_request sends the request to an interface of oauth proxy again. This visit carries the cookie in 8. This way, the oauth proxy knows who it is based on the cookie, and resolves its access_token to pass relevant claims. Put it in the response header and return to NGINX Use auth_request_set to put the claims in the response header of the sub-request into variables and pass it to the parent request NGINX judges whether to release based on these variables, or puts these user information in the request header to pass the content to the last protected application  There are many implementations of such an oauth proxy online, here is a brief list: vouch-proxy\noauth2 proxy\noauth2 proxy by lua -implement proxy directly in lua, no need to install additional proxy service\nDemo This demonstration uses NGINX plus and vouch-proxy to achieve. For the specific installation and configuration of vouch-proxy, please refer to its github directly, it is not complicated\nIn the actual demo, the web application backend actually has an intermediate NGINX to simulate, using return to return the content.\nNGINX configuration:\n############entry for protected app http://authcode.imesh.club/personalinfo server { listen 80; server_name authcode.imesh.club; #root /var/www/html/; # send all requests to the `/validate` endpoint for authorization auth_request /validate; #The location is for auth_request subrequest location = /validate { # forward the /validate request to Vouch Proxy proxy_pass http://127.0.0.1:9090/validate; # be sure to pass the original host header proxy_set_header Host $http_host; # Vouch Proxy only acts on the request headers proxy_pass_request_body off; proxy_set_header Content-Length \u0026quot;\u0026quot;; # optionally add X-Vouch-User as returned by Vouch Proxy along with the request auth_request_set $auth_resp_x_vouch_user $upstream_http_x_vouch_user; # these return values are used by the @error401 call auth_request_set $auth_resp_jwt $upstream_http_x_vouch_jwt; auth_request_set $auth_resp_err $upstream_http_x_vouch_err; auth_request_set $auth_resp_failcount $upstream_http_x_vouch_failcount; } # if validate returns `401 not authorized` then forward the request to the error401block error_page 401 = @error401; location @error401 { # redirect to Vouch Proxy for login return 302 http://vouch.imesh.club/login?url=$scheme://$http_host$request_uri\u0026amp;amp;vouch-failcount=$auth_resp_failcount\u0026amp;amp;X-Vouch-Token=$auth_resp_jwt\u0026amp;amp;error=$auth_resp_err; # you usually *want* to redirect to Vouch running behind the same Nginx config proteced by https # but to get started you can just forward the end user to the port that vouch is running on } # for the real service that being protected location / { # forward authorized requests to your service protectedapp.yourdomain.com ##he backend real server also simiulated by this nginx proxy_pass http://127.0.0.1:8080; # you may need to set these variables in this block as per https://github.com/vouch/vouch-proxy/issues/26#issuecomment-425215810 auth_request_set $auth_resp_x_vouch_user $upstream_http_x_vouch_user; auth_request_set $auth_resp_x_vouch_idp_claims_avatar $upstream_http_x_vouch_idp_claims_avatar_url; auth_request_set $auth_resp_x_vouch_idp_claims_company $upstream_http_x_vouch_idp_claims_company; auth_request_set $auth_resp_x_vouch_idp_claims_blog $upstream_http_x_vouch_idp_claims_blog; # set user header (usually an email) proxy_set_header X-Vouch-User $auth_resp_x_vouch_user; # optionally pass any custom claims you are tracking proxy_set_header X-Vouch-IdP-Claims-company $auth_resp_x_vouch_idp_claims_company; proxy_set_header X-Vouch-IdP-Claims-avatar $auth_resp_x_vouch_idp_claims_avatar; proxy_set_header X-Vouch-IdP-Claims-blog $auth_resp_x_vouch_idp_claims_blog; } } Simulation configuration of back-end applications\n server { listen 8080; location /personalinfo { default_type text/html; set $user $http_x_vouch_user; set $avatar $http_x_vouch_idp_claims_avatar; set $company $http_x_vouch_idp_claims_company; set $blog $http_x_vouch_idp_claims_blog; return 200 '\u0026amp;lt;html\u0026gt;\u0026amp;lt;head\u0026gt;\u0026amp;lt;meta http-equiv=\u0026quot;Content-Type\u0026quot; content=\u0026quot;text/html; charset=utf-8\u0026quot; /\u0026gt;\u0026amp;lt;/head\u0026gt;\u0026amp;lt;h2\u0026gt;Your personal info:\u0026amp;lt;/h2\u0026gt;\u0026amp;lt;hr /\u0026gt;Name: $user \u0026amp;lt;br\u0026gt;avatar: $avatar \u0026amp;lt;br\u0026gt;company: $company \u0026amp;lt;br\u0026gt;blog:$blog \u0026amp;lt;/html\u0026gt;'; } } Responsible for receiving the request configuration initiated by the client browser to the oauth proxy:\n#######work for vouch login/auth server { listen 80; server_name vouch.imesh.club; location / { proxy_pass http://127.0.0.1:9090; # be sure to pass the original host header proxy_set_header Host vouch.imesh.club; } } The effect of the visit process: The first visit to http://authcode.imesh.club/personalinfo, the browser is automatically jumped to the vouch.imesh.club/login? interface, this jump is actually driven by NGINX\nAfter receiving it, vouch.imesh.club processes it and asks the browser to jump to the github.com/authorize interface. Since it has not logged in on github, github jumps to the /login interface to let the user log in.\nThe login interface appears. After logging in, the authorization will be displayed. Clicking on the authorization will be redirected to vouch.imesh.club (the service address of oauth proxy), which actually returns the authorization code to the oauth poxy service.\nAfter clicking the authorization, the browser will continue to jump. The github implementation will have the following jump prompt, which is actually the browser to jump to the callback interface of vouch.imesh.club:\nAfter the callback interface of vouch.imesh.club is accessed, it will drive vouch to initiate access_token acquisition on the server side. At this time, the browser cannot capture it. When vouch has been obtained on the server, it returns a 302 to the browser again. This 302 requires the browser to officially access the application address, and is accompanied by the relevant cookie to the client browser:\nFinally completed the visit:\nSummary Use NGINX\u0026rsquo;s auth_request function, and through clever configuration to use oauth proxy to achieve the complete authentication process of oAuth, and pass relevant user information to NGINX to achieve access control and information processing. Except for the back-end, all applications need to develop code to implement oauth verification, so that enterprises can quickly use third-party accounts to control user access\nFollow up In this practice, the authorization code mode of oAuth is adopted, and the external oauth proxy service is used. If you do not want to rely on external services and want to implement on pure NGINX, you can refer to the second part of this series .\nCheck more oAuth posts of the series at my tech blog https://imesh.club/?s=oauth\n","date":1589068800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"372bebf41c0bfb5e03df40bc235d3607","permalink":"http://linjing.io/post/nginx-oauth2-oidc-series/","publishdate":"2020-05-10T00:00:00Z","relpermalink":"/post/nginx-oauth2-oidc-series/","section":"post","summary":"NGINX as different role in oAuth/OIDC","tags":["nginx","oAuth","OIDC"],"title":"NGINX and oAuth2/OIDC series one","type":"post"},{"authors":["Jing Lin"],"categories":null,"content":"","date":1582906410,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"8677edda20b7f461ea6677c957c59c21","permalink":"http://linjing.io/talk/f5-nginx-traning-2020/","publishdate":"2019-11-01T00:00:00Z","relpermalink":"/talk/f5-nginx-traning-2020/","section":"talk","summary":"NGINX training and practice.","tags":["talks","NGINX","train"],"title":"NGINX from zero to hero","type":"talk"},{"authors":["Jing Lin"],"categories":null,"content":"Get PPT from here: 链接: https://pan.baidu.com/s/18VV6w2q_s8zYVq3dWat3Zw 提取码：lu6x\n","date":1575820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"3e673fc4fa7e68815880f5eb27c6e721","permalink":"http://linjing.io/talk/devopsday-2019-shanghai/","publishdate":"2019-12-01T00:00:00Z","relpermalink":"/talk/devopsday-2019-shanghai/","section":"talk","summary":"This is an offline talk at Devopsday event. Talk about several possible API patterns.","tags":["talks","devops","API","feature"],"title":"Deployment Patterns for API Gateways","type":"talk"},{"authors":["Jing Lin"],"categories":null,"content":"","date":1574957610,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"60ea447a4c8e9df2be58ab3c561417b5","permalink":"http://linjing.io/talk/infoq-api-m-2019/","publishdate":"2019-11-01T00:00:00Z","relpermalink":"/talk/infoq-api-m-2019/","section":"talk","summary":"Talk about How does nginx help you on API-M.","tags":["talks","API","feature"],"title":"API deployment, security and management","type":"talk"},{"authors":["Jing Lin (林静)"],"categories":null,"content":"The serials include:\n Opening ………… What is ADC Chapter 1 ………… Cloud Native Introduction Chapter 2 ………… Financial Industry and Cloud Native Chapter 3 ………… F5/Nginx and Cloud Native Chapter 4 ………… Cloud Native ADC Chapter 5 ………… PaaS platform services exposed Chapter 6 ………… Service Mesh Chapter 7 ………… API priority Chapter 8 ………… Cloud-Ready\u0026rsquo;s first step towards cloud native  Check here for full article The link.\n","date":1566777600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"cee16b926bbad977aae5790f8b93e09b","permalink":"http://linjing.io/publication/f5-cloudnative-adc-2019/","publishdate":"2019-08-26T00:00:00Z","relpermalink":"/publication/f5-cloudnative-adc-2019/","section":"publication","summary":"What’s right direction for ADN evolution during the dramatic market change? Lots of different noises and arguments are arising.","tags":["cloud native","f5"],"title":"From legacy ADC to cloud native ADC series","type":"publication"},{"authors":["Jing Lin (林静)"],"categories":null,"content":"Check here for full article The link.\n","date":1562803200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"4b07a4d1ac7f25e3c790be52a54c7412","permalink":"http://linjing.io/publication/f5-cloudnative-adc-2019-infoq/","publishdate":"2019-07-15T00:00:00Z","relpermalink":"/publication/f5-cloudnative-adc-2019-infoq/","section":"publication","summary":"A public post at infoq.","tags":["cloud native","f5"],"title":"Viewing the construction of cloud native from the perspective of application delivery","type":"publication"},{"authors":[],"categories":[],"content":"Welcome to Slides academia\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three  A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/img/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"http://linjing.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using academia's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Jing Lin"],"categories":null,"content":"","date":1477408200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"b5d96d884e64d95e94754eb43c0fe48a","permalink":"http://linjing.io/talk/f5-ssl-2016/","publishdate":"2016-10-01T00:00:00Z","relpermalink":"/talk/f5-ssl-2016/","section":"talk","summary":"SSL deep dive.","tags":["talks","SSL","feature"],"title":"SSL every where","type":"talk"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"a903a8fd061907c9182a22fe4aed4729","permalink":"http://linjing.io/project/artificial-intelligence/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/artificial-intelligence/","section":"project","summary":"Lorem ipsum dolor sit amet consectetur adipisicing elit. Magnam, eius.","tags":["Demo","robotics"],"title":"Artificial Intelligence","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"http://linjing.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using \"external_link\".","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"http://linjing.io/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Jing Lin (林静)"],"categories":[],"content":"Create a free website with academia using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\nCheck out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n Setup academia Get Started View the documentation Ask a question Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of academia:  Donate a coffee Become a backer on Patreon Decorate your laptop or journal with an academia sticker Wear the T-shirt    \nKey features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Color Themes academia comes with day (light) and night (dark) mode built-in. Click the sun/moon icon in the top right of the Demo to see it in action!\nChoose a stunning color and font theme for your site. Themes are fully customizable and include:\n         Ecosystem  academia Admin: An admin tool to import publications from BibTeX or import assets for an offline site academia Scripts: Scripts to help migrate content to new versions of academia  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735210820,"objectID":"737a4d9f40e4da19ee82ee5cb6985167","permalink":"http://linjing.io/post/snail/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/snail/","section":"post","summary":"Create a beautifully simple website in under 10 minutes.","tags":["academia"],"title":"Just a sample","type":"post"}]